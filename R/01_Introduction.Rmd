---
editor_options: 
  markdown: 
    wrap: 72
---

\pagenumbering{arabic}

# Introduction

\ChapFrame[Introduction][bhtyellow]

Information is generated and processed by humans. And it is shared among
humans. At first this information sharing was done synchronous using
their voice. Later they developed the capabilities to store information
at clay tablets, paper and most recently in digital files
[@bentleyKnowingYouKnow2025]. The amount of stored information, the
human knowledge base grew paper by paper, file by file. The field of
library and information science emerged, to organize these information,
in order to allow efficient access. Since the information was shared
only among humans, the format of stored data was optimized for human
perception as well.

But things have changed in multiple ways. First, the amount of
information generation is growing rapidly and the amount of relevant
knowledge is increasing faster, than humans can absorb
[@chamberlainKnowledgeNotEverything2020]. Alone in the field of science
each year volumes of new information is beyond any humanâ€™s ability to
read are created [@hongChallengesAdvancesInformation2021]. Luckily, the
advent of recent \acr{LLM}s gives us a tool to compress this information
before reception by summarizing texts.

But on the same time generative \acr{AI} drives the increasing rate of
information generation. A human can initiate the generation of a whole
website or book with a single sentence of natural language. Most
recently \acr{AI} agents can, once created, react to triggers in the
digital or real world and automatically generate content. Together with
the information generated by devices in the Internet of Things the
extrapolation of a information duplication every eleven hours
[@ibmglobaltechnologyservicesToxicTerabyte2006] might have become
reality. This is the second thing that changed: algorithms generate,
process and share information too.

What often remains unchanged until today: a lot of the published
information is optimized for human processing, e.g. in \acr{PDF}
documents. Algorithms can be very efficient in information processing,
iff the information is machine readable. Since it is inefficient and
error-prone to let humans encode the information, the field of
information retrieval emerged as a new field of research. \acr{LLM}s can
help to retrieve information, even in a structured format, that can be
used from other algorithms in downstream tasks.

For older sources of information this is the only way possible. For
information shared in future there is another, more direct solution:
additionally providing the information in a machine readable format in
the first place. Otherwise we keep facing the "Last Mile Problem"
[@liAddressingLastMile2023]. Since the format, data is provided in, can
only be changed for the data owned by one self, one has to cope with the
data received, until the needs for machine-readable formats is
successfully communicated to and served by the data owners.

Section \@ref(motivation) describes, that the amount and format of
information provided to the \acr{RHvB} are raising challenges for the
audition process. Section \@ref(objectives) specifies these challenges
to specific real world problem. We derive our research questions from
this use case. Section \@ref(introduction-methodology) gives an overview
of our methodology and the thesis outline can be found in section
\@ref(thesis-outline).

## Motivation {#motivation}

In the last decades the digital transformation accelerated and
"electronic documents have increasingly supplanted paper documents as
the primary medium for information exchange across various industries"
[@zhangDocumentParsingUnveiled2024, p. 1]. And also within the finance
industry a lot of information is stored in (unstructured) digital
formats, i.e. in \acr{PDF} files [@liExtractingFinancialData2023]. This
is not only impeding investment decisions
[@el-hajRetrievingClassifyingAnalysing2020] and academic research
[@jrHowBigData2015] but also regulatory processes
[@liAddressingLastMile2023].

Such regulatory processes may be grounded on the audition reports by the
\acr{RHvB}. The \acr{RHvB} is contributing to the transparent usage of
tax money in Berlin by auditing public administrations and companies,
where the state of Berlin is a shareholder or that get funded with
public money. This prevents corruption and ensures efficient spending
procedures.

In the audition process the employees at \acr{RHvB} are faced with a lot
of information embedded in \acr{PDF} documents. Some are native digital
documents, while other are just scanned paper pages.For the audition of
the UEFA football championship they receive gigabytes of data. To
extract the information necessary to perform the audition is a big
challenge and would require a huge amount of human work force.
Algorithmic assistance is highly welcome.

Since the targets of the audition change frequently, classical rule
based approaches seem to have a rather limited payoff, comparing time
used programming the system and the times it gets used. Thus, leveraging
the flexible automation capabilities through programming by examples
with \acr{LLM}s [@liProgrammingExampleSolved2024] seems promising. The
need for automation is also driven by the impending shortage of
experienced employees due to large number of retirements.

## Objectives {#objectives}

The sixth division at \acr{RHvB} is auditing the companies where Berlin
is a shareholder (see Figure \@ref(fig:beteiligungsunternehmen). They
have to process the balance sheets and profit and loss accounting as a
fundamental information. Those information is provided via the companies
annual reports in form of \acr{PDF} files. Automate the extraction of
those information would be a good starting point for \acr{AI} assisted
information retrieval from \acr{PDF}s for the \acr{RHvB} overall. It
especially is worth the effort invested in a thesis, because exporting
financial data from the 59 companies is a recurring task.

```{r beteiligungsunternehmen, echo=FALSE, out.width="100%", fig.cap="Overview of the 59 companies Berlin holds share at."}
knitr::include_graphics("images/beteiligungsunternehmen.png")
```

The provided annual reports often differ from the publicly available
ones in matter of information granularity and design and are treated as
non public information. For this thesis we use the publicly available
versions to allow a comparison of open-source models with OpenAIs
\acr{GPT} models. We focus on open-source models, because the
information in the non public reports might be confidential. The
Berliner IKT-Richtlinie prohibits the processing of such information at
public clouds and empowers the usage of open-source solutions.

We limit the broad field of information retrieval for this thesis on the
extraction of the assets table, that is part of the balance sheet. To
reach a high degree of automation, we investigate the possibilities of
detecting the table, without having the user to provide the page number
or area, as a second task. We formulate our two main research questions:

```{r, include=knitr::is_html_output(), results='asis', echo=FALSE}
cat("<ol class='rs-questions'><li>How can we use LLMs effectively to locate specific information in a financial report?</li><li>How can we use LLMs effectively to extract these information from the document?</li></ol>")
```

\begin{enumerate}[label={\textbf{Q\theenumi}}]
  \item How can we use LLMs effectively to locate specific information in a financial report?
  \item How can we use LLMs effectively to extract these information from the document?
\end{enumerate}

Since the results of this thesis will be used to create an application
with \acr{HITL} approach, we want to investigate an additional side
research question. Section \@ref(hitl) presents the idea for the
application. The user should check the information extraction results
and resolve issues, the system alone could not handle. But redundant
double work should be minimized. Therefore we formulate our third
research question:

```{r, include=knitr::is_html_output(), results='asis', echo=FALSE}
cat("<ol class='rs-questions' style='--counter: 3;'><li>Can we use additional information from the extraction process, to guide the user which values need to be checked and which can be trusted as they are?</li></ol>")
```

\begin{enumerate}[label={\textbf{Q\theenumi}}]
  \setcounter{enumi}{3}
  \item Can we use additional information from the extraction process, to guide the user which values need to be checked and which can be trusted as they are?
\end{enumerate}

The following section will briefly describe our methodology to
investigate our research questions. The corresponding hypotheses are
formulated in section \@ref(research-questions).

## Methodology {#introduction-methodology}

This thesis is aiming to give a recommendation, how to solve the
described extraction task best. Thus, it is placed in the field of
applied research. We benchmark a broad variety of approaches and conduct
experiments, to identify general predictors for the task performance. We
start our investigation, implementing the framework described by
@liExtractingFinancialData2023. Figure
\@ref(fig:extraction-framework-flow-chart) shows that they describe two
stages, that match with our main research questions.

First, they show different approaches to identify the page, that
contains the searched information, and how to combine those approaches
efficiently. Additionally to a \acr{regex} based and a \acr{LLM} driven
\acr{TOC} based approach, we test a \acr{LLM} driven classification
approach, as well as a term-frequency based ranking approach.

Second, they show that \acr{LLM}s can effectively extract the target
information with the correct prompting strategy. We extend their task by
testing, how well \acr{LLM} can extract multiple values in a single
prompt and designed experiments measure the effect of different
influence factors. Besides model and prompting specific predictors, we
systematically evaluate characteristics of the tabular structure as
well.

Furthermore, we test the upper limits for the extraction performance
with a synthetic dataset, that is free of unknown target row
identifiers. This allows us, to test, if a simple text extract can be
sufficient as input or if additional effort - e.g. performing a document
layout analysis or using specialiced table extraction techniques -
should be invested, to extract the assets tables structure as well.

Our work is also contributing to the question, if the presented
framework is promising on more heterogeneous documents, how open-source
models perform and if the German language of the annual reports may hold
unique challenges.

## Thesis Outline {#thesis-outline}

Chapter \@ref(literature-review) briefly introduces into the theoretical
background of the used concepts and references literature, that is
describing them in depth.

Chapter \@ref(methodology) is describing our research design, research
questions and hypotheses. Separate for our three research questions, it
presents our evaluation and data strategy. It gives an overview about
the experimental setting, including the used evaluation methods and
expected error types .

Chapter \@ref(implementation) describes the hardware the experiments run
on and the software used to implement them. It presents a flow chart and
description of the data processing workflow.

Chapter \@ref(results) briefly presents the results for the three
investigated research questions. Detailed descriptions, how the results
are obtained can be found in the appendix.

Chapter \@ref(discussion) discusses the results. It interprets the
results in regard to the research questions and hypotheses. It contains
the error analysis. It shows the limitations of this study and names
what is not covered yet. It gives an outlook, on how we will proceed
with the results of this thesis, to solve the real life problem.

Chapter \@ref(conclusion) summarizes the answers on our research
questions.

## Summary

This chapter, showed the challenges that result from the ever growing
amount of information to process and the hurdles that
non-machine-readable data is placing on the way to use algorithms, to
handle the information overflow. It described the specific problem we
tackle with this thesis of extracting financial information from annual
reports, to prepare the audition processes at \acr{RHvB}. We formulated
our research questions, sketched our methodology to investigate them and
gave an outlook on the subsequent chapters.

## To place in chapters above

XBRL reports instead of PDFs? employees need to know, that they exist
and how to work with those

It is important to get numeric values totally accurate; numeric values
are difficult to handle for langauge models

Research questions and hypothesss

Q1: Can a \acr{LLM} be used to efficiently extract financial information
from German annual reports? Q2. Can LLMs be used to identify the page of
interest automatically?

Q3: Can confidence scores be used to head up the human in the loop on
which results to double check? (How can sources of the automatic
extraction being communicated down stream in order to make double
checking easy before making decisions?) Q4: Can contextual information
from similar documents reduce errors made during table extraction? Q5:
What are characteristics of financial tables that make it hard for LLMs
to identify / extract them? (How does the length and complexity of
financial documents (e.g., multi-column layouts, nested tables) affect
table extraction performance?)

missing law to access digital data and no law to choose the format of
the data [extensible Business Reporting Language](https://de.xbrl.org/)
as a standard changing from HGB to IFSR

## Unstrukturierte Daten

-   Beispielbilder

### Portable Document Format

-   print optimized
-   Table structure information gets lost
-   Bild und Textextract
-   see Erics thesis ;)
