# Results

```{r page-identification-data-loading, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
# data <- read.csv("../benchmark_truth/aktiva_passiva_guv_table_pages_no_ocr.csv")
# 
# # pdf_files <- data$filepath %>% unique()
# # 
# # # Initialize a counter for the total page count
# # total_pages <- 0
# # 
# # # Loop through each PDF file to count pages
# # for (pdf_file in pdf_files) {
# #   # Use the pdftools package to count pages
# #   total_pages <- total_pages + pdftools::pdf_info(pdf_file)$pages
# # }
# 
# # Split the "type" column by '&' and explode it into multiple rows
# data_unnested <- data %>%
#   mutate(type = strsplit(as.character(type), "&")) %>%
#   unnest(type)
# 
# num_tables <- data_unnested %>% 
#   nrow()
# 
# # Get a list of all .json files in the folder
# json_files <- list.files("../benchmark_results/page_identification/", pattern = "\\.json$", full.names = TRUE)
# 
# # Initialize an empty dataframe to store results
# results_df <- data.frame(
#   package = character(),
#   method = character(),
#   # acc = numeric(),
#   precision = numeric(),
#   recall = numeric(),
#   F1 = numeric(),
#   runtime_in_s = numeric(),
#   stringsAsFactors = FALSE
# )
# 
# # Loop through each .json file
# for (file in json_files) {
#   # Read the JSON file
#   json_data <- fromJSON(file)
#   
#   # Extract the required values
#   correct_df <- as.data.frame(fromJSON(json_data$correct)) # %>% filter(type == 'Aktiva')
#   wrong_df <- as.data.frame(fromJSON(json_data$wrong)) # %>% filter(type == 'Aktiva')
#   missing_df <- as.data.frame(fromJSON(json_data$missing)) # %>% filter(type == 'Aktiva')
#   
#   filename <- basename(file)
#   package <- strsplit(filename, "_")[[1]][1]
#   method <- gsub("\\.json$", "", paste(strsplit(filename, "_")[[1]][-1], collapse = " "))
#   
#   num_true_pos <- num_correct <- nrow(correct_df)
#   num_false_pos <- num_wrong <- nrow(wrong_df)
#   num_false_neg <- num_tables-num_correct
#   num_true_neg <- 3*total_pages-num_true_pos-num_false_pos-num_false_neg
#   num_missing <- nrow(missing_df)
#   runtime <- round(json_data$runtime, 2)
#   acc = round((num_true_pos+num_true_neg)/(3*total_pages),2)
#   precision = round(num_true_pos/(num_true_pos+num_false_pos),2)
#   recall = round(num_true_pos/(num_true_pos+num_false_neg),2)
#   F1 = round(2*precision*recall/(precision+recall),2)
#   
#   # Append the values to the results dataframe
#   results_df <- results_df %>%
#     add_row(
#       package = package,
#       method = method,
#       # acc = acc,
#       precision = precision,
#       recall = recall,
#       F1 = F1#,
#       # runtime_in_s = runtime
#     )
# }
# 
# results_df <- results_df %>%
#   group_by(method) %>%
#   summarise(
#     precision_mean = mean(precision, na.rm = TRUE),
#     precision_sd = sd(precision, na.rm = TRUE),
#     recall_mean = mean(recall, na.rm = TRUE),
#     recall_sd = sd(recall, na.rm = TRUE),
#     F1_mean = mean(F1, na.rm = TRUE),
#     F1_sd = sd(F1, na.rm = TRUE)
#   ) %>%
#   pivot_longer(
#     cols = c(precision_mean, precision_sd, recall_mean, recall_sd, F1_mean, F1_sd),
#     names_to = c("metric", "stat"),
#     names_pattern = "(.*)_(mean|sd)"
#   ) %>%
#   pivot_wider(
#     names_from = metric,
#     values_from = value
#   ) %>% 
#   mutate_if(is.numeric, ~round(., 3))

source("page_identification_regex.R")
```

## Page identification

As described in \@ref(text-extraction-benchmark) open source libraries have been used to extract the text from the annual reports.

### Baseline: Regex {#regex-page-identification}

Building a sound regular expression often is an iterative process. In a first approach a very simple one was implemented. 

The regular expressions can be found in the appendix (see \@ref(regex-page-identification)).

```{python, eval=FALSE, echo = knitr::is_html_output()}
simple_regex_patterns = {
    "Aktiva": [
        r"aktiva",
        r"((20\d{2}).*(20\d{2}))"
    ],
    "Passiva": [
        r"passiva",
        r"((20\d{2}).*(20\d{2}))"
    ],
    "GuV": [
        r"gewinn",
        r"verlust",
        r"rechnung",
        r"((20\d{2}).*(20\d{2}))"
    ]
}
```

```{r display-results-df, echo=FALSE, results="asis"}
metric_summaries["Aktiva"][[1]] %>%
  mutate_if(
    is.numeric, 
    ~ifelse(
      . == max(., na.rm = TRUE),
      paste0("**", ., "**"),
      .
    )
  ) %>% arrange(desc(method)) %>% 
  render_table(alignment="llrrr", caption="Comparing page identification metrics for different regular expressions for classification task 'Aktiva'", ref="display-results-df")
```

\@ref(tab:display-results-df)

### Advanced techniques

#### Table of Contents understanding

* top 1
* top k

* toc analysis
* cleaned measures

#### Classification with LLMs {#llm-page-identification}

##### Binary classification

* f1
* multiple models
* best model detail (different methods / settings)

##### Multi classification

* f1
* multiple models
* best model detail (different methods / settings)

### Comparison

#### F1

#### Energy usage and runtime

## Table extraction