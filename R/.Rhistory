method_order <- c("top_n_rag_examples", "n_random_examples", "top_n_rag_examples_out_of_sample", "static_example", "zero_shot" )
norm_factors <- read_csv("../benchmark_jobs/page_identification/gpu_benchmark/runtime_factors_real_table_extraction.csv") %>%
mutate(
model_name = model_name %>% str_replace("/", "_")
)
norm_factors_few_examples <- norm_factors %>% filter((str_ends(filename, "binary.yaml") | str_ends(filename, "multi.yaml") | str_ends(filename, "vllm_batched.yaml")))
df_real_table_extraction <- df_real_table_extraction %>% left_join(
norm_factors_few_examples %>% mutate(model_name = gsub("^[^_]+_", "", model_name)) %>% select(model_name, parameter_count, normalization_factor),
by = c("model" = "model_name")
) %>% mutate(normalized_runtime = round(runtime*normalization_factor, 0))
df_overview <- bind_rows(df_real_table_extraction, df_real_table_extraction_azure) %>%
filter(out_of_company != TRUE | is.na(out_of_company), n_examples <= 5) %>%
filter(model %in% model_by_size) %>%
filter(n_examples != 2) %>%
mutate(
model = factor(model, levels = model_by_size),
method_family = factor(method_family, levels = method_order),
n_examples = fct_rev(ordered(paste("n =", n_examples)))
)
units_real_tables <- read_csv("../benchmark_truth/real_tables_extended/table_characteristics_more_examples.csv") %>% mutate(
filepath = paste0('/pvc/benchmark_truth/real_tables_extended/', company, '__', filename),
T_EUR = (T_in_year + T_in_previous_year)>0,
T_EUR_both = (T_in_year + T_in_previous_year)>1
) %>% select(filepath, T_EUR, T_EUR_both)
df_real_table_extraction_synth <- df_real_table_extraction_synth %>% left_join(units_real_tables)
df_synth_table_extraction <- readRDS("data_storage/synth_table_extraction_llm.rds") %>%
mutate(model = if_else(model == "Qwen3-235B-A22B-Instruct-2507", "Qwen3-235B-A22B-Instruct-2507-FP8", model)) %>%
sample_frac(size = .05) %>%
filter(!model %in% c("deepseek-ai_DeepSeek-R1-Distill-Qwen-32B", 'google_gemma-3n-E4B-it')) %>%
mutate(
model = gsub("^[^_]+_", "", model)
)
norm_factors <- read_csv("../benchmark_jobs/page_identification/gpu_benchmark/runtime_factors_synth_table_extraction.csv") %>%
mutate(
model_name = model_name %>% str_replace("/", "_")
)
norm_factors_few_examples <- norm_factors %>% filter((str_ends(filename, "binary.yaml") | str_ends(filename, "multi.yaml") | str_ends(filename, "vllm_batched.yaml")))
df_synth_table_extraction <- df_synth_table_extraction %>% left_join(
norm_factors_few_examples %>% mutate(model_name = gsub("^[^_]+_", "", model_name)) %>% select(model_name, parameter_count, normalization_factor),
by = c("model" = "model_name")
) %>% mutate(
normalized_runtime = normalization_factor * runtime
)
df_overview_synth <- df_synth_table_extraction %>%
mutate(
model = factor(model, levels = model_by_size),
method_family = factor(method_family, levels = method_order),
n_examples = fct_rev(ordered(paste("n =", n_examples)))
)
# synth
zero_shot_stars_synth <- df_synth_table_extraction %>% filter(method == "zero_shot") %>% group_by(model) %>%
reframe(median_total = median(percentage_correct_total, na.rm = TRUE), median_num = median(percentage_correct_numeric, na.rm = TRUE), median_F1 = median(NA_F1, na.rm = TRUE)) %>% filter(median_total>synth_table_extraction_regex_total_performance_median, median_num>synth_table_extraction_regex_num_performance_median, median_F1>synth_table_extraction_regex_NA_F1_median)
static_example_stars_synth <- df_synth_table_extraction %>% filter(method == "static_example") %>% group_by(model) %>%
reframe(median_total = median(percentage_correct_total, na.rm = TRUE), median_num = median(percentage_correct_numeric, na.rm = TRUE), median_F1 = median(NA_F1, na.rm = TRUE)) %>% filter(median_total>synth_table_extraction_regex_total_performance_median, median_num>synth_table_extraction_regex_num_performance_median, median_F1>synth_table_extraction_regex_NA_F1_median)
underperformer_synth <- df_synth_table_extraction %>% filter(!method %in% c('zero_shot', 'static_example')) %>% group_by(model, method) %>%
reframe(median_total = median(percentage_correct_total, na.rm = TRUE), median_num = median(percentage_correct_numeric, na.rm = TRUE), median_F1 = median(NA_F1, na.rm = TRUE)) %>% filter(any(median_total<synth_table_extraction_regex_total_performance_median, median_num<synth_table_extraction_regex_num_performance_median, median_F1<synth_table_extraction_regex_NA_F1_median)) %>% arrange(median_total) %>% slice_head(n = 1)
super_underperformer_synth <- df_synth_table_extraction %>% filter(!method %in% c('zero_shot', 'static_example'), n_examples>1) %>% group_by(model, method) %>%
reframe(median_total = median(percentage_correct_total, na.rm = TRUE), median_num = median(percentage_correct_numeric, na.rm = TRUE), median_F1 = median(NA_F1, na.rm = TRUE)) %>% group_by(model) %>% filter(any(median_total<synth_table_extraction_regex_total_performance_median, median_num<synth_table_extraction_regex_num_performance_median, median_F1<synth_table_extraction_regex_NA_F1_median)) %>% arrange(median_total) %>% slice_head(n = 1)
df_synth_top_performance <- df_synth_table_extraction %>% group_by(model, method) %>%
filter(input_format == "pdf") %>%
mutate(
median_total = median(percentage_correct_total, na.rm = TRUE),
mean_total = mean(percentage_correct_total, na.rm = TRUE),
median_runtime = median(normalized_runtime, na.rm = TRUE)
) %>%
# arrange(desc(median_total)) %>%
group_by(model_family) %>% slice_max(n = 1, mean_total, with_ties = FALSE) %>%
select(model_family, model, method_family, n_examples, mean_total, median_total, median_runtime) %>%
arrange(desc(mean_total)) %>%
mutate(
mean_total = round(mean_total, 3),
median_total = round(median_total, 3)
)
df_synth_top_performance_small <- df_synth_table_extraction %>%
filter(input_format == "pdf") %>%
filter(parameter_count < 17) %>%
group_by(model, method) %>%
mutate(
median_total = median(percentage_correct_total, na.rm = TRUE),
mean_total = mean(percentage_correct_total, na.rm = TRUE),
median_runtime = median(normalized_runtime, na.rm = TRUE)
) %>%
# arrange(desc(median_total)) %>%
group_by(model_family) %>% slice_max(n = 1, mean_total, with_ties = FALSE) %>%
select(model_family, model, method_family, n_examples, mean_total, median_total, median_runtime) %>%
arrange(desc(mean_total)) %>%
mutate(
mean_total = round(mean_total, 3),
median_total = round(median_total, 3)
)
n_better_as_regex <- df_synth_table_extraction %>% group_by(model, method) %>%
filter(input_format == "pdf") %>%
summarise(median_total = median(percentage_correct_total, na.rm = TRUE)) %>%
arrange(desc(median_total))  %>%
mutate(
better_than_regex =  median_total>synth_table_extraction_regex_total_performance_median
) %>% group_by(better_than_regex) %>% summarise(n())
n_better_as_regex_families <- df_synth_top_performance %>% mutate(
better_than_regex =  median_total>synth_table_extraction_regex_total_performance_median
) %>% group_by(better_than_regex) %>% summarise(n())
n_synth_tables <- list.files(
"../benchmark_truth/synthetic_tables/separate_files/final/"
) %>% length()
n_synth_table_extraction <- list.files(
"../benchmark_results/table_extraction/llm/final/synth_tables/"
) %>% length()
# confidence_vs_truth_synth <- df_synth_table_extraction %>%
#   # filter(method_family %in% c("top_n_rag_examples", "n_random_examples")) %>%
#   filter(model %in% c("Ministral-8B-Instruct-2410", "Qwen3-8B", "Qwen3-235B-A22B-Instruct-2507-FP8")) %>%
#   group_by(method, model, loop) %>% mutate(
#     mean_percentage_correct_total = mean(percentage_correct_total, na.rm=TRUE), .before = 1,
#     respect_units = !ignore_units
#   ) %>% group_by(respect_units, model, filepath) %>%
#   # arrange(desc(mean_percentage_correct_total)) %>%
#   slice_max(mean_percentage_correct_total, n = 1, with_ties = FALSE) %>%
#   mutate(predictions_processed = map(predictions, ~{
#     .x %>%
#       select(-"_merge") %>%
#       mutate(
#         match = (year_truth == year_result) | (is.na(year_truth) & is.na(year_result)),
#         confidence = confidence_this_year,
#         truth_NA = is.na(year_truth),
#         predicted_NA = is.na(year_result),
#         .before = 4
#       ) %>% nest(
#         tuple_year = c(match, confidence, truth_NA, predicted_NA)
#       ) %>%
#       mutate(
#         confidence = confidence_previous_year,
#         match = (previous_year_truth == previous_year_result) | (is.na(previous_year_truth) & is.na(previous_year_result)),
#         truth_NA = is.na(previous_year_truth),
#         predicted_NA = is.na(previous_year_result),
#         .before = 4
#       ) %>% nest(
#         tuple_previous_year = c(match, confidence, truth_NA, predicted_NA)
#       ) %>% select(
#         -c(year_truth, previous_year_truth, year_result, previous_year_result,
#            confidence_this_year, confidence_previous_year)
#       ) %>%
#       pivot_longer(-c("E1", "E2", "E3")) %>%
#       unnest(cols = value) %>% mutate(
#         match = if_else(is.na(match), FALSE, match)
#       )
#   })) %>%
#   unnest(predictions_processed) %>% mutate(
#     match = factor(match, levels = c(F, T)),
#     truth_NA = factor(truth_NA, levels = c(F, T))
#   )
#
# confidence_intervals_synth <- confidence_vs_truth_synth %>% #rename(confidence = confidence_score) %>%
#   mutate(
#     conf_interval = cut(confidence, breaks = seq(0, 1, by = 0.05), include.lowest = TRUE),
#     conf_center = as.numeric(sub("\\((.+),(.+)\\]", "\\1", levels(conf_interval))[conf_interval]) + 0.025
#   ) %>%
#   group_by(conf_center, predicted_NA, model, respect_units) %>%
#   summarise(
#     n_true = sum(match == TRUE, na.rm = TRUE),
#     n_false = sum(match == FALSE, na.rm = TRUE),
#     total = n_true + n_false,
#     chance_false = if_else(total > 0, n_false / total * 100, NA_real_),
#     chance_zero = chance_false == 0,
#     chance_below_1 = chance_false < 1,
#     chance_low = if_else(chance_zero, 0, if_else(chance_below_1, 1, 2)),
#     chance_low = factor(chance_low, levels = c(0,1,2), labels = c("equls 0 %", "below 1 %", "more"))
#   ) %>% group_by(predicted_NA, model, respect_units) %>% mutate(
#     perc = total/sum(total)*100
#   ) %>% ungroup() %>%
#   mutate(
#     chance_false_interval = cut(
#       chance_false,
#       breaks = c(0, 1, 2, 4, 8, 16, 32, 64, Inf),
#       labels = c("[0,1)", "[1,2)", "[2,4)", "[4,8)",
#                  "[8,16)", "[16,32)", "[32,64)", "[64,Inf)"),
#       right = FALSE,
#       ordered_result = TRUE
#     ),
#   )
df_real_table_extraction %>% select(model) %>%
mutate(task = "real tables") %>%
bind_rows(
df_synth_table_extraction %>% select(model) %>%
mutate(task = "synth tables")
) %>%
bind_rows(
df_real_table_extraction_synth %>% select(model) %>%
mutate(task = "hybrid")
) %>%
bind_rows(
df_real_table_extraction_azure %>% select(model) %>%
mutate(task = "azure")
)
df_real_table_extraction %>% select(model) %>%
mutate(task = "real tables") %>%
bind_rows(
df_synth_table_extraction %>% select(model) %>%
mutate(task = "synth tables")
) %>%
bind_rows(
df_real_table_extraction_synth %>% select(model) %>%
mutate(task = "hybrid")
) %>%
bind_rows(
df_real_table_extraction_azure %>% select(model) %>%
mutate(task = "azure")
) %>% unique()
df_real_table_extraction %>% select(model) %>%
mutate(task = "real tables") %>%
bind_rows(
df_synth_table_extraction %>% select(model) %>%
mutate(task = "synth tables")
) %>%
bind_rows(
df_real_table_extraction_synth %>% select(model) %>%
mutate(task = "hybrid")
) %>%
bind_rows(
df_real_table_extraction_azure %>% select(model) %>%
mutate(task = "azure")
) %>% unique() %>%
pivot_wider(names_from = task)
df_real_table_extraction %>% select(model) %>%
mutate(task = "real tables") %>%
bind_rows(
df_synth_table_extraction %>% select(model) %>%
mutate(task = "synth tables")
) %>%
bind_rows(
df_real_table_extraction_synth %>% select(model) %>%
mutate(task = "hybrid")
) %>%
bind_rows(
df_real_table_extraction_azure %>% select(model) %>%
mutate(task = "azure")
) %>% unique() %>%
mutate(used = "X") %>%
pivot_wider(names_from = task, values_from = used)
# bind_rows(
#   df_real_table_extraction_azure %>% select(model) %>%
#     mutate(task = "azure")
# ) %>%
df_real_table_extraction %>% select(model) %>%
mutate(task = "real tables") %>%
bind_rows(
df_synth_table_extraction %>% select(model) %>%
mutate(task = "synth tables")
) %>%
bind_rows(
df_real_table_extraction_synth %>% select(model) %>%
mutate(task = "hybrid")
) %>%
# bind_rows(
#   df_real_table_extraction_azure %>% select(model) %>%
#     mutate(task = "azure")
# ) %>%
unique() %>%
mutate(used = "X") %>%
pivot_wider(names_from = task, values_from = used)
df_real_table_extraction %>% select(model) %>%
mutate(task = "real tables") %>%
bind_rows(
df_synth_table_extraction %>% select(model) %>%
mutate(task = "synth tables")
) %>%
bind_rows(
df_real_table_extraction_synth %>% select(model) %>%
mutate(task = "hybrid")
) %>%
# bind_rows(
#   df_real_table_extraction_azure %>% select(model) %>%
#     mutate(task = "azure")
# ) %>%
unique() %>%
mutate(used = "X") %>%
pivot_wider(names_from = task, values_from = used) %>%
mutate_all(~if_else(is.na(.), "", .))
df_real_table_extraction %>% select(model) %>%
mutate(task = "real tables") %>%
bind_rows(
df_synth_table_extraction %>% select(model) %>%
mutate(task = "synth tables")
) %>%
bind_rows(
df_real_table_extraction_synth %>% select(model) %>%
mutate(task = "hybrid")
) %>%
# bind_rows(
#   df_real_table_extraction_azure %>% select(model) %>%
#     mutate(task = "azure")
# ) %>%
unique() %>%
mutate(used = "X") %>%
pivot_wider(names_from = task, values_from = used) %>%
mutate_all(~if_else(is.na(.), "", .)) %>% write_csv("data_storage/model_usage_extraction.csv")
read_csv("data_storage/model_usage_extraction.csv") %>%
render_table(alignment="llr", caption="Overview of benchmarked LLMs for the extraction tasks.", ref = opts_current$get("label"))
read_csv("data_storage/model_usage_extraction.csv") %>%
render_table(alignment="lccc", caption="Overview of benchmarked LLMs for the extraction tasks.", ref = opts_current$get("label"))
read_csv("data_storage/model_usage_extraction.csv") %>%
mutate_all(~if_else(is.na(.), "", .)) %>%
render_table(alignment="lccc", caption="Overview of benchmarked LLMs for the extraction tasks.", ref = opts_current$get("label"))
df_real_table_extraction %>% select(model_family, model) %>%
mutate(task = "real tables") %>%
bind_rows(
df_synth_table_extraction %>% select(model_family, model) %>%
mutate(task = "synth tables")
) %>%
bind_rows(
df_real_table_extraction_synth %>% select(model_family, model) %>%
mutate(task = "hybrid")
) %>%
# bind_rows(
#   df_real_table_extraction_azure %>% select(model_family, model) %>%
#     mutate(task = "azure")
# ) %>%
unique() %>%
mutate(used = "X") %>%
pivot_wider(names_from = task, values_from = used) %>%
write_csv("data_storage/model_usage_extraction.csv")
read_csv("data_storage/model_usage_extraction.csv") %>%
mutate_all(~if_else(is.na(.), "", .)) %>%
render_table(alignment="lccc", caption="Overview of benchmarked LLMs for the extraction tasks.", ref = opts_current$get("label"))
norm_factors_few_examples
df_real_table_extraction %>% select(model_family, model) %>%
mutate(task = "real tables") %>%
bind_rows(
df_synth_table_extraction %>% select(model_family, model) %>%
mutate(task = "synth tables")
) %>%
bind_rows(
df_real_table_extraction_synth %>% select(model_family, model) %>%
mutate(task = "hybrid")
) %>%
# bind_rows(
#   df_real_table_extraction_azure %>% select(model_family, model) %>%
#     mutate(task = "azure")
# ) %>%
unique() %>%
mutate(used = "X") %>%
pivot_wider(names_from = task, values_from = used) %>%
left_join(
norm_factors_few_examples %>% select(model, parameter_count)
)
df_real_table_extraction %>% select(model_family, model) %>%
mutate(task = "real tables") %>%
bind_rows(
df_synth_table_extraction %>% select(model_family, model) %>%
mutate(task = "synth tables")
) %>%
bind_rows(
df_real_table_extraction_synth %>% select(model_family, model) %>%
mutate(task = "hybrid")
) %>%
# bind_rows(
#   df_real_table_extraction_azure %>% select(model_family, model) %>%
#     mutate(task = "azure")
# ) %>%
unique() %>%
mutate(used = "X") %>%
pivot_wider(names_from = task, values_from = used) %>%
left_join(
norm_factors_few_examples %>% select(model_name, parameter_count)
)
df_real_table_extraction %>% select(model_family, model) %>%
mutate(task = "real tables") %>%
bind_rows(
df_synth_table_extraction %>% select(model_family, model) %>%
mutate(task = "synth tables")
) %>%
bind_rows(
df_real_table_extraction_synth %>% select(model_family, model) %>%
mutate(task = "hybrid")
) %>%
# bind_rows(
#   df_real_table_extraction_azure %>% select(model_family, model) %>%
#     mutate(task = "azure")
# ) %>%
unique() %>%
mutate(used = "X") %>%
pivot_wider(names_from = task, values_from = used) %>%
left_join(
norm_factors_few_examples %>%
mutate(model = gsub("^[^_]+_", "", model_name)) %>%
select(model, parameter_count),
)
norm_factors <- read_csv("../benchmark_jobs/page_identification/gpu_benchmark/runtime_factors_real_table_extraction.csv") %>%
mutate(
model_name = model_name %>% str_replace("/", "_")
)
norm_factors_few_examples <- norm_factors %>% filter((str_ends(filename, "binary.yaml") | str_ends(filename, "multi.yaml") | str_ends(filename, "vllm_batched.yaml")))
df_real_table_extraction %>% select(model_family, model) %>%
mutate(task = "real tables") %>%
bind_rows(
df_synth_table_extraction %>% select(model_family, model) %>%
mutate(task = "synth tables")
) %>%
bind_rows(
df_real_table_extraction_synth %>% select(model_family, model) %>%
mutate(task = "hybrid")
) %>%
# bind_rows(
#   df_real_table_extraction_azure %>% select(model_family, model) %>%
#     mutate(task = "azure")
# ) %>%
unique() %>%
mutate(used = "X") %>%
pivot_wider(names_from = task, values_from = used) %>%
left_join(
norm_factors_few_examples %>%
mutate(model = gsub("^[^_]+_", "", model_name)) %>%
select(model, parameter_count),
)
df_real_table_extraction %>% select(model_family, model) %>%
mutate(task = "real tables") %>%
bind_rows(
df_synth_table_extraction %>% select(model_family, model) %>%
mutate(task = "synth tables")
) %>%
bind_rows(
df_real_table_extraction_synth %>% select(model_family, model) %>%
mutate(task = "hybrid")
) %>%
# bind_rows(
#   df_real_table_extraction_azure %>% select(model_family, model) %>%
#     mutate(task = "azure")
# ) %>%
unique() %>%
mutate(used = "X") %>%
left_join(
norm_factors_few_examples %>%
mutate(model = gsub("^[^_]+_", "", model_name)) %>%
select(model, parameter_count),
) %>%
pivot_wider(names_from = task, values_from = used) # %>%
df_real_table_extraction %>% select(model_family, model) %>%
mutate(task = "real tables") %>%
bind_rows(
df_synth_table_extraction %>% select(model_family, model) %>%
mutate(task = "synth tables")
) %>%
bind_rows(
df_real_table_extraction_synth %>% select(model_family, model) %>%
mutate(task = "hybrid")
) %>%
# bind_rows(
#   df_real_table_extraction_azure %>% select(model_family, model) %>%
#     mutate(task = "azure")
# ) %>%
unique() %>%
mutate(used = "X") %>%
left_join(
norm_factors_few_examples %>%
mutate(model = gsub("^[^_]+_", "", model_name)) %>%
select(model, parameter_count),
) %>%
pivot_wider(names_from = task, values_from = used) %>%
write_csv("data_storage/model_usage_extraction.csv")
read_csv("data_storage/model_usage_extraction.csv") %>%
mutate_all(~if_else(is.na(.), "", .)) %>%
render_table(alignment="llrccc", caption="Overview of benchmarked LLMs for the extraction tasks.", ref = opts_current$get("label"))
read_csv("data_storage/model_usage_extraction.csv") %>%
mutate_if(is.character, ~if_else(is.na(.), "", .)) %>%
render_table(alignment="llrccc", caption="Overview of benchmarked LLMs for the extraction tasks.", ref = opts_current$get("label"))
df_real_table_extraction %>% select(model_family, model) %>%
mutate(task = "real tables") %>%
bind_rows(
df_synth_table_extraction %>% select(model_family, model) %>%
mutate(task = "synth tables")
) %>%
bind_rows(
df_real_table_extraction_synth %>% select(model_family, model) %>%
mutate(task = "hybrid")
) %>%
# bind_rows(
#   df_real_table_extraction_azure %>% select(model_family, model) %>%
#     mutate(task = "azure")
# ) %>%
unique() %>%
mutate(used = "X") %>%
left_join(
norm_factors_few_examples %>%
mutate(model = gsub("^[^_]+_", "", model_name)) %>%
select(model, parameter_count),
) %>%
pivot_wider(names_from = task, values_from = used) %>%
unique() %>%
write_csv("data_storage/model_usage_extraction.csv")
read_csv("data_storage/model_usage_extraction.csv") %>%
mutate_if(is.character, ~if_else(is.na(.), "", .)) %>%
render_table(alignment="llrccc", caption="Overview of benchmarked LLMs for the extraction tasks.", ref = opts_current$get("label"))
read_csv("data_storage/model_usage_extraction.csv") %>%
arrange(model_family, model) %>%
mutate_if(is.character, ~if_else(is.na(.), "", .)) %>%
render_table(alignment="llrccc", caption="Overview of benchmarked LLMs for the extraction tasks.", ref = opts_current$get("label"))
read_csv("data_storage/model_usage_extraction.csv") %>%
arrange(tolower(model_family), model) %>%
mutate_if(is.character, ~if_else(is.na(.), "", .)) %>%
render_table(alignment="llrccc", caption="Overview of benchmarked LLMs for the extraction tasks.", ref = opts_current$get("label"))
read_csv("data_storage/model_usage_extraction.csv") %>%
arrange(tolower(model_family), tolower(model)) %>%
mutate_if(is.character, ~if_else(is.na(.), "", .)) %>%
render_table(alignment="llrccc", caption="Overview of benchmarked LLMs for the extraction tasks.", ref = opts_current$get("label"))
target_type <- "Aktiva"
df_filtered <- df_binary %>% filter(
classification_type == target_type, n_examples<=3
) %>%
arrange(desc(f1_score))
df_temp <- df_filtered[1,"predictions"][[1]][[1]] %>% as_tibble()
df_flipped_score <- df_temp %>%
mutate(
confidence_score = if_else(predicted_type == "no", 1-confidence_score, confidence_score),
is_aktiva = str_detect(type, target_type)
)
