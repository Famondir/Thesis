calc_metrics <- function(classification_type) {
# Initialize an empty dataframe to store results
results_df <- data.frame(
package = character(),
method = character(),
classification_type = character(),
true_pos = numeric(),
false_pos = numeric(),
false_neg = numeric(),
true_neg = numeric(),
missing = numeric(),
acc = numeric(),
precision = numeric(),
recall = numeric(),
F1 = numeric(),
runtime_in_s = numeric(),
stringsAsFactors = FALSE
)
# Loop through each .json file
for (file in json_files) {
# browser()
json_data <- fromJSON(file)
# Extract the required values
correct_df <- as.data.frame(fromJSON(json_data$correct)) %>% filter(type == classification_type)
wrong_df <- as.data.frame(fromJSON(json_data$wrong)) %>% filter(type == classification_type)
missing_df <- as.data.frame(fromJSON(json_data$missing)) %>% filter(type == classification_type)
filename <- basename(file)
package <- strsplit(filename, "_")[[1]][1]
method <- gsub("\\.json$", "", paste(strsplit(filename, "_")[[1]][-1], collapse = " "))
num_tables <- data_unnested %>% filter(type == classification_type) %>% nrow()
num_true_pos <- num_correct <- nrow(correct_df)
num_false_pos <- num_wrong <- nrow(wrong_df)
num_false_neg <- num_tables-num_correct
num_true_neg <- total_pages-num_true_pos-num_false_pos-num_false_neg
num_missing <- nrow(missing_df)
runtime <- round(json_data$runtime, 2)
acc = round((num_true_pos+num_true_neg)/(total_pages),2)
precision = round(num_true_pos/(num_true_pos+num_false_pos),2)
recall = round(num_true_pos/(num_true_pos+num_false_neg),2)
F1 = round(2*precision*recall/(precision+recall),2)
# Append the values to the results dataframe
results_df <- results_df %>%
add_row(
package = package,
method = method,
classification_type = classification_type,
true_pos = num_true_pos,
false_pos = num_false_pos,
false_neg = num_false_neg,
true_neg = num_true_neg,
missing = num_missing,
acc = acc,
precision = precision,
recall = recall,
F1 = F1,
runtime_in_s = runtime
)
}
return(results_df %>% as_tibble())
}
metrics <- list()
for (type in c('Aktiva', 'Passiva', 'GuV')) {
metrics[type] <- list(calc_metrics(type))
}
metric_summaries <- list()
for (df in metrics) {
type <- df$classification_type[[1]]
results_df <- df %>%
group_by(method) %>%
summarise(
precision_mean = mean(precision, na.rm = TRUE),
precision_sd = sd(precision, na.rm = TRUE),
recall_mean = mean(recall, na.rm = TRUE),
recall_sd = sd(recall, na.rm = TRUE),
F1_mean = mean(F1, na.rm = TRUE),
F1_sd = sd(F1, na.rm = TRUE)
) %>%
pivot_longer(
cols = c(precision_mean, precision_sd, recall_mean, recall_sd, F1_mean, F1_sd),
names_to = c("metric", "stat"),
names_pattern = "(.*)_(mean|sd)"
) %>%
pivot_wider(
names_from = metric,
values_from = value
) %>%
mutate_if(is.numeric, ~round(., 3))
metric_summaries[type] <- list(results_df)
}
metric_summaries
metrics
metrics$method %>% unique()
metrics$Aktiva$method %>% unique()
json_files
metrics
metrics$Aktiva$method %>% unique()
# Get a list of all .json files in the folder
json_files <- list.files("../benchmark_results/page_identification/", pattern = "regex\\.json$", full.names = TRUE)
calc_metrics <- function(classification_type) {
# Initialize an empty dataframe to store results
results_df <- data.frame(
package = character(),
method = character(),
classification_type = character(),
true_pos = numeric(),
false_pos = numeric(),
false_neg = numeric(),
true_neg = numeric(),
missing = numeric(),
acc = numeric(),
precision = numeric(),
recall = numeric(),
F1 = numeric(),
runtime_in_s = numeric(),
stringsAsFactors = FALSE
)
# Loop through each .json file
for (file in json_files) {
# browser()
print(file)
json_data <- fromJSON(file)
# Extract the required values
correct_df <- as.data.frame(fromJSON(json_data$correct)) %>% filter(type == classification_type)
wrong_df <- as.data.frame(fromJSON(json_data$wrong)) %>% filter(type == classification_type)
missing_df <- as.data.frame(fromJSON(json_data$missing)) %>% filter(type == classification_type)
filename <- basename(file)
package <- strsplit(filename, "_")[[1]][1]
method <- gsub("\\.json$", "", paste(strsplit(filename, "_")[[1]][-1], collapse = " "))
num_tables <- data_unnested %>% filter(type == classification_type) %>% nrow()
num_true_pos <- num_correct <- nrow(correct_df)
num_false_pos <- num_wrong <- nrow(wrong_df)
num_false_neg <- num_tables-num_correct
num_true_neg <- total_pages-num_true_pos-num_false_pos-num_false_neg
num_missing <- nrow(missing_df)
runtime <- round(json_data$runtime, 2)
acc = round((num_true_pos+num_true_neg)/(total_pages),2)
precision = round(num_true_pos/(num_true_pos+num_false_pos),2)
recall = round(num_true_pos/(num_true_pos+num_false_neg),2)
F1 = round(2*precision*recall/(precision+recall),2)
# Append the values to the results dataframe
results_df <- results_df %>%
add_row(
package = package,
method = method,
classification_type = classification_type,
true_pos = num_true_pos,
false_pos = num_false_pos,
false_neg = num_false_neg,
true_neg = num_true_neg,
missing = num_missing,
acc = acc,
precision = precision,
recall = recall,
F1 = F1,
runtime_in_s = runtime
)
}
return(results_df %>% as_tibble())
}
metrics <- list()
for (type in c('Aktiva', 'Passiva', 'GuV')) {
metrics[type] <- list(calc_metrics(type))
}
# Get a list of all .json files in the folder
json_files <- list.files("../benchmark_results/page_identification/", pattern = "regex(_exhaustive)?\\.json$", full.names = TRUE)
calc_metrics <- function(classification_type) {
# Initialize an empty dataframe to store results
results_df <- data.frame(
package = character(),
method = character(),
classification_type = character(),
true_pos = numeric(),
false_pos = numeric(),
false_neg = numeric(),
true_neg = numeric(),
missing = numeric(),
acc = numeric(),
precision = numeric(),
recall = numeric(),
F1 = numeric(),
runtime_in_s = numeric(),
stringsAsFactors = FALSE
)
# Loop through each .json file
for (file in json_files) {
# browser()
print(file)
json_data <- fromJSON(file)
# Extract the required values
correct_df <- as.data.frame(fromJSON(json_data$correct)) %>% filter(type == classification_type)
wrong_df <- as.data.frame(fromJSON(json_data$wrong)) %>% filter(type == classification_type)
missing_df <- as.data.frame(fromJSON(json_data$missing)) %>% filter(type == classification_type)
filename <- basename(file)
package <- strsplit(filename, "_")[[1]][1]
method <- gsub("\\.json$", "", paste(strsplit(filename, "_")[[1]][-1], collapse = " "))
num_tables <- data_unnested %>% filter(type == classification_type) %>% nrow()
num_true_pos <- num_correct <- nrow(correct_df)
num_false_pos <- num_wrong <- nrow(wrong_df)
num_false_neg <- num_tables-num_correct
num_true_neg <- total_pages-num_true_pos-num_false_pos-num_false_neg
num_missing <- nrow(missing_df)
runtime <- round(json_data$runtime, 2)
acc = round((num_true_pos+num_true_neg)/(total_pages),2)
precision = round(num_true_pos/(num_true_pos+num_false_pos),2)
recall = round(num_true_pos/(num_true_pos+num_false_neg),2)
F1 = round(2*precision*recall/(precision+recall),2)
# Append the values to the results dataframe
results_df <- results_df %>%
add_row(
package = package,
method = method,
classification_type = classification_type,
true_pos = num_true_pos,
false_pos = num_false_pos,
false_neg = num_false_neg,
true_neg = num_true_neg,
missing = num_missing,
acc = acc,
precision = precision,
recall = recall,
F1 = F1,
runtime_in_s = runtime
)
}
return(results_df %>% as_tibble())
}
metrics <- list()
for (type in c('Aktiva', 'Passiva', 'GuV')) {
metrics[type] <- list(calc_metrics(type))
}
# Get a list of all .json files in the folder
json_files <- list.files("../benchmark_results/page_identification/", pattern = "regex(_exhaustive)?\\.json$", full.names = TRUE)
# Get a list of all .json files in the folder
json_files <- list.files("../benchmark_results/page_identification/", pattern = "regex\\.json$", full.names = TRUE)
# Get a list of all .json files in the folder
json_files <- list.files("../benchmark_results/page_identification/", pattern = "regex.*\\.json$", full.names = TRUE)
calc_metrics <- function(classification_type) {
# Initialize an empty dataframe to store results
results_df <- data.frame(
package = character(),
method = character(),
classification_type = character(),
true_pos = numeric(),
false_pos = numeric(),
false_neg = numeric(),
true_neg = numeric(),
missing = numeric(),
acc = numeric(),
precision = numeric(),
recall = numeric(),
F1 = numeric(),
runtime_in_s = numeric(),
stringsAsFactors = FALSE
)
# Loop through each .json file
for (file in json_files) {
# browser()
print(file)
json_data <- fromJSON(file)
# Extract the required values
correct_df <- as.data.frame(fromJSON(json_data$correct)) %>% filter(type == classification_type)
wrong_df <- as.data.frame(fromJSON(json_data$wrong)) %>% filter(type == classification_type)
missing_df <- as.data.frame(fromJSON(json_data$missing)) %>% filter(type == classification_type)
filename <- basename(file)
package <- strsplit(filename, "_")[[1]][1]
method <- gsub("\\.json$", "", paste(strsplit(filename, "_")[[1]][-1], collapse = " "))
num_tables <- data_unnested %>% filter(type == classification_type) %>% nrow()
num_true_pos <- num_correct <- nrow(correct_df)
num_false_pos <- num_wrong <- nrow(wrong_df)
num_false_neg <- num_tables-num_correct
num_true_neg <- total_pages-num_true_pos-num_false_pos-num_false_neg
num_missing <- nrow(missing_df)
runtime <- round(json_data$runtime, 2)
acc = round((num_true_pos+num_true_neg)/(total_pages),2)
precision = round(num_true_pos/(num_true_pos+num_false_pos),2)
recall = round(num_true_pos/(num_true_pos+num_false_neg),2)
F1 = round(2*precision*recall/(precision+recall),2)
# Append the values to the results dataframe
results_df <- results_df %>%
add_row(
package = package,
method = method,
classification_type = classification_type,
true_pos = num_true_pos,
false_pos = num_false_pos,
false_neg = num_false_neg,
true_neg = num_true_neg,
missing = num_missing,
acc = acc,
precision = precision,
recall = recall,
F1 = F1,
runtime_in_s = runtime
)
}
return(results_df %>% as_tibble())
}
metrics <- list()
for (type in c('Aktiva', 'Passiva', 'GuV')) {
metrics[type] <- list(calc_metrics(type))
}
calc_metrics_by_company_and_type <- function(classification_type) {
df_list <- list()
# Loop through each .json file
for (file in json_files) {
# browser()
json_data <- fromJSON(file)
# Extract the required values
correct_df <- as_tibble(fromJSON(json_data$correct)) %>% group_by(company, type) %>% summarise(n_correct = n())
wrong_df <- as_tibble(fromJSON(json_data$wrong)) %>% group_by(company, type) %>% summarise(n_wrong = n())
# missing_df <- as_tibble(fromJSON(json_data$missing))
# if (nrow(missing_df>0)) {
#     missing_df <- df_missing %>% group_by(company, type) %>% summarise(n_missing = n())
#   }
filename <- basename(file)
package <- strsplit(filename, "_")[[1]][1]
method <- gsub("\\.json$", "", paste(strsplit(filename, "_")[[1]][-1], collapse = " "))
runtime <- round(json_data$runtime, 2)
num_tables <- data_unnested %>% rowwise() %>% mutate(
company = str_split(filepath, "/")[[1]][3]
) %>% group_by(type, company) %>% summarise(n_total = n())
file_count <- data_unnested %>% rowwise() %>% mutate(
company = str_split(filepath, "/")[[1]][3]
) %>% select(filepath, company) %>% unique() %>% group_by(company) %>% summarise(n_files = n())
df_results <- correct_df %>% full_join(wrong_df) %>% full_join(num_tables) %>%
full_join(file_count) %>% mutate(
num_true_pos = n_correct,
num_false_pos = n_wrong,
num_false_neg = n_total-n_correct,
# acc = round((num_true_pos+num_true_neg)/(total_pages),2)
precision = round(num_true_pos/(num_true_pos+num_false_pos),2),
recall = round(num_true_pos/(num_true_pos+num_false_neg),2),
F1 = round(2*precision*recall/(precision+recall),2),
package = package,
method = method,
runtime_in_s = runtime
) %>% rename(classification_type = type)
df_list[filename] <- list(df_results)
}
return(bind_rows(df_list) %>% as_tibble())
}
metrics_by_company_and_type <- calc_metrics_by_company_and_type(type)
metrics_by_company_and_type %>%
select(company, n_files, method, F1, precision, recall, classification_type) %>%
pivot_longer(cols=c(F1, precision, recall), names_to = "metric") %>%
ggplot() +
geom_boxplot(aes(x = company, y = value, fill = n_files)) +
geom_jitter(aes(x = company, y = value, color = method), alpha = .4) +
facet_grid(classification_type~metric) +
scale_x_discrete(guide = guide_axis(angle = 30))
metrics_by_company_and_type %>%
select(company, n_files, method, F1, precision, recall, classification_type) %>%
pivot_longer(cols=c(F1, precision, recall), names_to = "metric") %>%
ggplot() +
geom_boxplot(aes(x = company, y = value, fill = n_files), alpha = 0.5) +
geom_jitter(aes(x = company, y = value, color = method), alpha = .4) +
facet_grid(classification_type~metric) +
scale_x_discrete(guide = guide_axis(angle = 30))
metrics_by_company_and_type %>%
select(company, n_files, method, F1, precision, recall, classification_type) %>%
pivot_longer(cols=c(F1, precision, recall), names_to = "metric") %>%
ggplot() +
geom_boxplot(aes(x = company, y = value, fill = n_files), alpha = 0.5) +
geom_jitter(aes(x = company, y = value, color = method), alpha = 1) +
facet_grid(classification_type~metric) +
scale_x_discrete(guide = guide_axis(angle = 30))
df_binary$model_family
df_binary$model_family %>% unique()
library(jsonlite)
library(tidyverse)
json_files_table_extraction_llm <- list.files(
"../benchmark_results/table_extraction/regex/",
pattern = "\\.json$",
full.names = TRUE
) %>%
.[!grepl("_test_", .)]
meta_list_llm <- list()
# Loop through each .json file
for (file in json_files_table_extraction_llm) {
# print(file)
# Read the JSON file
# Read the JSON file and replace NaN with NULL in the file content
file_content <- readLines(file, warn = FALSE)
file_content <- gsub("\\bNaN\\b", "null", file_content)
file_content <- gsub("\\bInfinity\\b", "null", file_content)
# Remove incomplete last JSON entry and close the list if file ends early
if (!grepl("\\]$", file_content[length(file_content)])) {
# Find the last complete JSON object (ends with "},")
last_complete <- max(grep('\\.pdf', file_content))
file_content <- c(file_content[1:last_complete], "}]")
}
json_data <- fromJSON(paste(file_content, collapse = "\n"))
# name_split = (basename(file) %>% str_split("__"))[[1]]
# method_index = which(str_starts((basename(file) %>% str_split("__"))[[1]], "loop"))-1
# print(name_split)
results <-  json_data %>% as_tibble() %>% rowwise() %>%
mutate(
model = basename(file) %>% str_replace('.json', '') %>% str_replace('evaluation_', ''),
# model = name_split[1],
# method = name_split[method_index],
# n_examples = str_match(method, "\\d+")[[1]],
# out_of_company = if_else(str_detect(method, "rag"), str_detect(method, "out_of_company"), NA),
# method_family = str_replace(str_replace(method, '\\d+', 'n'), '_out_of_company', ''),
# loop = as.numeric((basename(file) %>% str_match("loop_(.)(_queued)?\\.json"))[2]),
predictions = list(fromJSON(df_joined) %>% as_tibble())
) %>% select(-df_joined)
# results$predictions <- predictions
meta_list_llm[[length(meta_list_llm) + 1]] <- results
}
df <- bind_rows(meta_list_llm) %>% select(!starts_with("changed_values")) %>%
filter(grammar_error != TRUE || is.na(grammar_error)) %>%
unnest_wider(`NA`, names_sep = "_") %>%
unnest_wider(`relative_numeric_difference`, names_sep = "_") %>%
unnest_wider(`levenstein_distance`, names_sep = "_") %>%
# rename_with(~ gsub("^NA_", "NA_", .x)) %>%  # Ensures prefix is NA_
mutate(
NA_total_truth = NA_true_positive + NA_false_negative,
NA_precision = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_positive), NA),
NA_recall = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_negative), NA),
NA_F1 = if_else((NA_precision + NA_recall) > 0, (2 * NA_precision * NA_recall)/(NA_precision + NA_recall), 0),
percentage_correct_numeric = correct_numeric/(correct_numeric + incorrect_numeric),
percentage_correct_total = (correct_numeric + NA_true_positive)/total_entries
)
df %>% select(c(model, percentage_correct_numeric, percentage_correct_total)) %>%
pivot_longer(cols = -c(model)) %>%
ggplot() +
geom_boxplot(aes(x = model, y = value)) +
# facet_wrap(~name, ncol = 1) +
scale_x_discrete(guide = guide_axis(angle = 30)) +
facet_grid(~name)
df %>% select(c(model, NA_precision, NA_recall, NA_F1)) %>%
pivot_longer(cols = -c(model)) %>%
ggplot() +
geom_boxplot(aes(x = model, y = value)) +
# facet_wrap(~name, ncol = 1) +
scale_x_discrete(guide = guide_axis(angle = 30)) +
facet_grid(name~1)
df %>% ggplot() +
geom_boxplot(aes(x = model, y = relative_numeric_difference_mean)) +
scale_x_discrete(guide = guide_axis(angle = 30)) +
coord_cartesian(ylim = c(0, 1500))
df %>% ggplot() +
geom_boxplot(aes(x = model, y = relative_numeric_difference_mean)) +
scale_x_discrete(guide = guide_axis(angle = 30)) +
coord_cartesian(ylim = c(0, 1))
df %>% ggplot() +
geom_boxplot(aes(x = model, y = levenstein_distance_mean)) +
scale_x_discrete(guide = guide_axis(angle = 30))
df %>% ggplot() +
geom_boxplot(aes(x = model, y = relative_numeric_difference_mean)) +
scale_x_discrete(guide = guide_axis(angle = 30)) +
coord_cartesian(ylim = c(0, 1))
df %>% ggplot() +
geom_boxplot(aes(x = model, y = levenstein_distance_mean)) +
scale_x_discrete(guide = guide_axis(angle = 30))
df %>% select(c(model, percentage_correct_numeric, percentage_correct_total)) %>%
pivot_longer(cols = -c(model)) %>%
ggplot() +
geom_boxplot(aes(x = model, y = value)) +
# facet_wrap(~name, ncol = 1) +
scale_x_discrete(guide = guide_axis(angle = 30)) +
facet_grid(~name)
df %>% select(c(model, NA_precision, NA_recall, NA_F1)) %>%
pivot_longer(cols = -c(model)) %>%
ggplot() +
geom_boxplot(aes(x = model, y = value)) +
# facet_wrap(~name, ncol = 1) +
scale_x_discrete(guide = guide_axis(angle = 30)) +
facet_grid(name~1)
df
df$model
json_files_table_extraction_llm <- list.files(
"../benchmark_results/table_extraction/regex/",
pattern = "\\.json$",
full.names = TRUE
) %>%
.[!grepl("_test_", .)]
meta_list_llm <- list()
# Loop through each .json file
for (file in json_files_table_extraction_llm) {
browser()
# print(file)
# Read the JSON file
# Read the JSON file and replace NaN with NULL in the file content
file_content <- readLines(file, warn = FALSE)
file_content <- gsub("\\bNaN\\b", "null", file_content)
file_content <- gsub("\\bInfinity\\b", "null", file_content)
# Remove incomplete last JSON entry and close the list if file ends early
if (!grepl("\\]$", file_content[length(file_content)])) {
# Find the last complete JSON object (ends with "},")
last_complete <- max(grep('\\.pdf', file_content))
file_content <- c(file_content[1:last_complete], "}]")
}
json_data <- fromJSON(paste(file_content, collapse = "\n"))
# name_split = (basename(file) %>% str_split("__"))[[1]]
# method_index = which(str_starts((basename(file) %>% str_split("__"))[[1]], "loop"))-1
# print(name_split)
results <-  json_data %>% as_tibble() %>% rowwise() %>%
mutate(
model = basename(file) %>% str_replace('.json', '') %>% str_replace('evaluation_', ''),
# model = name_split[1],
# method = name_split[method_index],
# n_examples = str_match(method, "\\d+")[[1]],
# out_of_company = if_else(str_detect(method, "rag"), str_detect(method, "out_of_company"), NA),
# method_family = str_replace(str_replace(method, '\\d+', 'n'), '_out_of_company', ''),
# loop = as.numeric((basename(file) %>% str_match("loop_(.)(_queued)?\\.json"))[2]),
predictions = list(fromJSON(df_joined) %>% as_tibble())
) %>% select(-df_joined)
# results$predictions <- predictions
meta_list_llm[[length(meta_list_llm) + 1]] <- results
}
file
