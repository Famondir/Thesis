pivot_longer(cols = -model) %>%
ggplot() +
geom_boxplot(aes(x = model, y = value)) +
facet_wrap(~name, ncol = 1) +
scale_x_discrete(guide = guide_axis(angle = 30))
library(jsonlite)
library(tidyverse)
json_files_table_extraction_llm <- list.files(
"../benchmark_results/table_extraction/llm/",
pattern = "\\.json$",
full.names = TRUE
) %>%
.[!grepl("_test_", .)]
meta_list_llm <- list()
# Loop through each .json file
for (file in json_files_table_extraction_llm) {
# print(file)
# Read the JSON file
# Read the JSON file and replace NaN with NULL in the file content
file_content <- readLines(file, warn = FALSE)
file_content <- gsub("\\bNaN\\b", "null", file_content)
file_content <- gsub("\\bInfinity\\b", "null", file_content)
json_data <- fromJSON(paste(file_content, collapse = "\n"))
results <-  json_data %>% as_tibble() %>% rowwise() %>%
mutate(
model = (basename(file) %>% str_split("__"))[[1]][1],
loop = as.numeric((basename(file) %>% str_match("loop_(.)(_queued)?\\.json"))[2]),
.before = 1
)
meta_list_llm[[length(meta_list_llm) + 1]] <- results
}
df <- bind_rows(meta_list_llm) %>% select(!starts_with("changed_values")) %>%
filter(grammar_error != TRUE || is.na(grammar_error)) %>%
unnest_wider(`NA`, names_sep = "_") %>%
unnest_wider(`relative_numeric_difference`, names_sep = "_") %>%
unnest_wider(`levenstein_distance`, names_sep = "_") %>%
# rename_with(~ gsub("^NA_", "NA_", .x)) %>%  # Ensures prefix is NA_
mutate(
NA_total_truth = NA_true_positive + NA_false_negative,
NA_precision = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_positive), NA),
NA_recall = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_negative), NA),
NA_F1 = if_else((NA_precision + NA_recall) > 0, (2 * NA_precision * NA_recall)/(NA_precision + NA_recall), 0),
percentage_correct_numeric = correct_numeric/(correct_numeric + incorrect_numeric),
percentage_correct_total = (correct_numeric + NA_true_positive)/total_entries
)
df <- df %>% rowwise() %>% mutate(
n_columns = str_match(filepath, "(.)_columns")[2],
span = if_else("True" == str_match(filepath, "span_(False|True)")[2], TRUE, FALSE),
thin = if_else("True" == str_match(filepath, "thin_(False|True)")[2], TRUE, FALSE),
year_as = str_match(filepath, "year_as_(.*)_unit")[2],
unit_in_first_cell = if_else("True" == str_match(filepath, "unit_in_first_cell_(False|True)")[2], TRUE, FALSE),
unit_str = str_match(filepath, "unit_in_first_cell_(False|True)_(.*)_enumeration")[3],
enumeration = if_else("True" == str_match(filepath, "enumeration_(False|True)")[2], TRUE, FALSE),
number_of_table = str_match(filepath, "enumeration_(False|True)_(.*)(_queued)?\\.pdf")[3]
) %>% mutate(
n_columns = ordered(n_columns, c("3", "4", "5"))
) # %>% filter(number_of_table %in% c("0", "1"))
df %>% select(c(model, percentage_correct_numeric, percentage_correct_total)) %>%
pivot_longer(cols = -c(model)) %>%
ggplot() +
geom_boxplot(aes(x = model, y = value)) +
facet_wrap(~name, ncol = 1) +
scale_x_discrete(guide = guide_axis(angle = 30))
json_files_table_extraction_llm <- list.files(
"../benchmark_results/table_extraction/llm/",
pattern = "\\.json$",
full.names = TRUE
) %>%
.[!grepl("_test_", .)]
meta_list_llm <- list()
# Loop through each .json file
for (file in json_files_table_extraction_llm) {
# print(file)
# Read the JSON file
# Read the JSON file and replace NaN with NULL in the file content
file_content <- readLines(file, warn = FALSE)
file_content <- gsub("\\bNaN\\b", "null", file_content)
file_content <- gsub("\\bInfinity\\b", "null", file_content)
json_data <- fromJSON(paste(file_content, collapse = "\n"))
results <-  json_data %>% as_tibble() %>% rowwise() %>%
mutate(
model = (basename(file) %>% str_split("__"))[[1]][1],
loop = as.numeric((basename(file) %>% str_match("loop_(.)(_queued)?\\.json"))[2]),
.before = 1
)
meta_list_llm[[length(meta_list_llm) + 1]] <- results
}
df <- bind_rows(meta_list_llm) %>% select(!starts_with("changed_values")) %>%
filter(grammar_error != TRUE || is.na(grammar_error)) %>%
unnest_wider(`NA`, names_sep = "_") %>%
unnest_wider(`relative_numeric_difference`, names_sep = "_") %>%
unnest_wider(`levenstein_distance`, names_sep = "_") %>%
# rename_with(~ gsub("^NA_", "NA_", .x)) %>%  # Ensures prefix is NA_
mutate(
NA_total_truth = NA_true_positive + NA_false_negative,
NA_precision = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_positive), NA),
NA_recall = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_negative), NA),
NA_F1 = if_else((NA_precision + NA_recall) > 0, (2 * NA_precision * NA_recall)/(NA_precision + NA_recall), 0),
percentage_correct_numeric = correct_numeric/(correct_numeric + incorrect_numeric),
percentage_correct_total = (correct_numeric + NA_true_positive)/total_entries
)
df <- df %>% rowwise() %>% mutate(
n_columns = str_match(filepath, "(.)_columns")[2],
span = if_else("True" == str_match(filepath, "span_(False|True)")[2], TRUE, FALSE),
thin = if_else("True" == str_match(filepath, "thin_(False|True)")[2], TRUE, FALSE),
year_as = str_match(filepath, "year_as_(.*)_unit")[2],
unit_in_first_cell = if_else("True" == str_match(filepath, "unit_in_first_cell_(False|True)")[2], TRUE, FALSE),
unit_str = str_match(filepath, "unit_in_first_cell_(False|True)_(.*)_enumeration")[3],
enumeration = if_else("True" == str_match(filepath, "enumeration_(False|True)")[2], TRUE, FALSE),
number_of_table = str_match(filepath, "enumeration_(False|True)_(.*)(_queued)?\\.pdf")[3]
) %>% mutate(
n_columns = ordered(n_columns, c("3", "4", "5"))
) # %>% filter(number_of_table %in% c("0", "1"))
df %>% select(c(model, percentage_correct_numeric, percentage_correct_total)) %>%
pivot_longer(cols = -c(model)) %>%
ggplot() +
geom_boxplot(aes(x = model, y = value)) +
facet_wrap(~name, ncol = 1) +
scale_x_discrete(guide = guide_axis(angle = 30))
df %>% select(c(model, NA_precision, NA_recall, NA_F1)) %>%
pivot_longer(cols = -c(model)) %>%
ggplot() +
geom_boxplot(aes(x = model, y = value)) +
facet_wrap(~name, ncol = 1) +
scale_x_discrete(guide = guide_axis(angle = 30))
json_files_table_extraction_llm <- list.files(
"../benchmark_results/table_extraction/llm/",
pattern = "\\.json$",
full.names = TRUE
) %>%
.[grepl("_test_", .)]
meta_list_llm <- list()
# Loop through each .json file
for (file in json_files_table_extraction_llm) {
# print(file)
# Read the JSON file
# Read the JSON file and replace NaN with NULL in the file content
file_content <- readLines(file, warn = FALSE)
file_content <- gsub("\\bNaN\\b", "null", file_content)
json_data <- fromJSON(paste(file_content, collapse = "\n"))
model_name <- (basename(file) %>% str_split("__"))[[1]][1] %>% str_replace("_vllm", "")
# if (grepl("_queued\\.json$", basename(file))) {
#   model_name <- paste0(model_name, "_queued")
# }
results <-  json_data %>% as_tibble() %>% rowwise() %>%
mutate(model = model_name, .before = 1)
meta_list_llm[[length(meta_list_llm) + 1]] <- results
}
df <- bind_rows(meta_list_llm) %>% select(!starts_with("changed_values")) %>%
filter(grammar_error != TRUE || is.na(grammar_error)) %>%
unnest_wider(`NA`, names_sep = "_") %>%
unnest_wider(`relative_numeric_difference`, names_sep = "_") %>%
unnest_wider(`levenstein_distance`, names_sep = "_") %>%
# rename_with(~ gsub("^NA_", "NA_", .x)) %>%  # Ensures prefix is NA_
mutate(
NA_total_truth = NA_true_positive + NA_false_negative,
NA_precision = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_positive), NA),
NA_recall = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_negative), NA),
NA_F1 = if_else((NA_precision + NA_recall) > 0, (2 * NA_precision * NA_recall)/(NA_precision + NA_recall), 0),
percentage_correct_numeric = correct_numeric/(correct_numeric + incorrect_numeric),
percentage_correct_total = (correct_numeric + NA_true_positive)/total_entries
)
df %>% select(c(model, percentage_correct_numeric, percentage_correct_total)) %>%
pivot_longer(cols = -model) %>%
ggplot() +
geom_boxplot(aes(x = model, y = value)) +
facet_wrap(~name, ncol = 1) +
scale_x_discrete(guide = guide_axis(angle = 30))
json_files_table_extraction_llm <- list.files(
"../benchmark_results/table_extraction/llm/",
pattern = "\\.json$",
full.names = TRUE
) %>%
.[!grepl("_test_", .)]
meta_list_llm <- list()
# Loop through each .json file
for (file in json_files_table_extraction_llm) {
# print(file)
# Read the JSON file
# Read the JSON file and replace NaN with NULL in the file content
file_content <- readLines(file, warn = FALSE)
file_content <- gsub("\\bNaN\\b", "null", file_content)
file_content <- gsub("\\bInfinity\\b", "null", file_content)
json_data <- fromJSON(paste(file_content, collapse = "\n"))
results <-  json_data %>% as_tibble() %>% rowwise() %>%
mutate(
model = (basename(file) %>% str_split("__"))[[1]][1],
loop = as.numeric((basename(file) %>% str_match("loop_(.)(_queued)?\\.json"))[2]),
.before = 1
)
meta_list_llm[[length(meta_list_llm) + 1]] <- results
}
df <- bind_rows(meta_list_llm) %>% select(!starts_with("changed_values")) %>%
filter(grammar_error != TRUE || is.na(grammar_error)) %>%
unnest_wider(`NA`, names_sep = "_") %>%
unnest_wider(`relative_numeric_difference`, names_sep = "_") %>%
unnest_wider(`levenstein_distance`, names_sep = "_") %>%
# rename_with(~ gsub("^NA_", "NA_", .x)) %>%  # Ensures prefix is NA_
mutate(
NA_total_truth = NA_true_positive + NA_false_negative,
NA_precision = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_positive), NA),
NA_recall = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_negative), NA),
NA_F1 = if_else((NA_precision + NA_recall) > 0, (2 * NA_precision * NA_recall)/(NA_precision + NA_recall), 0),
percentage_correct_numeric = correct_numeric/(correct_numeric + incorrect_numeric),
percentage_correct_total = (correct_numeric + NA_true_positive)/total_entries
)
df <- df %>% rowwise() %>% mutate(
n_columns = str_match(filepath, "(.)_columns")[2],
span = if_else("True" == str_match(filepath, "span_(False|True)")[2], TRUE, FALSE),
thin = if_else("True" == str_match(filepath, "thin_(False|True)")[2], TRUE, FALSE),
year_as = str_match(filepath, "year_as_(.*)_unit")[2],
unit_in_first_cell = if_else("True" == str_match(filepath, "unit_in_first_cell_(False|True)")[2], TRUE, FALSE),
unit_str = str_match(filepath, "unit_in_first_cell_(False|True)_(.*)_enumeration")[3],
enumeration = if_else("True" == str_match(filepath, "enumeration_(False|True)")[2], TRUE, FALSE),
number_of_table = str_match(filepath, "enumeration_(False|True)_(.*)(_queued)?\\.pdf")[3]
) %>% mutate(
n_columns = ordered(n_columns, c("3", "4", "5"))
) # %>% filter(number_of_table %in% c("0", "1"))
##### plotting #####
df %>% select(c(model, percentage_correct_numeric, percentage_correct_total)) %>%
pivot_longer(cols = -c(model)) %>%
ggplot() +
geom_boxplot(aes(x = model, y = value)) +
facet_wrap(~name, ncol = 1) +
scale_x_discrete(guide = guide_axis(angle = 30))
library(jsonlite)
library(tidyverse)
# Rename files ending with __no_think.json to -no-think in the model name and remove the suffix
files_to_rename <- list.files(
"../benchmark_results/table_detection/llm/",
pattern = "__no_think\\.json$",
full.names = TRUE
)
for (old_path in files_to_rename) {
# Extract filename
old_name <- basename(old_path)
# Replace "__no_think.json" with ".json" and insert "-no-think" after the model name
new_name <- sub("([0-9]+B)__", "\\1-no-think__", sub("__no_think\\.json$", ".json", old_name))
# print(new_name)
new_path <- file.path(dirname(old_path), new_name)
file.rename(old_path, new_path)
}
json_files_table_detection_llm <- list.files(
"../benchmark_results/table_detection/llm/",
pattern = "\\.json$",
full.names = TRUE
) %>%
.[!grepl("_test_", .)] %>%
# .[grepl("_binary_", .)]
.[grepl("_five_classes_", .)]
meta_list_llm <- list()
# Loop through each .json file
for (file in json_files_table_detection_llm) {
# print(file)
# Read the JSON file
json_data <- fromJSON(file)
# Extract the threshold and metrics from the "metrics" key
metrics <- as.data.frame(json_data$metrics)
lst <- list(
metrics = metrics,
model = basename(file),
runtime = json_data$runtime
)
meta_list_llm[[length(meta_list_llm) + 1]] <- lst
}
results_df_llm <- data.frame(
llm = character(),
parameters = character(),
method = character(),
loop = numeric(),
setNames(
rep(list(numeric()), length(unique(unlist(lapply(meta_list_llm, function(x) names(x$metrics)))))),
unique(unlist(lapply(meta_list_llm, function(x) names(x$metrics))))
),
runtime_in_s = numeric(),
stringsAsFactors = FALSE
)
for (result in meta_list_llm) {
name_split = result$model %>% str_split("__")
name_split = name_split[[1]]
llm = name_split[1]
parameters = str_extract(llm, "\\d*\\.?\\d+B")
method = name_split[length(name_split)-1]
loop = name_split[length(name_split)] %>% str_remove(".json") %>% str_remove("loop_") %>% as.integer()
F1_Aktiva = result$metrics$Aktiva.f1_score
F1_Passiva = result$metrics$Passiva.f1_score
runtime = result$runtime
results_df_llm <- results_df_llm %>%
add_row(
llm = llm,
parameters = parameters,
method = method,
loop = loop,
!!!setNames(
lapply(result$metrics, function(x) round(as.numeric(x), 2)),
names(result$metrics)
),
runtime_in_s = round(runtime, 2)
)
}
results_df_llm$llm %>% unique()
results_df_llm <- results_df_llm %>%
mutate(llm = factor(llm, levels = c(
"Qwen_Qwen2.5-0.5B-Instruct",
"Qwen_Qwen2.5-1.5B-Instruct",
"Qwen_Qwen2.5-1.5B-Instruct_alt_prompts",
"Qwen_Qwen2.5-3B-Instruct",
"Qwen_Qwen2.5-7B-Instruct",
"Qwen_Qwen2.5-7B-Instruct_alt_prompts",
"Qwen_Qwen2.5-14B-Instruct",
"Qwen_Qwen2.5-32B-Instruct",
"Qwen_Qwen2.5-72B-Instruct",
"Qwen_Qwen3-8B",
"Qwen_Qwen3-8B-no-think",
"Qwen_Qwen3-32B",
"Qwen_Qwen3-32B-no-think"
))) %>%
# mutate(llm = factor(llm, levels = c(
#   "deepseek-ai_DeepSeek-R1-Distill-Qwen-32B",
#   "google_gemma-3-4b-it",
#   "google_gemma-3-27b-it",
#   "microsoft_phi-4",
#   "meta-llama_Llama-4-Scout-17B-16E",
#   "meta-llama_Llama-3.3-70B-Instruct",
#   "meta-llama_Llama-3.2-3B-Instruct",
#   "meta-llama_Llama-3.1-8B-Instruct",
#   "meta-llama_Llama-3.1-70B-Instruct",
#   "mistralai_Mistral-7B-Instruct-v0.3",
#   "tiiuae_Falcon3-10B-Instruct",
#   "Qwen_Qwen2.5-7B-Instruct",
#   "Qwen_Qwen2.5-72B-Instruct"
# ))) %>%
filter(!str_detect(llm, "_alt_"))
selected_columns <- names(results_df_llm)[c(5:ncol(results_df_llm)-1)]
results_df_llm %>%
group_by(llm, parameters, method) %>%
summarise(across(all_of(selected_columns), list(median = ~median(.x, na.rm = TRUE), MAD = ~mad(.x, na.rm = TRUE))))
results_df_llm %>%
pivot_longer(cols = contains("F1"), values_to = "value", names_to = "metric") %>%
ggplot() +
geom_boxplot(aes(x=llm, y=value)) +
facet_grid(metric~method) +
ylim(c(0,1)) +
scale_x_discrete(guide = guide_axis(angle = 30))
results_df_llm <- results_df_llm %>%
# mutate(llm = factor(llm, levels = c(
#   "Qwen_Qwen2.5-0.5B-Instruct",
#   "Qwen_Qwen2.5-1.5B-Instruct",
#   "Qwen_Qwen2.5-1.5B-Instruct_alt_prompts",
#   "Qwen_Qwen2.5-3B-Instruct",
#   "Qwen_Qwen2.5-7B-Instruct",
#   "Qwen_Qwen2.5-7B-Instruct_alt_prompts",
#   "Qwen_Qwen2.5-14B-Instruct",
#   "Qwen_Qwen2.5-32B-Instruct",
#   "Qwen_Qwen2.5-72B-Instruct",
#   "Qwen_Qwen3-8B",
#   "Qwen_Qwen3-8B-no-think",
#   "Qwen_Qwen3-32B",
#   "Qwen_Qwen3-32B-no-think"
# ))) %>%
mutate(llm = factor(llm, levels = c(
"deepseek-ai_DeepSeek-R1-Distill-Qwen-32B",
"google_gemma-3-4b-it",
"google_gemma-3-27b-it",
"microsoft_phi-4",
"meta-llama_Llama-4-Scout-17B-16E",
"meta-llama_Llama-3.3-70B-Instruct",
"meta-llama_Llama-3.2-3B-Instruct",
"meta-llama_Llama-3.1-8B-Instruct",
"meta-llama_Llama-3.1-70B-Instruct",
"mistralai_Mistral-7B-Instruct-v0.3",
"tiiuae_Falcon3-10B-Instruct",
"Qwen_Qwen2.5-7B-Instruct",
"Qwen_Qwen2.5-72B-Instruct"
))) %>%
filter(!str_detect(llm, "_alt_"))
selected_columns <- names(results_df_llm)[c(5:ncol(results_df_llm)-1)]
results_df_llm %>%
group_by(llm, parameters, method) %>%
summarise(across(all_of(selected_columns), list(median = ~median(.x, na.rm = TRUE), MAD = ~mad(.x, na.rm = TRUE))))
results_df_llm %>%
pivot_longer(cols = contains("F1"), values_to = "value", names_to = "metric") %>%
ggplot() +
geom_boxplot(aes(x=llm, y=value)) +
facet_grid(metric~method) +
ylim(c(0,1)) +
scale_x_discrete(guide = guide_axis(angle = 30))
for (result in meta_list_llm) {
name_split = result$model %>% str_split("__")
name_split = name_split[[1]]
llm = name_split[1]
parameters = str_extract(llm, "\\d*\\.?\\d+B")
method = name_split[length(name_split)-1]
loop = name_split[length(name_split)] %>% str_remove(".json") %>% str_remove("loop_") %>% as.integer()
F1_Aktiva = result$metrics$Aktiva.f1_score
F1_Passiva = result$metrics$Passiva.f1_score
runtime = result$runtime
results_df_llm <- results_df_llm %>%
add_row(
llm = llm,
parameters = parameters,
method = method,
loop = loop,
!!!setNames(
lapply(result$metrics, function(x) round(as.numeric(x), 2)),
names(result$metrics)
),
runtime_in_s = round(runtime, 2)
)
}
results_df_llm$llm %>% unique()
results_df_llm <- results_df_llm %>%
# mutate(llm = factor(llm, levels = c(
#   "Qwen_Qwen2.5-0.5B-Instruct",
#   "Qwen_Qwen2.5-1.5B-Instruct",
#   "Qwen_Qwen2.5-1.5B-Instruct_alt_prompts",
#   "Qwen_Qwen2.5-3B-Instruct",
#   "Qwen_Qwen2.5-7B-Instruct",
#   "Qwen_Qwen2.5-7B-Instruct_alt_prompts",
#   "Qwen_Qwen2.5-14B-Instruct",
#   "Qwen_Qwen2.5-32B-Instruct",
#   "Qwen_Qwen2.5-72B-Instruct",
#   "Qwen_Qwen3-8B",
#   "Qwen_Qwen3-8B-no-think",
#   "Qwen_Qwen3-32B",
#   "Qwen_Qwen3-32B-no-think"
# ))) %>%
mutate(llm = factor(llm, levels = c(
"deepseek-ai_DeepSeek-R1-Distill-Qwen-32B",
"google_gemma-3-4b-it",
"google_gemma-3-27b-it",
"microsoft_phi-4",
"meta-llama_Llama-4-Scout-17B-16E",
"meta-llama_Llama-3.3-70B-Instruct",
"meta-llama_Llama-3.2-3B-Instruct",
"meta-llama_Llama-3.1-8B-Instruct",
"meta-llama_Llama-3.1-70B-Instruct",
"mistralai_Mistral-7B-Instruct-v0.3",
"tiiuae_Falcon3-10B-Instruct",
"Qwen_Qwen2.5-7B-Instruct",
"Qwen_Qwen2.5-72B-Instruct"
))) %>%
filter(!str_detect(llm, "_alt_"))
selected_columns <- names(results_df_llm)[c(5:ncol(results_df_llm)-1)]
results_df_llm %>%
group_by(llm, parameters, method) %>%
summarise(across(all_of(selected_columns), list(median = ~median(.x, na.rm = TRUE), MAD = ~mad(.x, na.rm = TRUE))))
results_df_llm %>%
pivot_longer(cols = contains("F1"), values_to = "value", names_to = "metric") %>%
ggplot() +
geom_boxplot(aes(x=llm, y=value)) +
facet_grid(metric~method) +
ylim(c(0,1)) +
scale_x_discrete(guide = guide_axis(angle = 30))
library(jsonlite)
library(tidyverse)
json_files_table_extraction_llm <- list.files(
"../benchmark_results/table_extraction/llm/",
pattern = "\\.json$",
full.names = TRUE
) %>%
.[!grepl("_test_", .)]
meta_list_llm <- list()
# Loop through each .json file
for (file in json_files_table_extraction_llm) {
# print(file)
# Read the JSON file
# Read the JSON file and replace NaN with NULL in the file content
file_content <- readLines(file, warn = FALSE)
file_content <- gsub("\\bNaN\\b", "null", file_content)
file_content <- gsub("\\bInfinity\\b", "null", file_content)
json_data <- fromJSON(paste(file_content, collapse = "\n"))
results <-  json_data %>% as_tibble() %>% rowwise() %>%
mutate(
model = (basename(file) %>% str_split("__"))[[1]][1],
loop = as.numeric((basename(file) %>% str_match("loop_(.)(_queued)?\\.json"))[2]),
.before = 1
)
meta_list_llm[[length(meta_list_llm) + 1]] <- results
}
df <- bind_rows(meta_list_llm) %>% select(!starts_with("changed_values")) %>%
filter(grammar_error != TRUE || is.na(grammar_error)) %>%
unnest_wider(`NA`, names_sep = "_") %>%
unnest_wider(`relative_numeric_difference`, names_sep = "_") %>%
unnest_wider(`levenstein_distance`, names_sep = "_") %>%
# rename_with(~ gsub("^NA_", "NA_", .x)) %>%  # Ensures prefix is NA_
mutate(
NA_total_truth = NA_true_positive + NA_false_negative,
NA_precision = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_positive), NA),
NA_recall = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_negative), NA),
NA_F1 = if_else((NA_precision + NA_recall) > 0, (2 * NA_precision * NA_recall)/(NA_precision + NA_recall), 0),
percentage_correct_numeric = correct_numeric/(correct_numeric + incorrect_numeric),
percentage_correct_total = (correct_numeric + NA_true_positive)/total_entries
)
df <- df %>% rowwise() %>% mutate(
n_columns = str_match(filepath, "(.)_columns")[2],
span = if_else("True" == str_match(filepath, "span_(False|True)")[2], TRUE, FALSE),
thin = if_else("True" == str_match(filepath, "thin_(False|True)")[2], TRUE, FALSE),
year_as = str_match(filepath, "year_as_(.*)_unit")[2],
unit_in_first_cell = if_else("True" == str_match(filepath, "unit_in_first_cell_(False|True)")[2], TRUE, FALSE),
unit_str = str_match(filepath, "unit_in_first_cell_(False|True)_(.*)_enumeration")[3],
enumeration = if_else("True" == str_match(filepath, "enumeration_(False|True)")[2], TRUE, FALSE),
number_of_table = str_match(filepath, "enumeration_(False|True)_(.*)(_queued)?\\.pdf")[3]
) %>% mutate(
n_columns = ordered(n_columns, c("3", "4", "5"))
) # %>% filter(number_of_table %in% c("0", "1"))
df %>% select(c(model, percentage_correct_numeric, percentage_correct_total)) %>%
pivot_longer(cols = -c(model)) %>%
ggplot() +
geom_boxplot(aes(x = model, y = value)) +
facet_wrap(~name, ncol = 1) +
scale_x_discrete(guide = guide_axis(angle = 30))
