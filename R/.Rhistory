# rename_with(~ gsub("^NA_", "NA_", .x)) %>%  # Ensures prefix is NA_
mutate(
NA_total_truth = NA_true_positive + NA_false_negative,
NA_precision = if_else(NA_total_truth > 0, if_else((NA_true_positive + NA_false_positive)>0, NA_true_positive/(NA_true_positive + NA_false_positive), 0), NA),
NA_recall = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_negative), NA),
NA_F1 = if_else((NA_precision + NA_recall) > 0, (2 * NA_precision * NA_recall)/(NA_precision + NA_recall), 0),
percentage_correct_numeric = if_else((correct_numeric + incorrect_numeric)>0, correct_numeric/(correct_numeric + incorrect_numeric), 0),
percentage_correct_total = (correct_numeric + NA_true_positive)/total_entries
) %>% mutate(
model = str_replace(model, "_vllm", ""),
method = str_replace(method, '_out_of_sample', ''),
model_family = sub("_.*", "", model),
model_family = if_else(str_detect(model, "Qwen2"), "Qwen 2.5", model_family),
model_family = if_else(str_detect(model, "Qwen3"), "Qwen 3", model_family),
model_family = if_else(str_detect(model, "Llama-3"), "Llama-3", model_family),
model_family = if_else(str_detect(model, "Llama-4"), "Llama-4", model_family)
) %>% mutate(
n_examples = as.numeric(n_examples),
n_examples = if_else(method_family == "zero_shot", 0, n_examples),
n_examples = if_else(method_family == "static_example", 1, n_examples)
) %>% mutate(
filepath = str_replace(filepath, "/pvc/benchmark_truth/real_tables_extended/Tempelhof Projekt GmbH __", "/pvc/benchmark_truth/real_tables_extended/Tempelhof Projekt GmbH__")
)
##### pdfium text #####
json_files_table_extraction_llm <- list.files(
"../benchmark_results/table_extraction/llm/final/real_tables_more_examples/",
pattern = "\\.json$",
full.names = TRUE
) %>%
.[!grepl("_test_", .)] %>%
.[grepl("235B", .)] %>%
.[!grepl("synth", .)]
meta_list_llm <- list()
error_list <- c()
# Loop through each .json file
for (file in json_files_table_extraction_llm) {
# print(file)
# Read the JSON file
# Read the JSON file and replace NaN with NULL in the file content
file_content <- readLines(file, warn = FALSE)
file_content <- gsub("\\bNaN\\b", "null", file_content)
file_content <- gsub("\\bInfinity\\b", "null", file_content)
# Remove incomplete last JSON entry and close the list if file ends early
# if (!grepl("\\]$", file_content[length(file_content)])) {
#   # Find the last complete JSON object (ends with "},")
#   last_complete <- max(grep('\\.pdf', file_content))
#   file_content <- c(file_content[1:last_complete], "}]")
# }
json_data <- fromJSON(paste(file_content, collapse = "\n"))
name_split = (basename(file) %>% str_split("__"))[[1]]
# if (str_detect(name_split[1], "gpt-oss")) next
method_index = which(str_starts((basename(file) %>% str_split("__"))[[1]], "loop"))-1
# print(name_split)
results <-  json_data$results %>% as_tibble()
if (nrow(results) == 0) {
error_list <-  c(error_list, file)
next
}
# for (idx in 1:nrow(results)) {
#   print(idx)
#   # try()
#   fromJSON(results$df_joined[[idx]])
# }
#
# results$df_joined[[16]]
results <-  results %>% rowwise() %>%
mutate(
extractor = "pdfium",
input_format = "text",
model = name_split[1],
method = name_split[method_index],
n_examples = str_match(method, "\\d+")[[1]],
out_of_company = if_else(str_detect(method, "rag"), str_detect(basename(file), "out_of_sample") == TRUE, NA),
method_family = str_replace(str_replace(method, '\\d+', 'n'), '_out_of_sample', ''),
loop = as.numeric((basename(file) %>% str_match("loop_(.)(_queued)?\\.json"))[2]),
predictions = list(try(fromJSON(df_joined)) %>% as_tibble()),
request_tokens = list(json_data$request_tokens),
runtime = json_data$runtime
) %>% select(-df_joined)
# results$predictions <- predictions
meta_list_llm[[length(meta_list_llm) + 1]] <- results
}
df_pdfium_txt <- bind_rows(meta_list_llm) %>% select(!starts_with("changed_values")) %>%
filter(grammar_error != TRUE || is.na(grammar_error)) %>%
unnest_wider(`NA`, names_sep = "_") %>%
unnest_wider(`relative_numeric_difference`, names_sep = "_") %>%
unnest_wider(`levenstein_distance`, names_sep = "_") %>%
# rename_with(~ gsub("^NA_", "NA_", .x)) %>%  # Ensures prefix is NA_
mutate(
NA_total_truth = NA_true_positive + NA_false_negative,
NA_precision = if_else(NA_total_truth > 0, if_else((NA_true_positive + NA_false_positive)>0, NA_true_positive/(NA_true_positive + NA_false_positive), 0), NA),
NA_recall = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_negative), NA),
NA_F1 = if_else((NA_precision + NA_recall) > 0, (2 * NA_precision * NA_recall)/(NA_precision + NA_recall), 0),
percentage_correct_numeric = if_else((correct_numeric + incorrect_numeric)>0, correct_numeric/(correct_numeric + incorrect_numeric), 0),
percentage_correct_total = (correct_numeric + NA_true_positive)/total_entries
) %>% mutate(
model = str_replace(model, "_vllm", ""),
method = str_replace(method, '_out_of_sample', ''),
model_family = sub("_.*", "", model),
model_family = if_else(str_detect(model, "Qwen2"), "Qwen 2.5", model_family),
model_family = if_else(str_detect(model, "Qwen3"), "Qwen 3", model_family),
model_family = if_else(str_detect(model, "Llama-3"), "Llama-3", model_family),
model_family = if_else(str_detect(model, "Llama-4"), "Llama-4", model_family)
) %>% mutate(
n_examples = as.numeric(n_examples),
n_examples = if_else(method_family == "zero_shot", 0, n_examples),
n_examples = if_else(method_family == "static_example", 1, n_examples)
) %>% mutate(
filepath = str_replace(filepath, "/pvc/benchmark_truth/real_tables_extended/Tempelhof Projekt GmbH __", "/pvc/benchmark_truth/real_tables_extended/Tempelhof Projekt GmbH__")
)
##### docling markdown #####
json_files_table_extraction_llm <- list.files(
"../benchmark_results/table_extraction/llm/final/real_tables_more_examples_docling_markdown/",
pattern = "\\.json$",
full.names = TRUE
) %>%
.[!grepl("_test_", .)] %>%
.[!grepl("synth", .)]
meta_list_llm <- list()
error_list <- c()
# Loop through each .json file
for (file in json_files_table_extraction_llm) {
# print(file)
# Read the JSON file
# Read the JSON file and replace NaN with NULL in the file content
file_content <- readLines(file, warn = FALSE)
file_content <- gsub("\\bNaN\\b", "null", file_content)
file_content <- gsub("\\bInfinity\\b", "null", file_content)
# Remove incomplete last JSON entry and close the list if file ends early
# if (!grepl("\\]$", file_content[length(file_content)])) {
#   # Find the last complete JSON object (ends with "},")
#   last_complete <- max(grep('\\.pdf', file_content))
#   file_content <- c(file_content[1:last_complete], "}]")
# }
json_data <- fromJSON(paste(file_content, collapse = "\n"))
name_split = (basename(file) %>% str_split("__"))[[1]]
# if (str_detect(name_split[1], "gpt-oss")) next
method_index = which(str_starts((basename(file) %>% str_split("__"))[[1]], "loop"))-1
# print(name_split)
results <-  json_data$results %>% as_tibble()
if (nrow(results) == 0) {
error_list <-  c(error_list, file)
next
}
# for (idx in 1:nrow(results)) {
#   print(idx)
#   # try()
#   fromJSON(results$df_joined[[idx]])
# }
#
# results$df_joined[[16]]
results <-  results %>% rowwise() %>%
mutate(
extractor = "docling",
input_format = "markdown",
model = name_split[1],
method = name_split[method_index],
n_examples = str_match(method, "\\d+")[[1]],
out_of_company = if_else(str_detect(method, "rag"), str_detect(basename(file), "out_of_sample") == TRUE, NA),
method_family = str_replace(str_replace(method, '\\d+', 'n'), '_out_of_sample', ''),
loop = as.numeric((basename(file) %>% str_match("loop_(.)(_queued)?\\.json"))[2]),
predictions = list(try(fromJSON(df_joined)) %>% as_tibble()),
request_tokens = list(json_data$request_tokens),
runtime = json_data$runtime
) %>% select(-df_joined)
# results$predictions <- predictions
meta_list_llm[[length(meta_list_llm) + 1]] <- results
}
df_docling_md <- bind_rows(meta_list_llm) %>% select(!starts_with("changed_values")) %>%
filter(grammar_error != TRUE || is.na(grammar_error)) %>%
unnest_wider(`NA`, names_sep = "_") %>%
unnest_wider(`relative_numeric_difference`, names_sep = "_") %>%
unnest_wider(`levenstein_distance`, names_sep = "_") %>%
# rename_with(~ gsub("^NA_", "NA_", .x)) %>%  # Ensures prefix is NA_
mutate(
NA_total_truth = NA_true_positive + NA_false_negative,
NA_precision = if_else(NA_total_truth > 0, if_else((NA_true_positive + NA_false_positive)>0, NA_true_positive/(NA_true_positive + NA_false_positive), 0), NA),
NA_recall = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_negative), NA),
NA_F1 = if_else((NA_precision + NA_recall) > 0, (2 * NA_precision * NA_recall)/(NA_precision + NA_recall), 0),
percentage_correct_numeric = if_else((correct_numeric + incorrect_numeric)>0, correct_numeric/(correct_numeric + incorrect_numeric), 0),
percentage_correct_total = (correct_numeric + NA_true_positive)/total_entries
) %>% mutate(
model = str_replace(model, "_vllm", ""),
method = str_replace(method, '_out_of_sample', ''),
model_family = sub("_.*", "", model),
model_family = if_else(str_detect(model, "Qwen2"), "Qwen 2.5", model_family),
model_family = if_else(str_detect(model, "Qwen3"), "Qwen 3", model_family),
model_family = if_else(str_detect(model, "Llama-3"), "Llama-3", model_family),
model_family = if_else(str_detect(model, "Llama-4"), "Llama-4", model_family)
) %>% mutate(
n_examples = as.numeric(n_examples),
n_examples = if_else(method_family == "zero_shot", 0, n_examples),
n_examples = if_else(method_family == "static_example", 1, n_examples)
) %>% mutate(
filepath = str_replace(filepath, "/pvc/benchmark_truth/real_tables_extended/Tempelhof Projekt GmbH __", "/pvc/benchmark_truth/real_tables_extended/Tempelhof Projekt GmbH__")
)
##### docling text #####
json_files_table_extraction_llm <- list.files(
"../benchmark_results/table_extraction/llm/final/real_tables_more_examples_docling_parse/",
pattern = "\\.json$",
full.names = TRUE
) %>%
.[!grepl("_test_", .)] %>%
.[grepl("235B", .)] %>%
.[!grepl("synth", .)]
meta_list_llm <- list()
error_list <- c()
# Loop through each .json file
for (file in json_files_table_extraction_llm) {
# print(file)
# Read the JSON file
# Read the JSON file and replace NaN with NULL in the file content
file_content <- readLines(file, warn = FALSE)
file_content <- gsub("\\bNaN\\b", "null", file_content)
file_content <- gsub("\\bInfinity\\b", "null", file_content)
# Remove incomplete last JSON entry and close the list if file ends early
# if (!grepl("\\]$", file_content[length(file_content)])) {
#   # Find the last complete JSON object (ends with "},")
#   last_complete <- max(grep('\\.pdf', file_content))
#   file_content <- c(file_content[1:last_complete], "}]")
# }
json_data <- fromJSON(paste(file_content, collapse = "\n"))
name_split = (basename(file) %>% str_split("__"))[[1]]
# if (str_detect(name_split[1], "gpt-oss")) next
method_index = which(str_starts((basename(file) %>% str_split("__"))[[1]], "loop"))-1
# print(name_split)
results <-  json_data$results %>% as_tibble()
if (nrow(results) == 0) {
error_list <-  c(error_list, file)
next
}
# for (idx in 1:nrow(results)) {
#   print(idx)
#   # try()
#   fromJSON(results$df_joined[[idx]])
# }
#
# results$df_joined[[16]]
results <-  results %>% rowwise() %>%
mutate(
extractor = "docling",
input_format = "text",
model = name_split[1],
method = name_split[method_index],
n_examples = str_match(method, "\\d+")[[1]],
out_of_company = if_else(str_detect(method, "rag"), str_detect(basename(file), "out_of_sample") == TRUE, NA),
method_family = str_replace(str_replace(method, '\\d+', 'n'), '_out_of_sample', ''),
loop = as.numeric((basename(file) %>% str_match("loop_(.)(_queued)?\\.json"))[2]),
predictions = list(try(fromJSON(df_joined)) %>% as_tibble()),
request_tokens = list(json_data$request_tokens),
runtime = json_data$runtime
) %>% select(-df_joined)
# results$predictions <- predictions
meta_list_llm[[length(meta_list_llm) + 1]] <- results
}
df_docling_txt <- bind_rows(meta_list_llm) %>% select(!starts_with("changed_values")) %>%
filter(grammar_error != TRUE || is.na(grammar_error)) %>%
unnest_wider(`NA`, names_sep = "_") %>%
unnest_wider(`relative_numeric_difference`, names_sep = "_") %>%
unnest_wider(`levenstein_distance`, names_sep = "_") %>%
# rename_with(~ gsub("^NA_", "NA_", .x)) %>%  # Ensures prefix is NA_
mutate(
NA_total_truth = NA_true_positive + NA_false_negative,
NA_precision = if_else(NA_total_truth > 0, if_else((NA_true_positive + NA_false_positive)>0, NA_true_positive/(NA_true_positive + NA_false_positive), 0), NA),
NA_recall = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_negative), NA),
NA_F1 = if_else((NA_precision + NA_recall) > 0, (2 * NA_precision * NA_recall)/(NA_precision + NA_recall), 0),
percentage_correct_numeric = if_else((correct_numeric + incorrect_numeric)>0, correct_numeric/(correct_numeric + incorrect_numeric), 0),
percentage_correct_total = (correct_numeric + NA_true_positive)/total_entries
) %>% mutate(
model = str_replace(model, "_vllm", ""),
method = str_replace(method, '_out_of_sample', ''),
model_family = sub("_.*", "", model),
model_family = if_else(str_detect(model, "Qwen2"), "Qwen 2.5", model_family),
model_family = if_else(str_detect(model, "Qwen3"), "Qwen 3", model_family),
model_family = if_else(str_detect(model, "Llama-3"), "Llama-3", model_family),
model_family = if_else(str_detect(model, "Llama-4"), "Llama-4", model_family)
) %>% mutate(
n_examples = as.numeric(n_examples),
n_examples = if_else(method_family == "zero_shot", 0, n_examples),
n_examples = if_else(method_family == "static_example", 1, n_examples)
) %>% mutate(
filepath = str_replace(filepath, "/pvc/benchmark_truth/real_tables_extended/Tempelhof Projekt GmbH __", "/pvc/benchmark_truth/real_tables_extended/Tempelhof Projekt GmbH__")
)
##### combine #####
df_qwen235 <- bind_rows(
df_docling_md,
df_docling_txt,
df_pdfium_txt,
df_pymupdf_md,
df_pymupdf_txt
)
df_qwen235 %>% group_by(model, method, extractor, input_format) %>%
mutate(mean_total = mean(percentage_correct_total)) %>%
group_by(model, extractor, input_format) %>%
slice_max(n = 1, mean_total)
df_qwen235 %>% group_by(model, method, extractor, input_format) %>%
mutate(mean_total = mean(percentage_correct_total)) %>%
group_by(model, extractor, input_format) %>%
slice_max(n = 1, mean_total) %>%
select(model, extractor, input_format, mean_total)
df_qwen235 %>% group_by(model, method, extractor, input_format) %>%
mutate(mean_total = mean(percentage_correct_total)) %>%
group_by(model, extractor, input_format) %>%
slice_max(n = 1, mean_total) %>%
select(model, extractor, input_format, mean_total) %>%
summarise(n())
df_qwen235 %>% group_by(model, method, extractor, input_format) %>%
mutate(mean_total = mean(percentage_correct_total)) %>%
group_by(model, extractor, input_format, filepath) %>%
slice_max(n = 1, mean_total, with_ties = FALSE) %>%
select(model, extractor, input_format, mean_total, filepath) %>%
summarise(n())
df_qwen235 %>% group_by(model, method, extractor, input_format) %>%
mutate(mean_total = mean(percentage_correct_total)) %>%
group_by(model, extractor, input_format, filepath) %>%
slice_max(n = 1, mean_total, with_ties = FALSE) %>%
select(model, extractor, input_format, mean_total, filepath) %>%
group_by(model, extractor, input_format)
df_qwen235 %>% group_by(model, method, extractor, input_format) %>%
mutate(mean_total = mean(percentage_correct_total)) %>%
group_by(model, extractor, input_format, filepath) %>%
slice_max(n = 1, mean_total, with_ties = FALSE) %>%
select(model, extractor, input_format, mean_total, filepath) %>%
group_by(model, extractor, input_format) %>%
summarise(n())
df_qwen235 %>% group_by(model, method, extractor, input_format) %>%
mutate(mean_total = mean(percentage_correct_total)) %>%
group_by(model, extractor, input_format, filepath) %>%
slice_max(n = 1, mean_total, with_ties = FALSE) %>%
select(model, method, extractor, input_format, mean_total, filepath) %>%
group_by(model, method, extractor, input_format) %>%
summarise(n())
df_qwen235 %>% group_by(model, method, extractor, input_format) %>%
mutate(mean_total = mean(percentage_correct_total)) %>%
group_by(model, extractor, input_format, filepath) %>%
slice_max(n = 1, mean_total, with_ties = FALSE) %>%
select(model, method, extractor, input_format, mean_total, filepath) #%>%
df_qwen235 %>% group_by(model, method, extractor, input_format) %>%
mutate(mean_total = mean(percentage_correct_total)) %>%
group_by(model, extractor, input_format, filepath) %>%
slice_max(n = 1, mean_total, with_ties = FALSE) %>%
# select(model, method, extractor, input_format, mean_total, filepath) %>%
ggplot() +
geom_boxplot(aes(x = 1, y = percentage_correct_total)) +
facet_nested(extractor+input_format~.)
df_qwen235 %>% group_by(model, method, extractor, input_format) %>%
mutate(mean_total = mean(percentage_correct_total)) %>%
group_by(model, extractor, input_format, filepath) %>%
slice_max(n = 1, mean_total, with_ties = FALSE) %>%
# select(model, method, extractor, input_format, mean_total, filepath) %>%
ggplot() +
geom_boxplot(aes(x = 1, y = percentage_correct_total)) +
facet_nested(.~extractor+input_format)
df_qwen235 %>% group_by(model, method, extractor, input_format) %>%
summarize(mean_total = mean(percentage_correct_total)) %>%
group_by(model, extractor, input_format) %>%
slice_max(n = 1, mean_total, with_ties = FALSE)
df_qwen235 <- bind_rows(
df_docling_md,
df_docling_txt,
df_pdfium_txt,
df_pymupdf_md,
df_pymupdf_txt
) %>% mutate(
model = gsub("^[^_]+_", "", model),
company = map_chr(filepath, ~str_split(str_split(., "/")[[1]][5], "__")[[1]][1])
) %>% filter(company != "MEAB GmbH")
df_qwen235 %>% group_by(model, method, extractor, input_format) %>%
mutate(mean_total = mean(percentage_correct_total)) %>%
group_by(model, extractor, input_format, filepath) %>%
slice_max(n = 1, mean_total, with_ties = FALSE) %>%
# select(model, method, extractor, input_format, mean_total, filepath) %>%
ggplot() +
geom_boxplot(aes(x = 1, y = percentage_correct_total)) +
facet_nested(.~extractor+input_format)
df_qwen235 %>% group_by(model, method, extractor, input_format) %>%
summarize(mean_total = mean(percentage_correct_total)) %>%
group_by(model, extractor, input_format) %>%
slice_max(n = 1, mean_total, with_ties = FALSE)
df_qwen235 %>% group_by(model, method, extractor, input_format) %>%
mutate(mean_total = mean(percentage_correct_total)) %>%
group_by(model, extractor, input_format, filepath) %>%
slice_max(n = 1, mean_total, with_ties = FALSE) %>%
# select(model, method, extractor, input_format, mean_total, filepath) %>%
ggplot() +
geom_boxplot(aes(x = 1, y = percentage_correct_total)) +
facet_nested(extractor+input_format~company)
df_qwen235 %>% group_by(model, method, extractor, input_format) %>%
mutate(mean_total = mean(percentage_correct_total)) %>%
group_by(model, extractor, input_format, filepath) %>%
slice_max(n = 1, mean_total, with_ties = FALSE) %>%
# select(model, method, extractor, input_format, mean_total, filepath) %>%
ggplot() +
geom_boxplot(aes(x = company, y = percentage_correct_total)) +
facet_nested(extractor+input_format~.)
df_qwen235 %>% group_by(model, method, extractor, input_format) %>%
mutate(mean_total = mean(percentage_correct_total)) %>%
group_by(model, extractor, input_format, filepath) %>%
slice_max(n = 1, mean_total, with_ties = FALSE) %>%
# select(model, method, extractor, input_format, mean_total, filepath) %>%
ggplot() +
geom_boxplot(aes(x = company, y = percentage_correct_total)) +
facet_nested(extractor+input_format~.) +
scale_x_discrete(guide = guide_axis(angle = 30))
json_files_table_extraction_llm <- list.files(
"../benchmark_results/table_extraction/llm/final/real_tables_more_examples_pymupdf_markdown/",
pattern = "\\.json$",
full.names = TRUE
) %>%
.[!grepl("_test_", .)] %>%
.[!grepl("synth", .)]
meta_list_llm <- list()
error_list <- c()
# Loop through each .json file
for (file in json_files_table_extraction_llm) {
# print(file)
# Read the JSON file
# Read the JSON file and replace NaN with NULL in the file content
file_content <- readLines(file, warn = FALSE)
file_content <- gsub("\\bNaN\\b", "null", file_content)
file_content <- gsub("\\bInfinity\\b", "null", file_content)
# Remove incomplete last JSON entry and close the list if file ends early
# if (!grepl("\\]$", file_content[length(file_content)])) {
#   # Find the last complete JSON object (ends with "},")
#   last_complete <- max(grep('\\.pdf', file_content))
#   file_content <- c(file_content[1:last_complete], "}]")
# }
json_data <- fromJSON(paste(file_content, collapse = "\n"))
name_split = (basename(file) %>% str_split("__"))[[1]]
# if (str_detect(name_split[1], "gpt-oss")) next
method_index = which(str_starts((basename(file) %>% str_split("__"))[[1]], "loop"))-1
# print(name_split)
results <-  json_data$results %>% as_tibble()
if (nrow(results) == 0 | 'none_type_error' %in% colnames(json_data$results)) {
error_list <-  c(error_list, file)
next
}
# for (idx in 1:nrow(results)) {
#   print(idx)
#   # try()
#   fromJSON(results$df_joined[[idx]])
# }
#
# results$df_joined[[16]]
results <-  results %>% rowwise() %>%
mutate(
extractor = "pymupdf",
input_format = "markdown",
model = name_split[1],
method = name_split[method_index],
n_examples = str_match(method, "\\d+")[[1]],
out_of_company = if_else(str_detect(method, "rag"), str_detect(basename(file), "out_of_sample") == TRUE, NA),
method_family = str_replace(str_replace(method, '\\d+', 'n'), '_out_of_sample', ''),
loop = as.numeric((basename(file) %>% str_match("loop_(.)(_queued)?\\.json"))[2]),
predictions = list(try(fromJSON(df_joined)) %>% as_tibble()),
request_tokens = list(json_data$request_tokens),
runtime = json_data$runtime
) %>% select(-df_joined)
# results$predictions <- predictions
meta_list_llm[[length(meta_list_llm) + 1]] <- results
}
df_pymupdf_md <- bind_rows(meta_list_llm) %>% select(!starts_with("changed_values")) %>%
filter(grammar_error != TRUE || is.na(grammar_error)) %>%
unnest_wider(`NA`, names_sep = "_") %>%
unnest_wider(`relative_numeric_difference`, names_sep = "_") %>%
unnest_wider(`levenstein_distance`, names_sep = "_") %>%
# rename_with(~ gsub("^NA_", "NA_", .x)) %>%  # Ensures prefix is NA_
mutate(
NA_total_truth = NA_true_positive + NA_false_negative,
NA_precision = if_else(NA_total_truth > 0, if_else((NA_true_positive + NA_false_positive)>0, NA_true_positive/(NA_true_positive + NA_false_positive), 0), NA),
NA_recall = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_negative), NA),
NA_F1 = if_else((NA_precision + NA_recall) > 0, (2 * NA_precision * NA_recall)/(NA_precision + NA_recall), 0),
percentage_correct_numeric = if_else((correct_numeric + incorrect_numeric)>0, correct_numeric/(correct_numeric + incorrect_numeric), 0),
percentage_correct_total = (correct_numeric + NA_true_positive)/total_entries
) %>% mutate(
model = str_replace(model, "_vllm", ""),
method = str_replace(method, '_out_of_sample', ''),
model_family = sub("_.*", "", model),
model_family = if_else(str_detect(model, "Qwen2"), "Qwen 2.5", model_family),
model_family = if_else(str_detect(model, "Qwen3"), "Qwen 3", model_family),
model_family = if_else(str_detect(model, "Llama-3"), "Llama-3", model_family),
model_family = if_else(str_detect(model, "Llama-4"), "Llama-4", model_family)
) %>% mutate(
n_examples = as.numeric(n_examples),
n_examples = if_else(method_family == "zero_shot", 0, n_examples),
n_examples = if_else(method_family == "static_example", 1, n_examples)
) %>% mutate(
filepath = str_replace(filepath, "/pvc/benchmark_truth/real_tables_extended/Tempelhof Projekt GmbH __", "/pvc/benchmark_truth/real_tables_extended/Tempelhof Projekt GmbH__")
)
df_qwen235 <- bind_rows(
df_docling_md,
df_docling_txt,
df_pdfium_txt,
df_pymupdf_md,
df_pymupdf_txt
) %>% mutate(
model = gsub("^[^_]+_", "", model),
company = map_chr(filepath, ~str_split(str_split(., "/")[[1]][5], "__")[[1]][1])
) %>% filter(company != "MEAB GmbH")
df_qwen235 %>% group_by(model, method, extractor, input_format) %>%
mutate(mean_total = mean(percentage_correct_total)) %>%
group_by(model, extractor, input_format, filepath) %>%
slice_max(n = 1, mean_total, with_ties = FALSE) %>%
# select(model, method, extractor, input_format, mean_total, filepath) %>%
ggplot() +
geom_boxplot(aes(x = company, y = percentage_correct_total)) +
facet_nested(extractor+input_format~.) +
scale_x_discrete(guide = guide_axis(angle = 30))
df_qwen235 %>% group_by(model, method, extractor, input_format) %>%
summarize(mean_total = mean(percentage_correct_total)) %>%
group_by(model, extractor, input_format) %>%
slice_max(n = 1, mean_total, with_ties = FALSE)
