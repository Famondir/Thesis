# n_examples = str_match(method, "\\d+")[[1]],
# out_of_company = if_else(str_detect(method, "rag"), str_detect(method, "out_of_company"), NA),
# method_family = str_replace(str_replace(method, '\\d+', 'n'), '_out_of_company', ''),
# loop = as.numeric((basename(file) %>% str_match("loop_(.)(_queued)?\\.json"))[2]),
predictions = list(fromJSON(df_joined) %>% as_tibble())
) %>% select(-df_joined)
# results$predictions <- predictions
meta_list_llm[[length(meta_list_llm) + 1]] <- results
}
df <- bind_rows(meta_list_llm) %>% select(!starts_with("changed_values")) %>%
filter(grammar_error != TRUE || is.na(grammar_error)) %>%
unnest_wider(`NA`, names_sep = "_") %>%
unnest_wider(`relative_numeric_difference`, names_sep = "_") %>%
unnest_wider(`levenstein_distance`, names_sep = "_") %>%
# rename_with(~ gsub("^NA_", "NA_", .x)) %>%  # Ensures prefix is NA_
mutate(
NA_total_truth = NA_true_positive + NA_false_negative,
NA_precision = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_positive), NA),
NA_recall = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_negative), NA),
NA_F1 = if_else((NA_precision + NA_recall) > 0, (2 * NA_precision * NA_recall)/(NA_precision + NA_recall), 0),
percentage_correct_numeric = correct_numeric/(correct_numeric + incorrect_numeric),
percentage_correct_total = (correct_numeric + NA_true_positive)/total_entries
) %>% mutate(
filepath = if_else(filepath == "../../benchmark_truth/real_tables/Tempelhof Projekt GmbH __TP_Geschaeftsbericht_2020.xlsx", "../../benchmark_truth/real_tables/Tempelhof Projekt GmbH__TP_Geschaeftsbericht_2020.xlsx", filepath)
)
units_real_tables <- read_csv("../benchmark_truth/real_tables/table_characteristics.csv") %>% mutate(
filepath = paste0('../../benchmark_truth/real_tables/', company, '__', str_replace(filename, '.pdf', '.xlsx')),
T_EUR = (T_in_year + T_in_previous_year)>0
) %>% select(filepath, T_EUR)
df <- df %>% left_join(units_real_tables) %>% mutate(
n_columns = str_match(filepath, "(\\d)_columns")[,2],
header_span = str_match(filepath, "span_(False|True)")[,2] == "True",
thin = str_match(filepath, "thin_(False|True)")[,2] == "True",
year_as = str_match(filepath, "year_as_(.*)__unit")[,2],
unit_in_first_cell = str_match(filepath, "unit_in_first_cell_(False|True)")[,2] == "True",
unit_str = str_match(filepath, "unit_in_first_cell_(False|True)__(.*)__enumeration")[,3],
enumeration = str_match(filepath, "enumeration_(False|True)")[,2] == "True",
shuffle_rows = str_match(filepath, "shuffle_(False|True)")[,2] == "True",
text_around = str_match(filepath, "text_around_(False|True)")[,2] == "True",
max_line_length = str_match(filepath, "max_length_(\\d+)")[,2],
sum_same_line = str_match(filepath, "sum_in_same_row_(False|True)")[,2] == "True"
) %>%
left_join(unit_list, by = c("unit_str" = "unit")) %>%
mutate(
unit_multiplier = multiplier
) %>%
select(-multiplier) %>%
mutate(
n_columns = as.character(n_columns, c("3", "4", "5"))
) %>% mutate(
many_line_breaks = if_else(max_line_length == 50, TRUE, FALSE),
log10_unit_multiplier = log10(unit_multiplier)
)
df <- bind_rows(meta_list_llm) %>% select(!starts_with("changed_values")) %>%
filter(grammar_error != TRUE || is.na(grammar_error)) %>%
unnest_wider(`NA`, names_sep = "_") %>%
unnest_wider(`relative_numeric_difference`, names_sep = "_") %>%
unnest_wider(`levenstein_distance`, names_sep = "_") %>%
# rename_with(~ gsub("^NA_", "NA_", .x)) %>%  # Ensures prefix is NA_
mutate(
NA_total_truth = NA_true_positive + NA_false_negative,
NA_precision = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_positive), NA),
NA_recall = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_negative), NA),
NA_F1 = if_else((NA_precision + NA_recall) > 0, (2 * NA_precision * NA_recall)/(NA_precision + NA_recall), 0),
percentage_correct_numeric = correct_numeric/(correct_numeric + incorrect_numeric),
percentage_correct_total = (correct_numeric + NA_true_positive)/total_entries
) %>% mutate(
filepath = if_else(filepath == "../../benchmark_truth/real_tables/Tempelhof Projekt GmbH __TP_Geschaeftsbericht_2020.xlsx", "../../benchmark_truth/real_tables/Tempelhof Projekt GmbH__TP_Geschaeftsbericht_2020.xlsx", filepath)
)
df <- bind_rows(meta_list_llm) %>% select(!starts_with("changed_values")) %>%
filter(grammar_error != TRUE || is.na(grammar_error)) %>%
unnest_wider(`NA`, names_sep = "_") %>%
unnest_wider(`relative_numeric_difference`, names_sep = "_") %>%
unnest_wider(`levenstein_distance`, names_sep = "_") %>%
# rename_with(~ gsub("^NA_", "NA_", .x)) %>%  # Ensures prefix is NA_
mutate(
NA_total_truth = NA_true_positive + NA_false_negative,
NA_precision = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_positive), NA),
NA_recall = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_negative), NA),
NA_F1 = if_else((NA_precision + NA_recall) > 0, (2 * NA_precision * NA_recall)/(NA_precision + NA_recall), 0),
percentage_correct_numeric = correct_numeric/(correct_numeric + incorrect_numeric),
percentage_correct_total = (correct_numeric + NA_true_positive)/total_entries
) %>% mutate(
filepath = if_else(filepath == "../../benchmark_truth/real_tables/Tempelhof Projekt GmbH __TP_Geschaeftsbericht_2020.xlsx", "../../benchmark_truth/real_tables/Tempelhof Projekt GmbH__TP_Geschaeftsbericht_2020.xlsx", filepath)
)
df$model
meta_list_llm <- list()
# Loop through each .json file
for (file in json_files_table_extraction_regex) {
# print(file)
# Read the JSON file
# Read the JSON file and replace NaN with NULL in the file content
file_content <- readLines(file, warn = FALSE)
file_content <- gsub("\\bNaN\\b", "null", file_content)
file_content <- gsub("\\bInfinity\\b", "null", file_content)
# Remove incomplete last JSON entry and close the list if file ends early
if (!grepl("\\]$", file_content[length(file_content)])) {
# Find the last complete JSON object (ends with "},")
last_complete <- max(grep('\\.pdf', file_content))
file_content <- c(file_content[1:last_complete], "}]")
}
json_data <- fromJSON(paste(file_content, collapse = "\n"))
name_split = (basename(file) %>% str_remove(".json") %>% str_split("__"))[[1]]
# method_index = which(str_starts((basename(file) %>% str_split("__"))[[1]], "loop"))-1
# print(name_split)
results <-  json_data %>% as_tibble() %>% rowwise() %>%
mutate(
table_type = name_split[2],
# model = name_split[1],
extraction_backend = name_split[3],
# n_examples = str_match(method, "\\d+")[[1]],
# out_of_company = if_else(str_detect(method, "rag"), str_detect(method, "out_of_company"), NA),
# method_family = str_replace(str_replace(method, '\\d+', 'n'), '_out_of_company', ''),
# loop = as.numeric((basename(file) %>% str_match("loop_(.)(_queued)?\\.json"))[2]),
predictions = list(fromJSON(df_joined) %>% as_tibble())
) %>% select(-df_joined)
# results$predictions <- predictions
meta_list_llm[[length(meta_list_llm) + 1]] <- results
}
df <- bind_rows(meta_list_llm) %>% select(!starts_with("changed_values")) %>%
filter(grammar_error != TRUE || is.na(grammar_error)) %>%
unnest_wider(`NA`, names_sep = "_") %>%
unnest_wider(`relative_numeric_difference`, names_sep = "_") %>%
unnest_wider(`levenstein_distance`, names_sep = "_") %>%
# rename_with(~ gsub("^NA_", "NA_", .x)) %>%  # Ensures prefix is NA_
mutate(
NA_total_truth = NA_true_positive + NA_false_negative,
NA_precision = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_positive), NA),
NA_recall = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_negative), NA),
NA_F1 = if_else((NA_precision + NA_recall) > 0, (2 * NA_precision * NA_recall)/(NA_precision + NA_recall), 0),
percentage_correct_numeric = correct_numeric/(correct_numeric + incorrect_numeric),
percentage_correct_total = (correct_numeric + NA_true_positive)/total_entries
) %>% mutate(
filepath = if_else(filepath == "../../benchmark_truth/real_tables/Tempelhof Projekt GmbH __TP_Geschaeftsbericht_2020.xlsx", "../../benchmark_truth/real_tables/Tempelhof Projekt GmbH__TP_Geschaeftsbericht_2020.xlsx", filepath)
)
units_real_tables <- read_csv("../benchmark_truth/real_tables/table_characteristics.csv") %>% mutate(
filepath = paste0('../../benchmark_truth/real_tables/', company, '__', str_replace(filename, '.pdf', '.xlsx')),
T_EUR = (T_in_year + T_in_previous_year)>0
) %>% select(filepath, T_EUR)
df <- df %>% left_join(units_real_tables) %>% mutate(
n_columns = str_match(filepath, "(\\d)_columns")[,2],
header_span = str_match(filepath, "span_(False|True)")[,2] == "True",
thin = str_match(filepath, "thin_(False|True)")[,2] == "True",
year_as = str_match(filepath, "year_as_(.*)__unit")[,2],
unit_in_first_cell = str_match(filepath, "unit_in_first_cell_(False|True)")[,2] == "True",
unit_str = str_match(filepath, "unit_in_first_cell_(False|True)__(.*)__enumeration")[,3],
enumeration = str_match(filepath, "enumeration_(False|True)")[,2] == "True",
shuffle_rows = str_match(filepath, "shuffle_(False|True)")[,2] == "True",
text_around = str_match(filepath, "text_around_(False|True)")[,2] == "True",
max_line_length = str_match(filepath, "max_length_(\\d+)")[,2],
sum_same_line = str_match(filepath, "sum_in_same_row_(False|True)")[,2] == "True"
) %>%
left_join(unit_list, by = c("unit_str" = "unit")) %>%
mutate(
unit_multiplier = multiplier
) %>%
select(-multiplier) %>%
mutate(
n_columns = as.character(n_columns, c("3", "4", "5"))
) %>% mutate(
many_line_breaks = if_else(max_line_length == 50, TRUE, FALSE),
log10_unit_multiplier = log10(unit_multiplier)
)
df %>% saveRDS("data_storage/table_extraction_regex.rds")
table_characteristics <- read.csv("../benchmark_truth/real_tables/table_characteristics.csv") %>%
mutate(
filepath = paste0("../../benchmark_truth/real_tables/", company, "__", filename) %>% str_replace(".pdf", ".xlsx")
) %>% as_tibble()
df_characteristics <- df %>%
#   rowwise() %>% mutate(
#   mean_tokens = mean(request_tokens[[1]])
# ) %>%
# select(
#   filepath,
#   method_family, model_family,
#   percentage_correct_total,
#   n_examples,
#   model, method,
#   mean_tokens
# ) %>%
left_join(table_characteristics, by = "filepath") %>% ungroup()
df2 <- df_characteristics %>%
unnest(predictions) %>%
mutate(
.before = 1,
match_this_year = (is.na(year_truth) & is.na(year_result)) | year_truth == year_result,
match_this_year = if_else(is.na(match_this_year), FALSE, match_this_year),
missing_this_year = is.na(year_truth),
match_previous_year = (is.na(previous_year_truth) & is.na(previous_year_result)) | previous_year_truth == previous_year_result,
match_previous_year = if_else(is.na(match_previous_year), FALSE, match_previous_year),
missing_previous_year = is.na(previous_year_truth),
label_length = if_else(!is.na(E3), nchar(E3), if_else(!is.na(E2), nchar(E2), nchar(E1))),
label = factor(paste(E1, E2, E3))
) %>%
# sample_n(min(2*sample_size, nrow(df_characteristics))) %>%
pivot_longer(
cols = c(starts_with("match")),
values_to = "match",
names_to = "year", names_prefix = "match_"
) %>% mutate(
.before = 1,
missing = if_else(year == "this_year", missing_this_year, missing_previous_year)
) %>%
group_by(match) %>% slice_sample(n = sample_size/2) %>% mutate(
match = factor(match)
)
df <- readRDS("data_storage/table_extraction_regex.rds") %>% filter(
table_type == "real_tables"
)
table_characteristics <- read.csv("../benchmark_truth/real_tables/table_characteristics.csv") %>%
mutate(
filepath = paste0("../../benchmark_truth/real_tables/", company, "__", filename) %>% str_replace(".pdf", ".xlsx")
) %>% as_tibble()
df_characteristics <- df %>%
#   rowwise() %>% mutate(
#   mean_tokens = mean(request_tokens[[1]])
# ) %>%
# select(
#   filepath,
#   method_family, model_family,
#   percentage_correct_total,
#   n_examples,
#   model, method,
#   mean_tokens
# ) %>%
left_join(table_characteristics, by = "filepath") %>% ungroup()
df2 <- df_characteristics %>%
unnest(predictions) %>%
mutate(
.before = 1,
match_this_year = (is.na(year_truth) & is.na(year_result)) | year_truth == year_result,
match_this_year = if_else(is.na(match_this_year), FALSE, match_this_year),
missing_this_year = is.na(year_truth),
match_previous_year = (is.na(previous_year_truth) & is.na(previous_year_result)) | previous_year_truth == previous_year_result,
match_previous_year = if_else(is.na(match_previous_year), FALSE, match_previous_year),
missing_previous_year = is.na(previous_year_truth),
label_length = if_else(!is.na(E3), nchar(E3), if_else(!is.na(E2), nchar(E2), nchar(E1))),
label = factor(paste(E1, E2, E3))
) %>%
# sample_n(min(2*sample_size, nrow(df_characteristics))) %>%
pivot_longer(
cols = c(starts_with("match")),
values_to = "match",
names_to = "year", names_prefix = "match_"
) %>% mutate(
.before = 1,
missing = if_else(year == "this_year", missing_this_year, missing_previous_year)
) %>%
group_by(match) %>% slice_sample(n = sample_size/2) %>% mutate(
match = factor(match)
)
formula_binomial_pdf = match ~
# method_family +
# n_examples +
# model_family +
extraction_backend +
# parameter_count +
n_columns +
# n_columns:input_format +
sum_same_line +
# sum_same_line:input_format +
header_span +
# header_span:input_format +
# header_span:respect_units +
# thin +
# respect_units +
# respect_units:input_format +
# input_format +
# year_as +
# unit_in_first_cell +
# unit_in_first_cell:input_format +
# log10_unit_multiplier +
# log10_unit_multiplier:input_format +
enumeration +
# shuffle_rows +
# text_around +
# many_line_breaks +
# many_line_breaks:input_format
T_in_previous_year +
T_in_year +
passiva_same_page +
# spacer +
vorjahr +
vis_seperated_cols +
vis_seperated_rows +
label_length +
label +
missing
df_modeling_binomial_pdf <- df2 %>% select(all.vars(formula_binomial_pdf)) %>%
mutate(across(where(is.character), as.factor))
df_characteristics %>% colnames()
library(jsonlite)
library(tidyverse)
unit_list = tribble(
~unit, ~multiplier,
'EUR', 1,
'€', 1,
'Tsd. EUR', 1000,
'Mio. EUR', 1000000,
'TEUR', 1000,
'T€', 1000,
'Tsd. €', 1000,
'Mio. €', 1000000
)
#### Regex ####
json_files_table_extraction_regex <- list.files(
"../benchmark_results/table_extraction/regex/",
pattern = "\\.json$",
full.names = TRUE
) %>%
.[!grepl("_test_", .)]
meta_list_llm <- list()
# Loop through each .json file
for (file in json_files_table_extraction_regex) {
# print(file)
# Read the JSON file
# Read the JSON file and replace NaN with NULL in the file content
file_content <- readLines(file, warn = FALSE)
file_content <- gsub("\\bNaN\\b", "null", file_content)
file_content <- gsub("\\bInfinity\\b", "null", file_content)
# Remove incomplete last JSON entry and close the list if file ends early
if (!grepl("\\]$", file_content[length(file_content)])) {
# Find the last complete JSON object (ends with "},")
last_complete <- max(grep('\\.pdf', file_content))
file_content <- c(file_content[1:last_complete], "}]")
}
json_data <- fromJSON(paste(file_content, collapse = "\n"))
name_split = (basename(file) %>% str_remove(".json") %>% str_split("__"))[[1]]
# method_index = which(str_starts((basename(file) %>% str_split("__"))[[1]], "loop"))-1
# print(name_split)
results <-  json_data %>% as_tibble() %>% rowwise() %>%
mutate(
table_type = name_split[2],
# model = name_split[1],
extraction_backend = name_split[3],
# n_examples = str_match(method, "\\d+")[[1]],
# out_of_company = if_else(str_detect(method, "rag"), str_detect(method, "out_of_company"), NA),
# method_family = str_replace(str_replace(method, '\\d+', 'n'), '_out_of_company', ''),
# loop = as.numeric((basename(file) %>% str_match("loop_(.)(_queued)?\\.json"))[2]),
predictions = list(fromJSON(df_joined) %>% as_tibble())
) %>% select(-df_joined)
# results$predictions <- predictions
meta_list_llm[[length(meta_list_llm) + 1]] <- results
}
df <- bind_rows(meta_list_llm) %>% select(!starts_with("changed_values")) %>%
filter(grammar_error != TRUE || is.na(grammar_error)) %>%
unnest_wider(`NA`, names_sep = "_") %>%
unnest_wider(`relative_numeric_difference`, names_sep = "_") %>%
unnest_wider(`levenstein_distance`, names_sep = "_") %>%
# rename_with(~ gsub("^NA_", "NA_", .x)) %>%  # Ensures prefix is NA_
mutate(
NA_total_truth = NA_true_positive + NA_false_negative,
NA_precision = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_positive), NA),
NA_recall = if_else(NA_total_truth > 0, NA_true_positive/(NA_true_positive + NA_false_negative), NA),
NA_F1 = if_else((NA_precision + NA_recall) > 0, (2 * NA_precision * NA_recall)/(NA_precision + NA_recall), 0),
percentage_correct_numeric = correct_numeric/(correct_numeric + incorrect_numeric),
percentage_correct_total = (correct_numeric + NA_true_positive)/total_entries
) %>% mutate(
filepath = if_else(filepath == "../../benchmark_truth/real_tables/Tempelhof Projekt GmbH __TP_Geschaeftsbericht_2020.xlsx", "../../benchmark_truth/real_tables/Tempelhof Projekt GmbH__TP_Geschaeftsbericht_2020.xlsx", filepath)
)
units_real_tables <- read_csv("../benchmark_truth/real_tables/table_characteristics.csv") %>% mutate(
filepath = paste0('../../benchmark_truth/real_tables/', company, '__', str_replace(filename, '.pdf', '.xlsx')),
T_EUR = (T_in_year + T_in_previous_year)>0
) %>% select(filepath, T_EUR)
df <- df %>% left_join(units_real_tables)
df %>% saveRDS("data_storage/table_extraction_regex.rds")
df <- readRDS("data_storage/table_extraction_regex.rds") %>% filter(
table_type == "real_tables"
)
table_characteristics <- read.csv("../benchmark_truth/real_tables/table_characteristics.csv") %>%
mutate(
filepath = paste0("../../benchmark_truth/real_tables/", company, "__", filename) %>% str_replace(".pdf", ".xlsx")
) %>% as_tibble()
df_characteristics <- df %>%
#   rowwise() %>% mutate(
#   mean_tokens = mean(request_tokens[[1]])
# ) %>%
# select(
#   filepath,
#   method_family, model_family,
#   percentage_correct_total,
#   n_examples,
#   model, method,
#   mean_tokens
# ) %>%
left_join(table_characteristics, by = "filepath") %>% ungroup()
library(shapviz)
df2 <- df_characteristics %>%
unnest(predictions) %>%
mutate(
.before = 1,
match_this_year = (is.na(year_truth) & is.na(year_result)) | year_truth == year_result,
match_this_year = if_else(is.na(match_this_year), FALSE, match_this_year),
missing_this_year = is.na(year_truth),
match_previous_year = (is.na(previous_year_truth) & is.na(previous_year_result)) | previous_year_truth == previous_year_result,
match_previous_year = if_else(is.na(match_previous_year), FALSE, match_previous_year),
missing_previous_year = is.na(previous_year_truth),
label_length = if_else(!is.na(E3), nchar(E3), if_else(!is.na(E2), nchar(E2), nchar(E1))),
label = factor(paste(E1, E2, E3))
) %>%
# sample_n(min(2*sample_size, nrow(df_characteristics))) %>%
pivot_longer(
cols = c(starts_with("match")),
values_to = "match",
names_to = "year", names_prefix = "match_"
) %>% mutate(
.before = 1,
missing = if_else(year == "this_year", missing_this_year, missing_previous_year)
) %>%
group_by(match) %>% slice_sample(n = sample_size/2) %>% mutate(
match = factor(match)
)
formula_binomial_pdf = match ~
# method_family +
# n_examples +
# model_family +
extraction_backend +
# parameter_count +
n_columns +
# n_columns:input_format +
sum_same_line +
# sum_same_line:input_format +
header_span +
# header_span:input_format +
# header_span:respect_units +
# thin +
# respect_units +
# respect_units:input_format +
# input_format +
# year_as +
# unit_in_first_cell +
# unit_in_first_cell:input_format +
# log10_unit_multiplier +
# log10_unit_multiplier:input_format +
enumeration +
# shuffle_rows +
# text_around +
# many_line_breaks +
# many_line_breaks:input_format
T_in_previous_year +
T_in_year +
passiva_same_page +
# spacer +
vorjahr +
vis_seperated_cols +
vis_seperated_rows +
label_length +
label +
missing
df_modeling_binomial_pdf <- df2 %>% select(all.vars(formula_binomial_pdf)) %>%
mutate(across(where(is.character), as.factor))
df_modeling_binomial_pdf.h2o <- as.h2o(df_modeling_binomial_pdf)
# Train-test split
set.seed(42)
split <- h2o.splitFrame(df_modeling_binomial_pdf.h2o, ratios = 0.7, seed = 42)
train <- split[[1]]
test <- split[[2]]
xvars <- colnames(df_modeling_binomial_pdf)[-1]
# Random forest
fit_rf_binomial <- h2o.randomForest(x = xvars, y = colnames(df_modeling_binomial_pdf)[1], training_frame = train, validation_frame = test)
shp_rf_binomial <- shapviz(fit_rf_binomial, X_pred = shap_test_sample)
# sv_force(shp_rf, row_id = 1)
# sv_dependence(shp_rf, xvars)
# sv_importance(shp_rf, show_numbers = TRUE)
sv_importance(shp_rf_binomial, kind = "beeswarm")
shap_test_sample <- as.h2o(test %>% as_tibble() %>% slice_sample(n = test_sample_size))
shp_rf_binomial <- shapviz(fit_rf_binomial, X_pred = shap_test_sample)
# sv_force(shp_rf, row_id = 1)
# sv_dependence(shp_rf, xvars)
# sv_importance(shp_rf, show_numbers = TRUE)
sv_importance(shp_rf_binomial, kind = "beeswarm")
sv_waterfall(1)
sv_waterfall(shp_rf_binomial, 1)
shap <- results$binomial$shap_values$rf
results <- readRDS("data_storage/h2o/synth_table_extraction_regex_h2o_results_sample_50000_shap_2000.rds")
shap <- results$binomial$shap_values$rf
df_shap <- tibble(
y = (shap$S %>% rowSums())+shap$baseline
) %>% bind_cols(shap$X) %>% rowid_to_column() %>%
arrange(y)
idx_lowest <- df_shap %>% pull(rowid)
shap %>% styled_waterfall(row_id = idx_lowest[1])
shap %>% sv_importance(kind = "beeswarm")
shap %>% sv_force(row_id = idx_lowest[1])
shap %>% sv_dependence(setdiff(colnames(.$X), "label"))
setdiff(colnames(.$X), "label")
shap %>% sv_dependence(setdiff(colnames(.$X), "label"), color_var = NULL)
shap %>% sv_dependence(setdiff(colnames(.$X), "label"), color_var = "extraction_backend")
# shap %>% sv_dependence("extraction_backend", color_var = "n_columns") # not so strong
shap %>% sv_dependence("label", color_var = "missing") +
theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
scale_x_discrete(labels = function(x) {
trimmed <- str_trim(str_sub(x, -40))
ifelse(nchar(x) > 40, paste0("...", trimmed), trimmed)
})
shap %>% sv_dependence("extraction_backend") # very interesting! (repeating)
shap %>% sv_dependence(setdiff(colnames(.$X), "label"), color_var = "extraction_backend")
shap %>% sv_importance(kind = "beeswarm")
shap %>% sv_dependence(setdiff(colnames(.$X), "label"), color_var = "extraction_backend")
shap %>% sv_dependence(setdiff(colnames(.$X), "label"), color_var = "missing")
results <- readRDS("data_storage/h2o/real_table_extraction_regex_h2o_results_sample_50000_shap_2000.rds")
shap <- results$NA_F1$shap_values$rf
shap$X <- shap$X %>% mutate(across(everything(), convert_binary)) %>% mutate(
n_columns = factor(n_columns+1)
)
shap %>% sv_dependence(colnames(.$X))
shap %>% sv_importance(kind = "beeswarm")
reticulate::repl_python()
reticulate::repl_python()
library(reticulate)
use_python("~/anaconda3/envs/llm/bin/python")
reticulate::repl_python()
