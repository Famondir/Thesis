install.packages("bookdown")
setwd("~/Dokumente/Data Science/Thesis/R")
tinytex::install_tinytex()
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
install.packages("bookdown")
tinytex::install_tinytex()
install.packages("tidyverse")
library(dplyr)
library(tidyr)
data <- read.csv("../benchmark_truth/aktiva_passiva_guv_table_pages.csv")
data
data %>%
arrange(filepath, page) %>%
group_by(filepath) %>%
mutate(next_page = lead(page))
data %>%
arrange(filepath, page) %>%
group_by(filepath) %>%
mutate(next_page = lead(page)) %>%
filter(
next_page == page + 1
) %>%
nrow()
data %>%
arrange(filepath, page) %>%
group_by(filepath) %>%
mutate(next_page = lead(page), next_type = lead(type)) %>%
filter(
next_page == page + 1 &
next_type = type
data %>%
arrange(filepath, page) %>%
group_by(filepath) %>%
mutate(next_page = lead(page), next_type = lead(type)) %>%
filter(
next_page == page + 1 &
next_type == type
) %>%
nrow()
data %>%
arrange(filepath, page) %>%
group_by(filepath, type) %>%
summarise(count)
data %>%
arrange(filepath, page) %>%
group_by(filepath, type) %>%
summarise(n)
data %>%
arrange(filepath, page) %>%
group_by(filepath, type) %>%
summarise(count = n())
data %>%
arrange(filepath, page) %>%
group_by(filepath, type) %>%
summarise(count = n()) %>%
filter(count > 1)
data %>%
arrange(filepath, page) %>%
group_by(filepath, type) %>%
summarise(count = n()) %>%
filter(count > 1) %>%
group_by(type) %>%
summarise(count = n())
data_unnnested <- data %>%
mutate(type = strsplit(as.character(type), "&")) %>%
unnest(type)
data_unnnested %>%
arrange(filepath, page) %>%
group_by(filepath, type) %>%
summarise(count = n()) %>%
filter(count > 1) %>%
group_by(type) %>%
summarise(count = n())
install.packages("DT")
data_unnested %>%
arrange(filepath, page) %>%
group_by(filepath, type) %>%
summarise(count = n()) %>%
filter(count > 1)
data_unnnested %>%
arrange(filepath, page) %>%
group_by(filepath, type) %>%
summarise(count = n()) %>%
filter(count > 1)
data_unnnested %>%
arrange(filepath, page) %>%
group_by(filepath, type) %>%
summarise(count = n()) %>%
filter(count > 1) %>% print(n=100)
data %>%
arrange(filepath, page) %>%
group_by(filepath) %>%
mutate(next_page = lead(page), next_type = lead(type)) %>%
filter(
next_page == page + 1 &
next_type == type
)
consecutive_pages <- data %>%
arrange(filepath, page) %>%
group_by(filepath) %>%
mutate(next_page = lead(page), next_type = lead(type)) %>%
filter(
next_page == page + 1 &
next_type == type
)
data_unnested <- data %>%
mutate(type = strsplit(as.character(type), "&")) %>%
unnest(type)
data_unnested
consecutive_pages
consecutive_pages %>% select(filepath, page, type)
data_unnested %>% anti_join(consecutive_pages, by = c("filepath", "page", "type"))
# Read the JSON file
library(jsonlite)
json_data <- fromJSON("../benchmark_results/page_identification/pymupdf_simple_regex.json")
# Convert the 'correct' element into a dataframe
correct_df <- as.data.frame(json_data$correct)
correct_df
json_data$runtime
json_data$correct
tibble(json_data$correct)
fromJSON(json_data$correct)
correct_df <- as.data.frame(fromJSON(json_data$correct))
correct_df
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
strsplit("fil_ename", "_")
strsplit("fil_ename", "_")[[1]]
strsplit("fil_ename", "_")[[1]][1]
install.packages("pdftools")
install.packages("pdftools")
data <- read.csv("../benchmark_truth/aktiva_passiva_guv_table_pages_no_ocr.csv")
data
data$filepath
data$filepath %>% distinct()
data$filepath %>% unique()
# Get a list of all PDF files in "Geschaeftsberichte" and its subfolders
pdf_files <- list.files("../Geschaeftsberichte/", pattern = "\\.pdf$", full.names = TRUE, recursive = TRUE)
pdf_files
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
library(tidyverse)
json_files_table_detection <- list.files("../benchmark_results/table_detection/", pattern = "\\.json$", full.names = TRUE)
meta_list <- list()
# Loop through each .json file
for (file in json_files_table_detection) {
# Read the JSON file
json_data <- fromJSON(file)
# Extract the threshold and metrics from the "metrics" key
metrics <- as.data.frame(fromJSON(json_data$metrics))
lst <- list()
lst['metrics'] = metrics
lst['model'] = basename(file)
lst['runtime'] = json_data$runtime
meta_list <- append(meta_list, list(lst))
}
library(jsonlite)
library(tidyverse)
meta_list <- list()
# Loop through each .json file
for (file in json_files_table_detection) {
# Read the JSON file
json_data <- fromJSON(file)
# Extract the threshold and metrics from the "metrics" key
metrics <- as.data.frame(fromJSON(json_data$metrics))
lst <- list()
lst['metrics'] = metrics
lst['model'] = basename(file)
lst['runtime'] = json_data$runtime
meta_list <- append(meta_list, list(lst))
}
meta_list[1]
lst
meta_list <- list()
# Loop through each .json file
for (file in json_files_table_detection) {
# Read the JSON file
json_data <- fromJSON(file)
# Extract the threshold and metrics from the "metrics" key
metrics <- as.data.frame(fromJSON(json_data$metrics))
lst <- list()
lst['metrics'] = metrics
lst['model'] = basename(file)
lst['runtime'] = json_data$runtime
meta_list <- append(meta_list, list(lst))
}
meta_list <- list()
# Loop through each .json file
for (file in json_files_table_detection) {
# Read the JSON file
json_data <- fromJSON(file)
# Extract the threshold and metrics from the "metrics" key
metrics <- as.data.frame(fromJSON(json_data$metrics))
print(metrics)
lst <- list()
lst['metrics'] = metrics
lst['model'] = basename(file)
lst['runtime'] = json_data$runtime
meta_list <- append(meta_list, list(lst))
}
meta_list <- list()
# Loop through each .json file
for (file in json_files_table_detection) {
# Read the JSON file
json_data <- fromJSON(file)
# Extract the threshold and metrics from the "metrics" key
metrics <- as.data.frame(fromJSON(json_data$metrics))
print(metrics)
lst <- list()
lst['metrics'] = as-list(metrics)
lst['model'] = basename(file)
lst['runtime'] = json_data$runtime
meta_list <- append(meta_list, list(lst))
}
meta_list <- list()
# Loop through each .json file
for (file in json_files_table_detection) {
# Read the JSON file
json_data <- fromJSON(file)
# Extract the threshold and metrics from the "metrics" key
metrics <- as.data.frame(fromJSON(json_data$metrics))
lst <- list()
lst['metrics'] = as-list(metrics)
lst['model'] = basename(file)
lst['runtime'] = json_data$runtime
meta_list <- append(meta_list, list(lst))
}
meta_list <- list()
# Loop through each .json file
for (file in json_files_table_detection) {
# Read the JSON file
json_data <- fromJSON(file)
# Extract the threshold and metrics from the "metrics" key
metrics <- as.data.frame(fromJSON(json_data$metrics))
lst <- list()
lst['metrics'] = as.list(metrics)
lst['model'] = basename(file)
lst['runtime'] = json_data$runtime
meta_list <- append(meta_list, list(lst))
}
for (file in json_files_table_detection) {
# Read the JSON file
json_data <- fromJSON(file)
# Extract the threshold and metrics from the "metrics" key
metrics <- as.data.frame(fromJSON(json_data$metrics))
lst <- list(
metrics = metrics,
model = basename(file)
runtime = json_data$runtime
for (file in json_files_table_detection) {
# Read the JSON file
json_data <- fromJSON(file)
# Extract the threshold and metrics from the "metrics" key
metrics <- as.data.frame(fromJSON(json_data$metrics))
lst <- list(
metrics = metrics,
model = basename(file),
runtime = json_data$runtime
)
meta_list <- append(meta_list, list(lst))
}
meta_list[1]
meta_list[1][[1]]
meta_list[[1]]
meta_list[[1]][1]
for (file in json_files_table_detection) {
# Read the JSON file
json_data <- fromJSON(file)
# Extract the threshold and metrics from the "metrics" key
metrics <- as.data.frame(fromJSON(json_data$metrics))
lst <- list(
metrics = [metrics],
for (file in json_files_table_detection) {
# Read the JSON file
json_data <- fromJSON(file)
# Extract the threshold and metrics from the "metrics" key
metrics <- as.data.frame(fromJSON(json_data$metrics))
lst <- list(
metrics = list(metrics),
model = basename(file),
runtime = json_data$runtime
)
meta_list <- append(meta_list, list(lst))
}
meta_list[[1]][1]
for (file in json_files_table_detection) {
# Read the JSON file
json_data <- fromJSON(file)
# Extract the threshold and metrics from the "metrics" key
metrics <- as.data.frame(fromJSON(json_data$metrics))
lst <- list(
metrics = metrics,
model = basename(file),
runtime = json_data$runtime
)
meta_list <- append(meta_list, lst)
}
meta_list[[1]][1]
for (file in json_files_table_detection) {
# Read the JSON file
json_data <- fromJSON(file)
# Extract the threshold and metrics from the "metrics" key
metrics <- as.data.frame(fromJSON(json_data$metrics)) %>% as_tibble()
lst <- list(
metrics = metrics,
model = basename(file),
runtime = json_data$runtime
)
meta_list <- append(meta_list, lst)
}
meta_list[[1]][1]
meta_list <- list()
# Loop through each .json file
for (file in json_files_table_detection) {
# Read the JSON file
json_data <- fromJSON(file)
# Extract the threshold and metrics from the "metrics" key
metrics <- as.data.frame(fromJSON(json_data$metrics))
lst <- list(
metrics = metrics,
model = basename(file),
runtime = json_data$runtime
)
meta_list <- append(meta_list, lst)
}
meta_list[[1]][1]
meta_list[[1]]
meta_list[1]
meta_list[2]
meta_list <- list()
# Loop through each .json file
for (file in json_files_table_detection) {
# Read the JSON file
json_data <- fromJSON(file)
# Extract the threshold and metrics from the "metrics" key
metrics <- as.data.frame(fromJSON(json_data$metrics))
lst <- list(
metrics = metrics,
model = basename(file),
runtime = json_data$runtime
)
meta_list <- append(meta_list, list(lst))
}
meta_list[1]
meta_list[[1]]
meta_list[[1]]$metrics
library(ggplot2)
table_detection_plot <- ggplot(meta_list[[1]]$metrics, aes(x = threshold)) +
geom_line(aes(y = precision, color = "Precision")) +
geom_line(aes(y = recall, color = "Recall")) +
geom_line(aes(y = F1, color = "F1")) +
labs(
title = "Metrics over Threshold",
x = "Threshold",
y = "Metric Value",
color = "Metric"
) +
theme_minimal()
table_detection_plot
