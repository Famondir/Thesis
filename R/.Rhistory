target_type <- "Aktiva"
df_filtered <- df_binary %>% filter(
classification_type == target_type, n_examples<=3
) %>%
arrange(desc(f1_score))
df_temp <- df_filtered[100,"predictions"][[1]][[1]] %>% as_tibble()
df_flipped_score <- df_temp %>%
mutate(
confidence_score = if_else(predicted_type == "no", 1-confidence_score, confidence_score),
is_aktiva = str_detect(type, target_type)
)
df_flipped_score %>% filter(type != "Aktiva&Passiva") %>% mutate(type = factor(type), predicted_type = factor(predicted_type)) %>% accuracy(type, predicted_type)
df_filtered <- df_selected %>% filter(
model == "Ministral-8B-Instruct-2410",
method == "zero_shot"
) %>%
arrange(desc(f1_score))
df_temp <- df_filtered[1,"predictions"][[1]][[1]] %>% as_tibble()
df_flipped_score <- df_temp %>%
mutate(
confidence_score = if_else(predicted_type == "no", 1-confidence_score, confidence_score),
is_aktiva = str_detect(type, "Aktiva")
)
df_flipped_score %>% filter(type != "Aktiva&Passiva") %>% mutate(type = factor(type), predicted_type = factor(predicted_type)) %>% accuracy(type, predicted_type)
df_flipped_score %>% filter(type != "Aktiva&Passiva") %>% mutate(type = factor(type), predicted_type = factor(predicted_type)) %>% kap(type, predicted_type)
df_filtered <- df_selected %>% filter(
model == "Qwen3-8B",
method == "zero_shot"
) %>%
arrange(desc(f1_score))
df_filtered <- df_selected %>% filter(
model == "Qwen3-8B",
method == "zero_shot"
) %>%
arrange(desc(f1_score))
df_temp <- df_filtered[1,"predictions"][[1]][[1]] %>% as_tibble()
df_flipped_score <- df_temp %>%
mutate(
confidence_score = if_else(predicted_type == "no", 1-confidence_score, confidence_score),
is_aktiva = str_detect(type, "Aktiva")
)
df_flipped_score %>% filter(type != "Aktiva&Passiva") %>% mutate(type = factor(type), predicted_type = factor(predicted_type)) %>% accuracy(type, predicted_type)
df_filtered <- df_selected %>% filter(
model == "Qwen3-8B",
method == "zero_shot"
) %>%
arrange(desc(f1_score))
df_temp <- df_filtered[1,"predictions"][[1]][[1]] %>% as_tibble()
df_flipped_score <- df_temp %>%
mutate(
confidence_score = if_else(predicted_type == "no", 1-confidence_score, confidence_score),
is_aktiva = str_detect(type, "Aktiva")
)
df_flipped_score %>% filter(type != "Aktiva&Passiva") %>% mutate(type = factor(type), predicted_type = factor(predicted_type)) %>% accuracy(type, predicted_type)
df_filtered <- df_selected %>% filter(
model == "Qwen3-8B",
method == "3_rag_examples"
) %>%
arrange(desc(f1_score))
df_temp <- df_filtered[1,"predictions"][[1]][[1]] %>% as_tibble()
df_flipped_score <- df_temp %>%
mutate(
confidence_score = if_else(predicted_type == "no", 1-confidence_score, confidence_score),
is_aktiva = str_detect(type, "Aktiva")
)
df_flipped_score %>% filter(type != "Aktiva&Passiva") %>% mutate(type = factor(type), predicted_type = factor(predicted_type)) %>% accuracy(type, predicted_type)
(top_k_results <- df_binary %>%
filter(model == "Ministral-8B-Instruct-2410", method == "3_rag_examples") %>%
group_by(classification_type) %>%
slice_max(n = 1, f1_score, with_ties = FALSE) %>%
select(-filepath) %>%
unnest(predictions) %>%
select(match, confidence_score, classification_type, filepath, predicted_type) %>%
mutate(confidence_score = if_else(predicted_type == classification_type, confidence_score, 1-confidence_score)) %>%
# filter(predicted_type == classification_type) %>%
group_by(classification_type, filepath) %>%
arrange(desc(confidence_score), .by_group = TRUE) %>%
mutate(rank = row_number()) %>%
ungroup() %>%
group_by(classification_type, filepath) %>%
arrange(rank, .by_group = TRUE) %>%
mutate(
cum_match = cumsum(match == TRUE)
) %>%
ungroup() %>%
group_by(classification_type, rank) %>%
summarise(
top_k_recall = mean(cum_match >= 1),
.groups = "drop"
) %>%
filter(rank <= 5,
#classification_type == "Passiva"
)
)
(top_k_results <- df_binary %>%
filter(model == "Ministral-8B-Instruct-2410", method == "3_rag_examples") %>%
group_by(classification_type) %>%
slice_max(n = 1, f1_score, with_ties = FALSE) %>%
select(-filepath) %>%
unnest(predictions) %>%
select(match, confidence_score, classification_type, filepath, predicted_type) %>%
mutate(confidence_score = if_else(predicted_type == classification_type, confidence_score, 1-confidence_score)) %>%
# filter(predicted_type == classification_type) %>%
group_by(classification_type, filepath) %>%
arrange(desc(confidence_score), .by_group = TRUE) %>%
mutate(rank = row_number()) %>%
ungroup() %>%
group_by(classification_type, filepath) %>%
arrange(rank, .by_group = TRUE) %>%
mutate(
cum_match = cumsum(match == TRUE)
) %>%
ungroup() %>%
group_by(classification_type, rank) %>%
summarise(
top_k_recall = mean(cum_match >= 1),
.groups = "drop"
) %>%
filter(rank <= 5,
#classification_type == "Passiva"
)
)
df_binary
(top_k_results <- df_binary %>%
filter(model == "Ministral-8B-Instruct-2410", method == "3_rag_examples") %>%
group_by(classification_type) %>%
slice_max(n = 1, f1_score, with_ties = FALSE) %>%
select(-filepath) %>%
unnest(predictions) %>%
select(match, confidence_score, classification_type, filepath, predicted_type) %>%
mutate(confidence_score = if_else(predicted_type == classification_type, confidence_score, 1-confidence_score)) %>%
# filter(predicted_type == classification_type) %>%
group_by(classification_type, filepath) %>%
arrange(desc(confidence_score), .by_group = TRUE) %>%
mutate(rank = row_number()) %>%
ungroup() %>%
group_by(classification_type, filepath) %>%
arrange(rank, .by_group = TRUE) %>%
mutate(
cum_match = cumsum(match == TRUE)
) %>%
ungroup() %>%
group_by(classification_type, rank) %>%
summarise(
top_k_recall = mean(cum_match >= 1),
.groups = "drop"
) %>%
filter(rank <= 5,
#classification_type == "Passiva"
)
)
df_binary %>%
filter(model == "Ministral-8B-Instruct-2410", method == "3_rag_examples") %>%
group_by(classification_type) %>%
slice_max(n = 1, f1_score, with_ties = FALSE) %>%
select(-filepath) %>%
unnest(predictions)
df_binary %>%
filter(model == "Ministral-8B-Instruct-2410", method == "3_rag_examples")
df_binary
df_binary$model
df_binary$model %>% unique()
temp_list <- readRDS("data_storage/page_identification_llm.rds")
df_binary <- temp_list$df_binary
df_multi <- temp_list$df_multi
method_families <- c("zero_shot", "law_context", "top_n_rag_examples", "n_random_examples", 'n_rag_examples')
method_familiy_colors <- c(
"zero_shot" = "#e41a1c",
"law_context" = "#377eb8",
"top_n_rag_examples" = "#4daf4a",
"n_random_examples" = "#984ea3",
'n_rag_examples' = "#ff7f00"
)
model_by_size_classification <- c('google_gemma-3-4b-it-0-9-1', 'google_gemma-3n-E4B-it-0-9-1', "google_gemma-3-12b-it-0-9-1",
"google_gemma-3-27b-it-0-9-1", "meta-llama_Llama-3.1-8B-Instruct",
"meta-llama_Llama-3.1-70B-Instruct", "meta-llama_Llama-3.3-70B-Instruct",
"meta-llama_Llama-4-Scout-17B-16E-Instruct", "meta-llama_Llama-4-Maverick-17B-128E-Instruct-FP8",
"mistralai_Ministral-8B-Instruct-2410", "mistralai_Mistral-Small-3.1-24B-Instruct-2503",
"mistralai_Mistral-Large-Instruct-2411", "Qwen_Qwen2.5-0.5B-Instruct",
"Qwen_Qwen2.5-1.5B-Instruct", "Qwen_Qwen2.5-3B-Instruct", "Qwen_Qwen2.5-7B-Instruct",
"Qwen_Qwen2.5-14B-Instruct", "Qwen_Qwen2.5-32B-Instruct", "Qwen_Qwen2.5-72B-Instruct",
"Qwen_Qwen3-8B", "Qwen_Qwen3-30B-A3B-Instruct-2507", "Qwen_Qwen3-32B", "Qwen_Qwen3-235B-A22B-Instruct-2507",
"tiiuae_Falcon3-10B-Instruct", "microsoft_phi-4"
) %>% gsub("^[^_]+_", "", .)
df_binary <- df_binary %>%
mutate(
n_examples = as.numeric(n_examples),
n_examples = if_else(method_family == "zero_shot", 0, n_examples),
n_examples = if_else(method_family == "law_context", 1, n_examples),
method_family = factor(method_family, levels = method_families)
) %>% mutate(model = gsub("^[^_]+_", "", model)) %>%
filter(model %in% model_by_size_classification) %>%
ungroup() # %>%
# mutate(
#   model = str_replace(model, "_vllm", ""),
#   model_family = sub("_.*", "", model),
#   model_family = if_else(str_detect(model, "Qwen2"), "Qwen 2.5", model_family),
#   model_family = if_else(str_detect(model, "Qwen3"), "Qwen 3", model_family),
#   model_family = if_else(str_detect(model, "Llama-3"), "Llama-3", model_family),
#   model_family = if_else(str_detect(model, "Llama-4"), "Llama-4", model_family)
# )
binary_task <- list()
binary_task$n_models <- df_binary$model %>% unique() %>% length()
binary_task$n_model_families <- df_binary$model_family %>% unique() %>% length()
binary_task$n_method_families <- df_binary$method_family %>% unique() %>% length()
top_performer_binary <- df_binary %>%
filter(is.finite(f1_score), loop == 0) %>%
filter(n_examples <= 3 | is.na(n_examples)) %>%
group_by(model_family, classification_type) %>%
slice_max(n = 1, f1_score) %>%
arrange(desc(f1_score)) %>%
select(model_family, model, classification_type, method_family, n_examples, f1_score, norm_runtime) %>%
mutate(
f1_score = round(f1_score, 2),
norm_runtime = round(norm_runtime, 0),
) %>% rename(
"runtime in s" = norm_runtime,
)
top_performer_binary_median <- top_performer_binary %>% group_by(classification_type) %>% summarise(median = median(f1_score))
top_performer_binary_median_guv <- top_performer_binary_median %>% filter(classification_type == "GuV") %>% pull(median)
top_performer_binary_median_aktiva <- top_performer_binary_median %>% filter(classification_type == "Aktiva") %>% pull(median)
top_performer_binary_median_passiva <- top_performer_binary_median %>% filter(classification_type == "Passiva") %>% pull(median)
df_multi <- df_multi %>%
mutate(
n_examples = as.numeric(n_examples),
n_examples = if_else(method_family == "zero_shot", 0, n_examples),
n_examples = if_else(method_family == "law_context", 1, n_examples),
method_family = factor(method_family, levels = method_families)
) %>% mutate(model = gsub("^[^_]+_", "", model)) %>%
filter(model %in% model_by_size_classification) %>%
ungroup() #%>%
# mutate(
#   model = str_replace(model, "_vllm", ""),
#   model_family = sub("_.*", "", model),
#   model_family = if_else(str_detect(model, "Qwen2"), "Qwen 2.5", model_family),
#   model_family = if_else(str_detect(model, "Qwen3"), "Qwen 3", model_family),
#   model_family = if_else(str_detect(model, "Llama-3"), "Llama-3", model_family),
#   model_family = if_else(str_detect(model, "Llama-4"), "Llama-4", model_family)
# )
top_performer_multu <- df_multi %>%
unnest(metrics) %>%
filter(metric_type %in% c("Aktiva", "Passiva", "GuV")) %>%
filter(is.finite(f1_score), loop == 0) %>%
filter(n_examples <= 3 | is.na(n_examples)) %>%
group_by(model_family, metric_type) %>%
slice_max(n = 1, f1_score) %>%
arrange(desc(f1_score)) %>% # head(10) %>%
select(model_family, model, metric_type, method_family, n_examples, f1_score, norm_runtime) %>%
mutate(
f1_score = round(f1_score, 2),
norm_runtime = round(norm_runtime, 0),
) %>% rename(
"runtime in s" = norm_runtime,
)
(top_k_results <- df_binary %>%
filter(model == "Ministral-8B-Instruct-2410", method == "3_rag_examples") %>%
group_by(classification_type) %>%
slice_max(n = 1, f1_score, with_ties = FALSE) %>%
select(-filepath) %>%
unnest(predictions) %>%
select(match, confidence_score, classification_type, filepath, predicted_type) %>%
mutate(confidence_score = if_else(predicted_type == classification_type, confidence_score, 1-confidence_score)) %>%
# filter(predicted_type == classification_type) %>%
group_by(classification_type, filepath) %>%
arrange(desc(confidence_score), .by_group = TRUE) %>%
mutate(rank = row_number()) %>%
ungroup() %>%
group_by(classification_type, filepath) %>%
arrange(rank, .by_group = TRUE) %>%
mutate(
cum_match = cumsum(match == TRUE)
) %>%
ungroup() %>%
group_by(classification_type, rank) %>%
summarise(
top_k_recall = mean(cum_match >= 1),
.groups = "drop"
) %>%
filter(rank <= 5,
#classification_type == "Passiva"
)
)
df_2_predictors_test <- read_csv("/home/simon/Documents/data_science/Thesis/benchmark_results/page_identification/term_frequency_results_2_predictors_test.csv") %>%
mutate(data_split = 'test', n_predictors = 2)
df_2_predictors_train <- read_csv("/home/simon/Documents/data_science/Thesis/benchmark_results/page_identification/term_frequency_results_2_predictors_train.csv") %>%
mutate(data_split = 'train', n_predictors = 2)
df_4_predictors_test <- read_csv("/home/simon/Documents/data_science/Thesis/benchmark_results/page_identification/term_frequency_results_4_predictors_test.csv") %>%
mutate(data_split = 'test', n_predictors = 4)
df_4_predictors_train <- read_csv("/home/simon/Documents/data_science/Thesis/benchmark_results/page_identification/term_frequency_results_4_predictors_train.csv") %>%
mutate(data_split = 'train', n_predictors = 4)
df_rf_results <- bind_rows(
df_2_predictors_train, df_2_predictors_test,
df_4_predictors_train, df_4_predictors_test
)
max_rank = df_rf_results %>% filter(is_truth == 1) %>% pull(rank) %>% max()
results <- map_dfr(1:max_rank, function(i_rank) {
df_rf_results %>%
filter(is_truth == 1) %>%
group_by(type, data_split, n_predictors) %>%
mutate(le = if_else(rank <= i_rank, 1, 0)) %>%
summarise(mean = mean(le), .groups = "drop") %>%
mutate(i_rank = i_rank)
})
results %>% ggplot() +
geom_col(aes(x = i_rank, y = mean)) +
facet_nested(type ~ data_split + n_predictors) +
labs(
x = "rank",
y = "top n accuracy",
# title = "Top n accuracy for different ranks, data splits and number of predictors"
)
results
results %>% filter(data_split == "test")
results %>% filter(data_split == "test", n_predictors == 4)
(top_k_results <- df_multi %>%
unnest(metrics) %>%
filter(metric_type %in% c("Aktiva", "Passiva", "GuV")) %>%
filter(model == "Ministral-8B-Instruct-2410", method == "3_rag_examples") %>%
group_by(classification_type) %>%
slice_max(n = 1, f1_score, with_ties = FALSE) %>%
select(-filepath) %>%
unnest(predictions) %>%
select(match, confidence_score, classification_type, filepath, predicted_type) %>%
mutate(confidence_score = if_else(predicted_type == classification_type, confidence_score, 1-confidence_score)) %>%
# filter(predicted_type == classification_type) %>%
group_by(classification_type, filepath) %>%
arrange(desc(confidence_score), .by_group = TRUE) %>%
mutate(rank = row_number()) %>%
ungroup() %>%
group_by(classification_type, filepath) %>%
arrange(rank, .by_group = TRUE) %>%
mutate(
cum_match = cumsum(match == TRUE)
) %>%
ungroup() %>%
group_by(classification_type, rank) %>%
summarise(
top_k_recall = mean(cum_match >= 1),
.groups = "drop"
) %>%
filter(rank <= 5,
#classification_type == "Passiva"
)
)
(top_k_results <- df_multi %>%
unnest(metrics) %>%
filter(metric_type %in% c("Aktiva", "Passiva", "GuV")) %>%
filter(model == "Ministral-8B-Instruct-2410", method == "3_rag_examples") %>%
rename(classification_type = metric_type) %>%
group_by(classification_type) %>%
slice_max(n = 1, f1_score, with_ties = FALSE) %>%
select(-filepath) %>%
unnest(predictions) %>%
select(match, confidence_score, classification_type, filepath, predicted_type) %>%
mutate(confidence_score = if_else(predicted_type == classification_type, confidence_score, 1-confidence_score)) %>%
# filter(predicted_type == classification_type) %>%
group_by(classification_type, filepath) %>%
arrange(desc(confidence_score), .by_group = TRUE) %>%
mutate(rank = row_number()) %>%
ungroup() %>%
group_by(classification_type, filepath) %>%
arrange(rank, .by_group = TRUE) %>%
mutate(
cum_match = cumsum(match == TRUE)
) %>%
ungroup() %>%
group_by(classification_type, rank) %>%
summarise(
top_k_recall = mean(cum_match >= 1),
.groups = "drop"
) %>%
filter(rank <= 5,
#classification_type == "Passiva"
)
)
(top_k_results <- df_multi %>%
unnest(metrics) %>%
filter(metric_type %in% c("Aktiva", "Passiva", "GuV")) %>%
filter(model == "Ministral-8B-Instruct-2410", method == "3_rag_examples") %>%
mutate(classification_type = metric_type) %>%
group_by(classification_type) %>%
slice_max(n = 1, f1_score, with_ties = FALSE) %>%
select(-filepath) %>%
unnest(predictions) %>%
select(match, confidence_score, classification_type, filepath, predicted_type) %>%
mutate(confidence_score = if_else(predicted_type == classification_type, confidence_score, 1-confidence_score)) %>%
# filter(predicted_type == classification_type) %>%
group_by(classification_type, filepath) %>%
arrange(desc(confidence_score), .by_group = TRUE) %>%
mutate(rank = row_number()) %>%
ungroup() %>%
group_by(classification_type, filepath) %>%
arrange(rank, .by_group = TRUE) %>%
mutate(
cum_match = cumsum(match == TRUE)
) %>%
ungroup() %>%
group_by(classification_type, rank) %>%
summarise(
top_k_recall = mean(cum_match >= 1),
.groups = "drop"
) %>%
filter(rank <= 5,
#classification_type == "Passiva"
)
)
# If you want a wide format (k as columns):
top_k_wide <- top_k_results %>%
pivot_wider(names_from = rank, values_from = top_k_acc, names_prefix = "top_")
top_k_wide
top_k_results
top_k_results %>%
pivot_wider(names_from = rank, values_from = top_k_acc, names_prefix = "top_")
# If you want a wide format (k as columns):
top_k_wide <- top_k_results %>%
pivot_wider(names_from = rank, values_from = top_k_recall, names_prefix = "top_")
top_k_wide
results %>% filter(data_split == "test", n_predictors == 4) %>% print(n = 20)
df_page_identification_comparing
df_page_identification_comparing <- read_csv("data_storage/page_identification_summary.csv")
df_page_identification_comparing
(top_k_results <- df_binary %>%
filter(model == "Ministral-8B-Instruct-2410", method == "3_rag_examples") %>%
group_by(classification_type) %>%
slice_max(n = 1, f1_score, with_ties = FALSE) %>%
select(-filepath) %>%
unnest(predictions) %>%
select(match, confidence_score, classification_type, filepath, predicted_type) %>%
mutate(confidence_score = if_else(predicted_type == classification_type, confidence_score, 1-confidence_score)) %>%
# filter(predicted_type == classification_type) %>%
group_by(classification_type, filepath) %>%
arrange(desc(confidence_score), .by_group = TRUE) %>%
mutate(rank = row_number()) %>%
ungroup() %>%
group_by(classification_type, filepath) %>%
arrange(rank, .by_group = TRUE) %>%
mutate(
cum_match = cumsum(match == TRUE)
) %>%
ungroup() %>%
group_by(classification_type, rank) %>%
summarise(
top_k_recall = mean(cum_match >= 1),
.groups = "drop"
) %>%
filter(rank <= 5,
#classification_type == "Passiva"
)
)
(top_k_results <- df_multi %>%
unnest(metrics) %>%
filter(metric_type %in% c("Aktiva", "Passiva", "GuV")) %>%
filter(model == "Ministral-8B-Instruct-2410", method == "3_rag_examples") %>%
mutate(classification_type = metric_type) %>%
group_by(classification_type) %>%
slice_max(n = 1, f1_score, with_ties = FALSE) %>%
select(-filepath) %>%
unnest(predictions) %>%
select(match, confidence_score, classification_type, filepath, predicted_type) %>%
mutate(confidence_score = if_else(predicted_type == classification_type, confidence_score, 1-confidence_score)) %>%
# filter(predicted_type == classification_type) %>%
group_by(classification_type, filepath) %>%
arrange(desc(confidence_score), .by_group = TRUE) %>%
mutate(rank = row_number()) %>%
ungroup() %>%
group_by(classification_type, filepath) %>%
arrange(rank, .by_group = TRUE) %>%
mutate(
cum_match = cumsum(match == TRUE)
) %>%
ungroup() %>%
group_by(classification_type, rank) %>%
summarise(
top_k_recall = mean(cum_match >= 1),
.groups = "drop"
) %>%
filter(rank <= 5,
#classification_type == "Passiva"
)
)
(top_k_results <- df_multi %>%
unnest(metrics) %>%
filter(metric_type %in% c("Aktiva", "Passiva", "GuV")) %>%
filter(model == "Llama-4-Scout-17B-16E-Instruct", method == "3_rag_examples") %>%
mutate(classification_type = metric_type) %>%
group_by(classification_type) %>%
slice_max(n = 1, f1_score, with_ties = FALSE) %>%
select(-filepath) %>%
unnest(predictions) %>%
select(match, confidence_score, classification_type, filepath, predicted_type) %>%
mutate(confidence_score = if_else(predicted_type == classification_type, confidence_score, 1-confidence_score)) %>%
# filter(predicted_type == classification_type) %>%
group_by(classification_type, filepath) %>%
arrange(desc(confidence_score), .by_group = TRUE) %>%
mutate(rank = row_number()) %>%
ungroup() %>%
group_by(classification_type, filepath) %>%
arrange(rank, .by_group = TRUE) %>%
mutate(
cum_match = cumsum(match == TRUE)
) %>%
ungroup() %>%
group_by(classification_type, rank) %>%
summarise(
top_k_recall = mean(cum_match >= 1),
.groups = "drop"
) %>%
filter(rank <= 5,
#classification_type == "Passiva"
)
)
df_multi %>% filter(model == "Ministral-8B-Instruct-2410", method == "3_rag_examples") %>% pull(norm_runtime)
