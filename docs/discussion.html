<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6 Discussion | Extraction of tabular data from annual reports with LLMs</title>
  <meta name="description" content="6 Discussion | Extraction of tabular data from annual reports with LLMs" />
  <meta name="generator" content="bookdown 0.43.2 and GitBook 2.6.7" />

  <meta property="og:title" content="6 Discussion | Extraction of tabular data from annual reports with LLMs" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6 Discussion | Extraction of tabular data from annual reports with LLMs" />
  
  
  

<meta name="author" content="Simon SchÃ¤fer" />


<meta name="date" content="2025-09-08" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="results.html"/>
<link rel="next" href="conclusion.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/codefolding-lua-1.1/codefolding-lua.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.33/datatables.js"></script>
<link href="libs/dt-core-1.13.6/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.13.6/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.13.6/js/jquery.dataTables.min.js"></script>
<link href="libs/dt-ext-rowgroup-1.13.6/css/rowGroup.dataTables.min.css" rel="stylesheet" />
<script src="libs/dt-ext-rowgroup-1.13.6/js/dataTables.rowGroup.min.js"></script>
<link href="libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/choices.js/public/assets/styles/choices.min.css" />
<script src="https://cdn.jsdelivr.net/npm/choices.js/public/assets/scripts/choices.min.js"></script>

<!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/glider-js@1/glider.min.css">
<script src="https://cdn.jsdelivr.net/npm/glider-js@1/glider.min.js"></script> -->


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="report_misc/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./index.html"><img src="images/BHT_Logo_horizontal_Anthrazit_transparent.svg"></a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#motivation"><i class="fa fa-check"></i><b>1.1</b> Motivation</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#objectives"><i class="fa fa-check"></i><b>1.2</b> Objectives</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#introduction-methodology"><i class="fa fa-check"></i><b>1.3</b> Methodology</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#thesis-outline"><i class="fa fa-check"></i><b>1.4</b> Thesis Outline</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#summary"><i class="fa fa-check"></i><b>1.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="literature-review.html"><a href="literature-review.html"><i class="fa fa-check"></i><b>2</b> Literature review</a>
<ul>
<li class="chapter" data-level="2.1" data-path="literature-review.html"><a href="literature-review.html#computer-science"><i class="fa fa-check"></i><b>2.1</b> Computer science</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="literature-review.html"><a href="literature-review.html#sparse-retrieval"><i class="fa fa-check"></i><b>2.1.1</b> Information retrieval</a></li>
<li class="chapter" data-level="2.1.2" data-path="literature-review.html"><a href="literature-review.html#nlp"><i class="fa fa-check"></i><b>2.1.2</b> Natural language processing</a></li>
<li class="chapter" data-level="2.1.3" data-path="literature-review.html"><a href="literature-review.html#text-processing"><i class="fa fa-check"></i><b>2.1.3</b> Text processing</a>
<ul>
<li class="chapter" data-level="2.1.3.1" data-path="literature-review.html"><a href="literature-review.html#document-layout-analysis"><i class="fa fa-check"></i><b>2.1.3.1</b> Document Layout Analysis</a></li>
</ul></li>
<li class="chapter" data-level="2.1.4" data-path="literature-review.html"><a href="literature-review.html#llm-theory"><i class="fa fa-check"></i><b>2.1.4</b> Large Language Models</a>
<ul>
<li class="chapter" data-level="2.1.4.1" data-path="literature-review.html"><a href="literature-review.html#transformers"><i class="fa fa-check"></i><b>2.1.4.1</b> Transformers</a></li>
<li class="chapter" data-level="2.1.4.2" data-path="literature-review.html"><a href="literature-review.html#attention"><i class="fa fa-check"></i><b>2.1.4.2</b> Attention</a></li>
<li class="chapter" data-level="2.1.4.3" data-path="literature-review.html"><a href="literature-review.html#encoder"><i class="fa fa-check"></i><b>2.1.4.3</b> Encoder</a></li>
<li class="chapter" data-level="2.1.4.4" data-path="literature-review.html"><a href="literature-review.html#decoder"><i class="fa fa-check"></i><b>2.1.4.4</b> Decoder</a></li>
<li class="chapter" data-level="2.1.4.5" data-path="literature-review.html"><a href="literature-review.html#gpt-generative-pretrained-transformers"><i class="fa fa-check"></i><b>2.1.4.5</b> GPT (Generative Pretrained Transformers)</a></li>
<li class="chapter" data-level="2.1.4.6" data-path="literature-review.html"><a href="literature-review.html#mixture-of-experts"><i class="fa fa-check"></i><b>2.1.4.6</b> Mixture of Experts</a></li>
<li class="chapter" data-level="2.1.4.7" data-path="literature-review.html"><a href="literature-review.html#confidence-scores"><i class="fa fa-check"></i><b>2.1.4.7</b> Confidence scores</a></li>
</ul></li>
<li class="chapter" data-level="2.1.5" data-path="literature-review.html"><a href="literature-review.html#llm-methods"><i class="fa fa-check"></i><b>2.1.5</b> Generation enhancing methods with LLMs</a>
<ul>
<li class="chapter" data-level="2.1.5.1" data-path="literature-review.html"><a href="literature-review.html#in-context-learning"><i class="fa fa-check"></i><b>2.1.5.1</b> In-context Learning</a></li>
<li class="chapter" data-level="2.1.5.2" data-path="literature-review.html"><a href="literature-review.html#rag"><i class="fa fa-check"></i><b>2.1.5.2</b> RAG</a></li>
<li class="chapter" data-level="2.1.5.3" data-path="literature-review.html"><a href="literature-review.html#guided-and-restricted-decoding"><i class="fa fa-check"></i><b>2.1.5.3</b> Guided and restricted decoding</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="literature-review.html"><a href="literature-review.html#other-concepts"><i class="fa fa-check"></i><b>2.2</b> General machine learning and statistics</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="literature-review.html"><a href="literature-review.html#sample-distribution-visualization-methods"><i class="fa fa-check"></i><b>2.2.1</b> Sample distribution visualization methods</a></li>
<li class="chapter" data-level="2.2.2" data-path="literature-review.html"><a href="literature-review.html#tree-based-machine-learning-algorithms"><i class="fa fa-check"></i><b>2.2.2</b> Tree based machine learning algorithms</a></li>
<li class="chapter" data-level="2.2.3" data-path="literature-review.html"><a href="literature-review.html#shap"><i class="fa fa-check"></i><b>2.2.3</b> Model agnostic explanation models</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="literature-review.html"><a href="literature-review.html#summary-1"><i class="fa fa-check"></i><b>2.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="methodology.html"><a href="methodology.html"><i class="fa fa-check"></i><b>3</b> Methodology</a>
<ul>
<li class="chapter" data-level="3.1" data-path="methodology.html"><a href="methodology.html#problem-definition"><i class="fa fa-check"></i><b>3.1</b> Problem Definition</a></li>
<li class="chapter" data-level="3.2" data-path="methodology.html"><a href="methodology.html#research-design-philosophy"><i class="fa fa-check"></i><b>3.2</b> Research Design &amp; Philosophy</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="methodology.html"><a href="methodology.html#research-questions"><i class="fa fa-check"></i><b>3.2.1</b> Research questions</a></li>
<li class="chapter" data-level="3.2.2" data-path="methodology.html"><a href="methodology.html#hypotheses"><i class="fa fa-check"></i><b>3.2.2</b> Hypotheses</a></li>
<li class="chapter" data-level="3.2.3" data-path="methodology.html"><a href="methodology.html#evaluation-research"><i class="fa fa-check"></i><b>3.2.3</b> Evaluation research</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="methodology.html"><a href="methodology.html#evaluation-strategy"><i class="fa fa-check"></i><b>3.3</b> Evaluation Strategy</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="methodology.html"><a href="methodology.html#evaluation-framework-and-metrics"><i class="fa fa-check"></i><b>3.3.1</b> Evaluation framework and metrics</a>
<ul>
<li class="chapter" data-level="3.3.1.1" data-path="methodology.html"><a href="methodology.html#page-identification"><i class="fa fa-check"></i><b>3.3.1.1</b> Page identification</a></li>
<li class="chapter" data-level="3.3.1.2" data-path="methodology.html"><a href="methodology.html#information-extraction"><i class="fa fa-check"></i><b>3.3.1.2</b> Information extraction</a></li>
<li class="chapter" data-level="3.3.1.3" data-path="methodology.html"><a href="methodology.html#error-rate-guidance"><i class="fa fa-check"></i><b>3.3.1.3</b> Error rate guidance</a></li>
</ul></li>
<li class="chapter" data-level="3.3.2" data-path="methodology.html"><a href="methodology.html#benchmarking"><i class="fa fa-check"></i><b>3.3.2</b> Benchmarking</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="methodology.html"><a href="methodology.html#data-strategy"><i class="fa fa-check"></i><b>3.4</b> Data Strategy</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="methodology.html"><a href="methodology.html#sampling-methodology"><i class="fa fa-check"></i><b>3.4.1</b> Sampling methodology</a></li>
<li class="chapter" data-level="3.4.2" data-path="methodology.html"><a href="methodology.html#ground-truth-creation-process"><i class="fa fa-check"></i><b>3.4.2</b> Ground truth creation process</a></li>
<li class="chapter" data-level="3.4.3" data-path="methodology.html"><a href="methodology.html#preprocessing"><i class="fa fa-check"></i><b>3.4.3</b> Preprocessing</a></li>
<li class="chapter" data-level="3.4.4" data-path="methodology.html"><a href="methodology.html#data-splitting"><i class="fa fa-check"></i><b>3.4.4</b> Data splitting</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="methodology.html"><a href="methodology.html#experimental-framework"><i class="fa fa-check"></i><b>3.5</b> Experimental Framework</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="methodology.html"><a href="methodology.html#llm-overview"><i class="fa fa-check"></i><b>3.5.1</b> LLM overview</a></li>
<li class="chapter" data-level="3.5.2" data-path="methodology.html"><a href="methodology.html#approaches"><i class="fa fa-check"></i><b>3.5.2</b> Approaches</a>
<ul>
<li class="chapter" data-level="3.5.2.1" data-path="methodology.html"><a href="methodology.html#page-identification-2"><i class="fa fa-check"></i><b>3.5.2.1</b> Page identification</a></li>
<li class="chapter" data-level="3.5.2.2" data-path="methodology.html"><a href="methodology.html#information-extraction-2"><i class="fa fa-check"></i><b>3.5.2.2</b> Information extraction</a></li>
</ul></li>
<li class="chapter" data-level="3.5.3" data-path="methodology.html"><a href="methodology.html#error-analysis-methodology"><i class="fa fa-check"></i><b>3.5.3</b> Error analysis</a>
<ul>
<li class="chapter" data-level="3.5.3.1" data-path="methodology.html"><a href="methodology.html#page-identificaion"><i class="fa fa-check"></i><b>3.5.3.1</b> Page identificaion</a></li>
<li class="chapter" data-level="3.5.3.2" data-path="methodology.html"><a href="methodology.html#inforamtion-extraction"><i class="fa fa-check"></i><b>3.5.3.2</b> Inforamtion extraction</a></li>
</ul></li>
<li class="chapter" data-level="3.5.4" data-path="methodology.html"><a href="methodology.html#evaluation-methods"><i class="fa fa-check"></i><b>3.5.4</b> Evaluation methods</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="implementation.html"><a href="implementation.html"><i class="fa fa-check"></i><b>4</b> Implementation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="implementation.html"><a href="implementation.html#environments"><i class="fa fa-check"></i><b>4.1</b> Environments</a></li>
<li class="chapter" data-level="4.2" data-path="implementation.html"><a href="implementation.html#software-packages"><i class="fa fa-check"></i><b>4.2</b> Software Packages</a></li>
<li class="chapter" data-level="4.3" data-path="implementation.html"><a href="implementation.html#ground-truth-datasets"><i class="fa fa-check"></i><b>4.3</b> Ground truth datasets</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="implementation.html"><a href="implementation.html#ground-truth-creation"><i class="fa fa-check"></i><b>4.3.1</b> Ground truth creation</a></li>
<li class="chapter" data-level="4.3.2" data-path="implementation.html"><a href="implementation.html#ground-truth-database-composition"><i class="fa fa-check"></i><b>4.3.2</b> Ground truth database composition</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="implementation.html"><a href="implementation.html#data-processing"><i class="fa fa-check"></i><b>4.4</b> Data processing</a></li>
<li class="chapter" data-level="4.5" data-path="implementation.html"><a href="implementation.html#evaluation-and-reporting"><i class="fa fa-check"></i><b>4.5</b> Evaluation and Reporting</a></li>
<li class="chapter" data-level="4.6" data-path="implementation.html"><a href="implementation.html#speedup-with-vllm-and-batching"><i class="fa fa-check"></i><b>4.6</b> Speedup with vLLM and batching</a></li>
<li class="chapter" data-level="4.7" data-path="implementation.html"><a href="implementation.html#gpu-benchmark"><i class="fa fa-check"></i><b>4.7</b> Hardware normalization</a></li>
<li class="chapter" data-level="4.8" data-path="implementation.html"><a href="implementation.html#summary-2"><i class="fa fa-check"></i><b>4.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i><b>5</b> Results</a>
<ul>
<li class="chapter" data-level="5.1" data-path="results.html"><a href="results.html#page-identification-introduction"><i class="fa fa-check"></i><b>5.1</b> Page identification</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="results.html"><a href="results.html#approaches-1"><i class="fa fa-check"></i><b>5.1.1</b> Approaches</a></li>
<li class="chapter" data-level="5.1.2" data-path="results.html"><a href="results.html#comparison-page-identification"><i class="fa fa-check"></i><b>5.1.2</b> Comparison</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="results.html"><a href="results.html#table-extraction-introduction"><i class="fa fa-check"></i><b>5.2</b> Information extraction</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="results.html"><a href="results.html#approaches-2"><i class="fa fa-check"></i><b>5.2.1</b> Approaches</a></li>
<li class="chapter" data-level="5.2.2" data-path="results.html"><a href="results.html#comparing-table-extraction-methods"><i class="fa fa-check"></i><b>5.2.2</b> Comparison</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="results.html"><a href="results.html#error-rate-guidance-results"><i class="fa fa-check"></i><b>5.3</b> Error rate guidance</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="results.html"><a href="results.html#page-identification-error-rate-results"><i class="fa fa-check"></i><b>5.3.1</b> Page identification</a></li>
<li class="chapter" data-level="5.3.2" data-path="results.html"><a href="results.html#information-extraction-error-rate-results"><i class="fa fa-check"></i><b>5.3.2</b> Information extraction</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="results.html"><a href="results.html#summary-results"><i class="fa fa-check"></i><b>5.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="discussion.html"><a href="discussion.html"><i class="fa fa-check"></i><b>6</b> Discussion</a>
<ul>
<li class="chapter" data-level="6.1" data-path="discussion.html"><a href="discussion.html#answer-research-questions"><i class="fa fa-check"></i><b>6.1</b> Research questions</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="discussion.html"><a href="discussion.html#page-identification-5"><i class="fa fa-check"></i><b>6.1.1</b> Page identification</a></li>
<li class="chapter" data-level="6.1.2" data-path="discussion.html"><a href="discussion.html#information-extraction-4"><i class="fa fa-check"></i><b>6.1.2</b> Information extraction</a>
<ul>
<li class="chapter" data-level="6.1.2.1" data-path="discussion.html"><a href="discussion.html#extraction-performace-hypotheses-evaluation"><i class="fa fa-check"></i><b>6.1.2.1</b> Core capabilities</a></li>
<li class="chapter" data-level="6.1.2.2" data-path="discussion.html"><a href="discussion.html#extraction-performace-predictor-hypotheses-evaluation"><i class="fa fa-check"></i><b>6.1.2.2</b> Feature effects</a></li>
<li class="chapter" data-level="6.1.2.3" data-path="discussion.html"><a href="discussion.html#error-rate-guidance-1"><i class="fa fa-check"></i><b>6.1.2.3</b> Error rate guidance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="discussion.html"><a href="discussion.html#error-analysis"><i class="fa fa-check"></i><b>6.2</b> Error analysis</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="discussion.html"><a href="discussion.html#page-identification-6"><i class="fa fa-check"></i><b>6.2.1</b> Page identification</a>
<ul>
<li class="chapter" data-level="6.2.1.1" data-path="discussion.html"><a href="discussion.html#llm-approach"><i class="fa fa-check"></i><b>6.2.1.1</b> LLM approach</a></li>
<li class="chapter" data-level="6.2.1.2" data-path="discussion.html"><a href="discussion.html#error-analysis-tf"><i class="fa fa-check"></i><b>6.2.1.2</b> Term frequency approach</a></li>
</ul></li>
<li class="chapter" data-level="6.2.2" data-path="discussion.html"><a href="discussion.html#information-extraction-5"><i class="fa fa-check"></i><b>6.2.2</b> Information extraction</a>
<ul>
<li class="chapter" data-level="6.2.2.1" data-path="discussion.html"><a href="discussion.html#real-tables-3"><i class="fa fa-check"></i><b>6.2.2.1</b> Real tables</a></li>
<li class="chapter" data-level="6.2.2.2" data-path="discussion.html"><a href="discussion.html#same-company-evaluation"><i class="fa fa-check"></i><b>6.2.2.2</b> Company specific results</a></li>
<li class="chapter" data-level="6.2.2.3" data-path="discussion.html"><a href="discussion.html#synthetic-tables-3"><i class="fa fa-check"></i><b>6.2.2.3</b> Synthetic tables</a></li>
<li class="chapter" data-level="6.2.2.4" data-path="discussion.html"><a href="discussion.html#numeric-transformation-discussion"><i class="fa fa-check"></i><b>6.2.2.4</b> Numeric transformations</a></li>
<li class="chapter" data-level="6.2.2.5" data-path="discussion.html"><a href="discussion.html#regex-synth-backend-discussion"><i class="fa fa-check"></i><b>6.2.2.5</b> Regular expression approach</a></li>
<li class="chapter" data-level="6.2.2.6" data-path="discussion.html"><a href="discussion.html#openai-discussion"><i class="fa fa-check"></i><b>6.2.2.6</b> OpenAI models</a></li>
</ul></li>
<li class="chapter" data-level="6.2.3" data-path="discussion.html"><a href="discussion.html#unconsistent-label-matching"><i class="fa fa-check"></i><b>6.2.3</b> Ground truth creation</a></li>
<li class="chapter" data-level="6.2.4" data-path="discussion.html"><a href="discussion.html#context-rot"><i class="fa fa-check"></i><b>6.2.4</b> Context rot</a>
<ul>
<li class="chapter" data-level="6.2.4.1" data-path="discussion.html"><a href="discussion.html#page-identification-7"><i class="fa fa-check"></i><b>6.2.4.1</b> Page identification</a></li>
<li class="chapter" data-level="6.2.4.2" data-path="discussion.html"><a href="discussion.html#information-extraction-6"><i class="fa fa-check"></i><b>6.2.4.2</b> Information extraction</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="discussion.html"><a href="discussion.html#general-performance"><i class="fa fa-check"></i><b>6.3</b> Practical Implications and Limitations</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="discussion.html"><a href="discussion.html#page-identification-8"><i class="fa fa-check"></i><b>6.3.1</b> Page identification</a>
<ul>
<li class="chapter" data-level="6.3.1.1" data-path="discussion.html"><a href="discussion.html#transfering-the-system-to-new-problems"><i class="fa fa-check"></i><b>6.3.1.1</b> Transfering the system to new problems</a></li>
<li class="chapter" data-level="6.3.1.2" data-path="discussion.html"><a href="discussion.html#limitations-of-transfer"><i class="fa fa-check"></i><b>6.3.1.2</b> Limitations of transfer</a></li>
<li class="chapter" data-level="6.3.1.3" data-path="discussion.html"><a href="discussion.html#toc-discussion"><i class="fa fa-check"></i><b>6.3.1.3</b> Possible improvement</a></li>
<li class="chapter" data-level="6.3.1.4" data-path="discussion.html"><a href="discussion.html#conclusion-4"><i class="fa fa-check"></i><b>6.3.1.4</b> Conclusion</a></li>
<li class="chapter" data-level="6.3.1.5" data-path="discussion.html"><a href="discussion.html#efficency-discussion"><i class="fa fa-check"></i><b>6.3.1.5</b> Energy usage and runtime</a></li>
</ul></li>
<li class="chapter" data-level="6.3.2" data-path="discussion.html"><a href="discussion.html#alternative-input-formats-extraction"><i class="fa fa-check"></i><b>6.3.2</b> Information extraction</a></li>
<li class="chapter" data-level="6.3.3" data-path="discussion.html"><a href="discussion.html#error-rate-guidance-2"><i class="fa fa-check"></i><b>6.3.3</b> Error rate guidance</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="discussion.html"><a href="discussion.html#not-covered"><i class="fa fa-check"></i><b>6.4</b> Not covered</a></li>
<li class="chapter" data-level="6.5" data-path="discussion.html"><a href="discussion.html#outlook-implementation"><i class="fa fa-check"></i><b>6.5</b> Outlook</a></li>
<li class="chapter" data-level="6.6" data-path="discussion.html"><a href="discussion.html#ethics"><i class="fa fa-check"></i><b>6.6</b> Ethical &amp; Practical Considerations</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="discussion.html"><a href="discussion.html#pdf-extraction-limitations"><i class="fa fa-check"></i><b>6.6.1</b> PDF extraction limitations</a></li>
<li class="chapter" data-level="6.6.2" data-path="discussion.html"><a href="discussion.html#computational-constraints"><i class="fa fa-check"></i><b>6.6.2</b> Computational constraints</a></li>
<li class="chapter" data-level="6.6.3" data-path="discussion.html"><a href="discussion.html#generalizability-scope"><i class="fa fa-check"></i><b>6.6.3</b> Generalizability scope</a></li>
<li class="chapter" data-level="6.6.4" data-path="discussion.html"><a href="discussion.html#ethical-considerations"><i class="fa fa-check"></i><b>6.6.4</b> Ethical considerations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="discussion.html"><a href="discussion.html#conclusion"><i class="fa fa-check"></i><b>7</b> Conclusion</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="chapter" data-level="" data-path="glossary.html"><a href="glossary.html"><i class="fa fa-check"></i>Glossary</a></li>
<li class="chapter" data-level="8" data-path="page-identification-report.html"><a href="page-identification-report.html"><i class="fa fa-check"></i><b>8</b> Appendix A - Page identification report</a>
<ul>
<li class="chapter" data-level="8.1" data-path="page-identification-report.html"><a href="page-identification-report.html#regex-page-identification"><i class="fa fa-check"></i><b>8.1</b> Baseline: Regex</a></li>
<li class="chapter" data-level="8.2" data-path="page-identification-report.html"><a href="page-identification-report.html#toc-understanding"><i class="fa fa-check"></i><b>8.2</b> Table of Contents understanding</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="page-identification-report.html"><a href="page-identification-report.html#text-based-toc-understanding"><i class="fa fa-check"></i><b>8.2.1</b> Details for the approaches</a></li>
<li class="chapter" data-level="8.2.2" data-path="page-identification-report.html"><a href="page-identification-report.html#results-5"><i class="fa fa-check"></i><b>8.2.2</b> Results</a>
<ul>
<li class="chapter" data-level="8.2.2.1" data-path="page-identification-report.html"><a href="page-identification-report.html#comparison-of-the-different-approaches"><i class="fa fa-check"></i><b>8.2.2.1</b> Comparison of the different approaches</a></li>
</ul></li>
<li class="chapter" data-level="8.2.3" data-path="page-identification-report.html"><a href="page-identification-report.html#machine-readable-toc-approach-specific-results"><i class="fa fa-check"></i><b>8.2.3</b> Machine readable TOC approach specific results</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="page-identification-report.html"><a href="page-identification-report.html#llm-page-identification"><i class="fa fa-check"></i><b>8.3</b> Classification with LLMs</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="page-identification-report.html"><a href="page-identification-report.html#binary-classification-1"><i class="fa fa-check"></i><b>8.3.1</b> Binary classification</a></li>
<li class="chapter" data-level="8.3.2" data-path="page-identification-report.html"><a href="page-identification-report.html#multi-class-classification-1"><i class="fa fa-check"></i><b>8.3.2</b> Multi-class classification</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="page-identification-report.html"><a href="page-identification-report.html#tf-classifier"><i class="fa fa-check"></i><b>8.4</b> Term frequency based classifier</a></li>
<li class="chapter" data-level="8.5" data-path="page-identification-report.html"><a href="page-identification-report.html#summary-4"><i class="fa fa-check"></i><b>8.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="information-extraction-report.html"><a href="information-extraction-report.html"><i class="fa fa-check"></i><b>9</b> Appendix B - Information extraction report</a>
<ul>
<li class="chapter" data-level="9.1" data-path="information-extraction-report.html"><a href="information-extraction-report.html#baseline-regex"><i class="fa fa-check"></i><b>9.1</b> Baseline: Regex</a></li>
<li class="chapter" data-level="9.2" data-path="information-extraction-report.html"><a href="information-extraction-report.html#extraction-with-llms-real-tables"><i class="fa fa-check"></i><b>9.2</b> Extraction with LLMs</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="information-extraction-report.html"><a href="information-extraction-report.html#real-table-extraction-results"><i class="fa fa-check"></i><b>9.2.1</b> Real tables</a></li>
<li class="chapter" data-level="9.2.2" data-path="information-extraction-report.html"><a href="information-extraction-report.html#synthetic-table-extraction"><i class="fa fa-check"></i><b>9.2.2</b> Synthetic tables</a></li>
<li class="chapter" data-level="9.2.3" data-path="information-extraction-report.html"><a href="information-extraction-report.html#real-table-extraction-synth-context"><i class="fa fa-check"></i><b>9.2.3</b> Hybrid approach</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="information-extraction-report.html"><a href="information-extraction-report.html#summary-5"><i class="fa fa-check"></i><b>9.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="error-guidance-report.html"><a href="error-guidance-report.html"><i class="fa fa-check"></i><b>10</b> Appendix C - Error rate guidance report</a>
<ul>
<li class="chapter" data-level="10.1" data-path="error-guidance-report.html"><a href="error-guidance-report.html#page-identification-9"><i class="fa fa-check"></i><b>10.1</b> Page identification</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="error-guidance-report.html"><a href="error-guidance-report.html#binary-classification-2"><i class="fa fa-check"></i><b>10.1.1</b> Binary classification</a></li>
<li class="chapter" data-level="10.1.2" data-path="error-guidance-report.html"><a href="error-guidance-report.html#multi-class-classification-2"><i class="fa fa-check"></i><b>10.1.2</b> Multi-class classification</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="error-guidance-report.html"><a href="error-guidance-report.html#extraction-with-llms"><i class="fa fa-check"></i><b>10.2</b> Extraction with LLMs</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="error-guidance-report.html"><a href="error-guidance-report.html#real-tables-4"><i class="fa fa-check"></i><b>10.2.1</b> Real tables</a></li>
<li class="chapter" data-level="10.2.2" data-path="error-guidance-report.html"><a href="error-guidance-report.html#synthetic-tables-4"><i class="fa fa-check"></i><b>10.2.2</b> Synthetic tables</a></li>
<li class="chapter" data-level="10.2.3" data-path="error-guidance-report.html"><a href="error-guidance-report.html#hybrid-respect-units"><i class="fa fa-check"></i><b>10.2.3</b> Hybrid approach</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="feature-effect-analysis.html"><a href="feature-effect-analysis.html"><i class="fa fa-check"></i><b>11</b> Appendix D - Feature effect analysis</a>
<ul>
<li class="chapter" data-level="11.1" data-path="feature-effect-analysis.html"><a href="feature-effect-analysis.html#regular-expressions-4"><i class="fa fa-check"></i><b>11.1</b> Regular expressions</a></li>
<li class="chapter" data-level="11.2" data-path="feature-effect-analysis.html"><a href="feature-effect-analysis.html#real-tables-5"><i class="fa fa-check"></i><b>11.2</b> Real tables</a></li>
<li class="chapter" data-level="11.3" data-path="feature-effect-analysis.html"><a href="feature-effect-analysis.html#synthetic-tables-5"><i class="fa fa-check"></i><b>11.3</b> Synthetic tables</a></li>
<li class="chapter" data-level="11.4" data-path="feature-effect-analysis.html"><a href="feature-effect-analysis.html#hybrid-approach-3"><i class="fa fa-check"></i><b>11.4</b> Hybrid approach</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="appendix-e---miscellaneous.html"><a href="appendix-e---miscellaneous.html"><i class="fa fa-check"></i><b>12</b> Appendix E - Miscellaneous</a>
<ul>
<li class="chapter" data-level="12.1" data-path="appendix-e---miscellaneous.html"><a href="appendix-e---miscellaneous.html#hitl"><i class="fa fa-check"></i><b>12.1</b> Human in the loop application</a></li>
<li class="chapter" data-level="12.2" data-path="appendix-e---miscellaneous.html"><a href="appendix-e---miscellaneous.html#local-machine"><i class="fa fa-check"></i><b>12.2</b> Local machine</a></li>
<li class="chapter" data-level="12.3" data-path="appendix-e---miscellaneous.html"><a href="appendix-e---miscellaneous.html#benchmarks"><i class="fa fa-check"></i><b>12.3</b> Benchmarks</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="appendix-e---miscellaneous.html"><a href="appendix-e---miscellaneous.html#text-extraction-benchmark"><i class="fa fa-check"></i><b>12.3.1</b> Text extraction</a></li>
<li class="chapter" data-level="12.3.2" data-path="appendix-e---miscellaneous.html"><a href="appendix-e---miscellaneous.html#table-detection-benchmark"><i class="fa fa-check"></i><b>12.3.2</b> Table detection</a>
<ul>
<li class="chapter" data-level="12.3.2.1" data-path="appendix-e---miscellaneous.html"><a href="appendix-e---miscellaneous.html#old-classification-with-llm"><i class="fa fa-check"></i><b>12.3.2.1</b> old classification with llm</a></li>
<li class="chapter" data-level="12.3.2.2" data-path="appendix-e---miscellaneous.html"><a href="appendix-e---miscellaneous.html#yolo"><i class="fa fa-check"></i><b>12.3.2.2</b> yolo benchmark and table transformer</a></li>
</ul></li>
<li class="chapter" data-level="12.3.3" data-path="appendix-e---miscellaneous.html"><a href="appendix-e---miscellaneous.html#vllm-batch-speed"><i class="fa fa-check"></i><b>12.3.3</b> Large language model process speed</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="appendix-e---miscellaneous.html"><a href="appendix-e---miscellaneous.html#prompts"><i class="fa fa-check"></i><b>12.4</b> Prompts</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="appendix-e---miscellaneous.html"><a href="appendix-e---miscellaneous.html#toc-understanding-promts"><i class="fa fa-check"></i><b>12.4.1</b> TOC understanding</a></li>
<li class="chapter" data-level="12.4.2" data-path="appendix-e---miscellaneous.html"><a href="appendix-e---miscellaneous.html#classification-prompts"><i class="fa fa-check"></i><b>12.4.2</b> Classification</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="appendix-e---miscellaneous.html"><a href="appendix-e---miscellaneous.html#regex-page-identification-code"><i class="fa fa-check"></i><b>12.5</b> Regular expressions</a></li>
<li class="chapter" data-level="12.6" data-path="appendix-e---miscellaneous.html"><a href="appendix-e---miscellaneous.html#annual-comprehensive-financial-report-balance-sheet"><i class="fa fa-check"></i><b>12.6</b> Annual Comprehensive Financial Report Balance Sheet</a></li>
<li class="chapter" data-level="12.7" data-path="appendix-e---miscellaneous.html"><a href="appendix-e---miscellaneous.html#regex-extraction-mistakes"><i class="fa fa-check"></i><b>12.7</b> Table extraction with regular expressions</a></li>
<li class="chapter" data-level="12.8" data-path="appendix-e---miscellaneous.html"><a href="appendix-e---miscellaneous.html#tf-missclassifications"><i class="fa fa-check"></i><b>12.8</b> Term frequency missclassifications</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="tables.html"><a href="tables.html"><i class="fa fa-check"></i><b>13</b> Tables</a>
<ul>
<li class="chapter" data-level="13.1" data-path="tables.html"><a href="tables.html#classification"><i class="fa fa-check"></i><b>13.1</b> Classification</a></li>
<li class="chapter" data-level="13.2" data-path="tables.html"><a href="tables.html#table-extraction"><i class="fa fa-check"></i><b>13.2</b> Table extraction</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="tables.html"><a href="tables.html#hybrid-approach-4"><i class="fa fa-check"></i><b>13.2.1</b> Hybrid approach</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="figure-collection.html"><a href="figure-collection.html"><i class="fa fa-check"></i><b>14</b> Figures</a>
<ul>
<li class="chapter" data-level="14.1" data-path="figure-collection.html"><a href="figure-collection.html#page-identification-10"><i class="fa fa-check"></i><b>14.1</b> Page identification</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="figure-collection.html"><a href="figure-collection.html#regex-baseline"><i class="fa fa-check"></i><b>14.1.1</b> Regex baseline</a></li>
<li class="chapter" data-level="14.1.2" data-path="figure-collection.html"><a href="figure-collection.html#toc-understanding-1"><i class="fa fa-check"></i><b>14.1.2</b> TOC understanding</a></li>
<li class="chapter" data-level="14.1.3" data-path="figure-collection.html"><a href="figure-collection.html#classification-1"><i class="fa fa-check"></i><b>14.1.3</b> Classification</a>
<ul>
<li class="chapter" data-level="14.1.3.1" data-path="figure-collection.html"><a href="figure-collection.html#binary"><i class="fa fa-check"></i><b>14.1.3.1</b> Binary</a></li>
<li class="chapter" data-level="14.1.3.2" data-path="figure-collection.html"><a href="figure-collection.html#multi-class-classification-3"><i class="fa fa-check"></i><b>14.1.3.2</b> Multi-class classification</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="figure-collection.html"><a href="figure-collection.html#table-extraction-1"><i class="fa fa-check"></i><b>14.2</b> Table extraction</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="figure-collection.html"><a href="figure-collection.html#regex-approach"><i class="fa fa-check"></i><b>14.2.1</b> Regex approach</a>
<ul>
<li class="chapter" data-level="14.2.1.1" data-path="figure-collection.html"><a href="figure-collection.html#real-tables-6"><i class="fa fa-check"></i><b>14.2.1.1</b> Real tables</a></li>
<li class="chapter" data-level="14.2.1.2" data-path="figure-collection.html"><a href="figure-collection.html#synthetic-tables-6"><i class="fa fa-check"></i><b>14.2.1.2</b> Synthetic tables</a></li>
</ul></li>
<li class="chapter" data-level="14.2.2" data-path="figure-collection.html"><a href="figure-collection.html#real-tables-7"><i class="fa fa-check"></i><b>14.2.2</b> Real tables</a>
<ul>
<li class="chapter" data-level="14.2.2.1" data-path="figure-collection.html"><a href="figure-collection.html#examples-from-same-company"><i class="fa fa-check"></i><b>14.2.2.1</b> Examples from same company</a></li>
<li class="chapter" data-level="14.2.2.2" data-path="figure-collection.html"><a href="figure-collection.html#openai-models-1"><i class="fa fa-check"></i><b>14.2.2.2</b> OpenAI models</a></li>
<li class="chapter" data-level="14.2.2.3" data-path="figure-collection.html"><a href="figure-collection.html#comparing-input-formats-and-text-extration-libraries"><i class="fa fa-check"></i><b>14.2.2.3</b> Comparing input formats and text extration libraries</a></li>
<li class="chapter" data-level="14.2.2.4" data-path="figure-collection.html"><a href="figure-collection.html#hypotheses-6"><i class="fa fa-check"></i><b>14.2.2.4</b> Hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="14.2.3" data-path="figure-collection.html"><a href="figure-collection.html#synthetic-tables-7"><i class="fa fa-check"></i><b>14.2.3</b> Synthetic tables</a>
<ul>
<li class="chapter" data-level="14.2.3.1" data-path="figure-collection.html"><a href="figure-collection.html#confidence-4"><i class="fa fa-check"></i><b>14.2.3.1</b> Confidence</a></li>
</ul></li>
<li class="chapter" data-level="14.2.4" data-path="figure-collection.html"><a href="figure-collection.html#hybrid-approach-5"><i class="fa fa-check"></i><b>14.2.4</b> Hybrid approach</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="layout-testing.html"><a href="layout-testing.html"><i class="fa fa-check"></i><b>15</b> Layout testing</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Extraction of tabular data from annual reports with LLMs</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="discussion" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">6</span> Discussion<a href="discussion.html#discussion" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>This chapter consits of the main sections as follows:</p>
<p>Section <a href="discussion.html#answer-research-questions">6.1</a> interprets the results found in relation to our research questions and hypotheses. It compares the findings with findings in previous work and names unexpected results.</p>
<p>Section <a href="discussion.html#error-analysis">6.2</a> contains our error analysis and discusses interesting findings under a researchers perspective.</p>
<p>Section <a href="discussion.html#general-performance">6.3</a> describes practical implications and limitations for the planned <a href="glossary.html#acronyms_HITL">HITL</a> application derived from the error analysis. It interprets the results from an engineers point of view.</p>
<p>Subsequent, Section <a href="discussion.html#not-covered">6.4</a> describes, what we have not investigated or implemented in this thesis. Section <a href="discussion.html#outlook-implementation">6.5</a> gives an outlook on the challenges for implementing the system at <a href="glossary.html#acronyms_RHvB">RHvB</a>. Finally, ethical and practical consideration get presented in Section <a href="discussion.html#ethics">6.6</a>.</p>
<div id="answer-research-questions" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> Research questions<a href="discussion.html#answer-research-questions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="page-identification-5" class="section level3 hasAnchor" number="6.1.1">
<h3><span class="header-section-number">6.1.1</span> Page identification<a href="discussion.html#page-identification-5" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We posed the following research question and hypotheses for the page identification task:</p>
<ol class="rs-questions" style="--counter: 1;">
<li>
How can we use LLMs effectively to locate specific information in a financial report?
</li>
</ol>
<p><strong>H1.1:</strong> <a href="glossary.html#acronyms_LLM">LLM</a>s can be used to locate specific information in a financial report, achieving a high F1 score.</p>
<p><strong>H1.2:</strong> <a href="glossary.html#acronyms_LLM">LLM</a>s can be combined with other approaches to reduce the energy consumption, without lowering the systems recall.</p>
<div id="results-1" class="section level5 hasAnchor paragraph-start" number="6.1.1.0.1">
<h5><span class="header-section-number">6.1.1.0.1</span> Results<a href="discussion.html#results-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The page identification task is solved by the <a href="glossary.html#acronyms_LLM">LLM</a> with higher F1 scores for every target class than the human reference F1 score. It is solved completely on the created dataset for predicting the class <strong>Aktiva</strong>. In two cases the multi-class classification with Llama 4 Scout is best. For classifying <strong>GuV</strong> the binary classification with Ministral works best.</p>
</div>
<p>The prompting strategy <em>n_rag_examples</em> often yields best results, especially if in-context learning examples from the same company as the subject of identification company are used. Section <a href="discussion.html#same-company-evaluation">6.2.2.2</a> is discussing this finding for both tasks.</p>
<p>The term frequency approach reaches a top k recall of 1.0 for a small <span class="math inline">\(k = 5\)</span>. It runs 100 times faster than the <a href="glossary.html#acronyms_LLM">LLM</a> approach and reduces the average number of pages to classify by 92.6 %. We discuss how to combine the two approaches in Section <a href="discussion.html#efficency-discussion">6.3.1.5</a>.</p>
<div id="interpretations" class="section level5 hasAnchor paragraph-start" number="6.1.1.0.2">
<h5><span class="header-section-number">6.1.1.0.2</span> Interpretations<a href="discussion.html#interpretations" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Both of our hypotheses find support. Thus, we see our research question as answered with the following statement: It is possible to locate specific information in a financial report using <a href="glossary.html#acronyms_LLM">LLM</a>s and it can be done more efficient if a term frequency based approach is used for page range refinement in advance.</p>
</div>
<div id="comparison-with-previous-work" class="section level5 hasAnchor paragraph-start" number="6.1.1.0.3">
<h5><span class="header-section-number">6.1.1.0.3</span> Comparison with previous work<a href="discussion.html#comparison-with-previous-work" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>We are able to narrow down the page range to five pages without using a <a href="glossary.html#acronyms_LLM">LLM</a>. With the <a href="glossary.html#acronyms_LLM">LLM</a> we are guaranteed, to find the correct pages within a range of two pages. Most of the time, the page, ranked highest in the confidence score ranking, is the correct one. <span class="citation">H. Li, Gao, et al. (<a href="#ref-liExtractingFinancialData2023">2023</a>)</span> do not present a concrete number of pages, they have to process after page refinement.</p>
</div>
<p>The <a href="glossary.html#acronyms_TOC">TOC</a> does not work as well as expected. <span class="citation">H. Li, Gao, et al. (<a href="#ref-liExtractingFinancialData2023">2023</a>)</span> do not report any issues or a low recall value for their <a href="glossary.html#acronyms_TOC">TOC</a> based approach. Thus, we assumed to find a recall value close to 1.0 for the <a href="glossary.html#acronyms_TOC">TOC</a> based approach too. Instead we found a recall of 0.27. We discuss difference in the two approaches in Section <a href="discussion.html#toc-discussion">6.3.1.3</a>.</p>
<div id="unexpected-results" class="section level5 hasAnchor paragraph-start" number="6.1.1.0.4">
<h5><span class="header-section-number">6.1.1.0.4</span> Unexpected results<a href="discussion.html#unexpected-results" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>We are surprised by the strong performance of Ministral-8B. It performs better, than other models of the Mistral family, that have been released more recent and have a larger parameter count. It shows one of the strongest performances with the <em>zero_shot</em> and <em>law_context</em>, too.</p>
</div>
<p>We are also positive surprised of the strong performance of the recently released members of the Qwen3 family. The older Qwen3 models could not handle the classification tasks at all - with or without thinking mode<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> - while the models of Qwen2.5 performed well. We identified the implementation of dense <a href="glossary.html#acronyms_MoE">MoE</a> layers as an architectural difference between the more recent and older Qwen3 models.</p>
<p>But we assume the difference is a different fine tuning process. While the original released models already claimed to deliver âgroundbreaking advancements in [â¦] instruction-followingâ <span class="citation">(<a href="#ref-QwenQwen34BHugging2025"><em>Qwen/<span>Qwen3-4B</span> <span><span class="math inline">\(\cdot\)</span></span> <span>Hugging Face</span></em>, 2025</a>)</span> we now find a newer version of the Qwen3-4B model that explicitly is tagged as Qwen3-4B-Instruction. It would be interesting, to add this model to the benchmark in future work.</p>
<div id="conclusion" class="section level5 hasAnchor paragraph-start" number="6.1.1.0.5">
<h5><span class="header-section-number">6.1.1.0.5</span> Conclusion<a href="discussion.html#conclusion" class="anchor-section" aria-label="Anchor link to header"></a></h5>
</div>
</div>
<div id="information-extraction-4" class="section level3 hasAnchor" number="6.1.2">
<h3><span class="header-section-number">6.1.2</span> Information extraction<a href="discussion.html#information-extraction-4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We posed the following research question and hypotheses for the information extraction task:</p>
<ol class="rs-questions" style="--counter: 2;">
<li>
How can we use LLMs effectively to extract this information from the document?
</li>
</ol>
<p>We will start discussing the hypotheses group <strong>H2.1</strong> in subsection <a href="discussion.html#extraction-performace-hypotheses-evaluation">6.1.2.1</a>, before we will look at the hypotheses group <strong>H2.2</strong> in subsection <a href="discussion.html#extraction-performace-predictor-hypotheses-evaluation">6.1.2.2</a>. The hypotheses of group <strong>H2.1</strong> are:</p>
<p><strong>H2.1a:</strong> <a href="glossary.html#acronyms_LLM">LLM</a>s can be used to correctly extract multiple numeric values from the assets table.</p>
<p><strong>H2.1b:</strong> <a href="glossary.html#acronyms_LLM">LLM</a>s can match row identifiers and place the numeric values in the correct target row.</p>
<p><strong>H2.1c:</strong> <a href="glossary.html#acronyms_LLM">LLM</a>s can identify unmatched row identifiers and report, that the value is missing.</p>
<div id="extraction-performace-hypotheses-evaluation" class="section level4 hasAnchor" number="6.1.2.1">
<h4><span class="header-section-number">6.1.2.1</span> Core capabilities<a href="discussion.html#extraction-performace-hypotheses-evaluation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="results-2" class="section level5 hasAnchor paragraph-start" number="6.1.2.1.1">
<h5><span class="header-section-number">6.1.2.1.1</span> Results<a href="discussion.html#results-2" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The best performing model - Qwen3-235B-A22B-Instruct - almost reaches human performance on real <strong>Aktiva</strong> tables, but is much faster. Both measures, percentage of correct numeric predictions (98.0 %) and F1 score (98.1 %), are not perfect yet and could be improved. It achieves perfect results on synthetic tables provided in <a href="glossary.html#acronyms_HTML">HTML</a> format.</p>
</div>
<p>The prompting strategy <em>n_rag_examples</em> often works best, especially if in-context learning examples from the same company as the subjects of extraction company are used. Section <a href="discussion.html#same-company-evaluation">6.2.2.2</a> is discussing this finding for both tasks.</p>
<div id="interpretations-1" class="section level5 hasAnchor paragraph-start" number="6.1.2.1.2">
<h5><span class="header-section-number">6.1.2.1.2</span> Interpretations<a href="discussion.html#interpretations-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The high percentage of correct extracted numeric values, shows that Qwen3-235B is not only able to exactly copy their values and to match the row identifiers, but also to perform numeric transformations, respecting the currency units, in many cases. If no numeric transformations are performed, the upper limit for correct numeric extraction is 80.8 %, since 19.2 % of all numeric values have <em>Tâ¬</em> as currency unit. We discuss this in Section <a href="discussion.html#numeric-transformation-discussion">6.2.2.4</a>.</p>
</div>
<p>Furthermore, we can see for the extraction from synthetic <strong>Aktiva</strong> tables, that it is possible to achieve perfect results, if the input is perfectly structured and without unknown row identifiers. In analogy to the concept of <em>garbage in, garbage out</em>, we could phrase it as <em>perfect in, perfect out</em>. Thus, we show that there is no <a href="glossary.html#acronyms_LLM">LLM</a> approach inherent mechanism, that prevents perfect information extraction of numeric values. @ref()</p>
<p>The high F1 score shows, that Qwen3-235B also is able to identify missing row identifiers and correctly returns <em>null</em> instead of hallucinating numeric values. We discuss the matter of label matching further in Section <a href="discussion.html#unconsistent-label-matching">6.2.3</a>.</p>
<p>Thus, we conclude, that all hypotheses of group <strong>H2.1</strong> get supported and the research question can be partially answered with the following statement: <a href="glossary.html#acronyms_LLM">LLM</a>s can be used effectively to extract information from the financial reports using in-context learning and a strict schema.</p>
<div id="comparison-with-previous-work-1" class="section level5 hasAnchor paragraph-start" number="6.1.2.1.3">
<h5><span class="header-section-number">6.1.2.1.3</span> Comparison with previous work<a href="discussion.html#comparison-with-previous-work-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p><span class="citation">H. Li, Gao, et al. (<a href="#ref-liExtractingFinancialData2023">2023</a>)</span> achieve a perfect extraction result, after refining their approach, extracting a total of 152 data points from 8 <a href="glossary.html#acronyms_ACFR">ACFR (Annual Comprehensive Financial Report)</a>s reports. Before the prompt refining they find 96.1 % correct extracted datapoints. Applying the refined approach on a more heterogeneous sample of 4_000 county year <a href="glossary.html#acronyms_ACFR">ACFR</a>s, they achieve a performance of 96 % on 80_000 data points.</p>
</div>
<p>Thus, our found performance is higher as their initial in sample and final out of sample performance. Since we did not adjust our prompting strategy before the second iteration of the ground truth creation, we argue that our performance should be compared to their out of sample performance.</p>
<p>There are some differences in our prompting approaches, that may have a minor influence on the performance. They include explicit instructions for handling currency units, which we do not for the extraction task with real <strong>Aktiva</strong> tables. But we investigated this with the synthetic and hybrid approach and discuss the findings in Section <a href="discussion.html#numeric-transformation-discussion">6.2.2.4</a>.</p>
<p><span class="citation">H. Li, Gao, et al. (<a href="#ref-liExtractingFinancialData2023">2023</a>)</span> extract three values per call, while we expect 10 to 40 numeric and 18 to 38 <em>null</em> predictions per call. They explicitly include an instruction on how to handle missing values and do not report any remarkably higher error rates with missing values. Therefore, we can not compare our F1 score with their results.</p>
<div id="unexpected-results-1" class="section level5 hasAnchor paragraph-start" number="6.1.2.1.4">
<h5><span class="header-section-number">6.1.2.1.4</span> Unexpected results<a href="discussion.html#unexpected-results-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>We did not expect the <a href="glossary.html#acronyms_LLM">LLM</a> to perform any currency units related numeric transformations, without being explicitly instructed, (how) to do this. But it is plausible, that this pattern can be learned during in-context learning. This is especially true, if the examples are chosen according to vector similarity and if documents from the same company can be used. We describe this in more detail in Section <a href="discussion.html#same-company-evaluation">6.2.2.2</a>.</p>
</div>
<div id="conclusion-1" class="section level5 hasAnchor paragraph-start" number="6.1.2.1.5">
<h5><span class="header-section-number">6.1.2.1.5</span> Conclusion<a href="discussion.html#conclusion-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
</div>
</div>
<div id="extraction-performace-predictor-hypotheses-evaluation" class="section level4 hasAnchor" number="6.1.2.2">
<h4><span class="header-section-number">6.1.2.2</span> Feature effects<a href="discussion.html#extraction-performace-predictor-hypotheses-evaluation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The hypotheses of group <strong>H2.2</strong> are:</p>
<p><strong>H2.2a:</strong> Model specific features have an effect on the extraction performance.</p>
<p><strong>H2.2.b:</strong> Prompt strategy specific features have an effect on the extraction performance.</p>
<p><strong>H2.2c:</strong> Table specific features have an effect on the extraction performance.</p>
<div id="results-3" class="section level5 hasAnchor paragraph-start" number="6.1.2.2.1">
<h5><span class="header-section-number">6.1.2.2.1</span> Results<a href="discussion.html#results-3" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The features, that show an noticeable importance value most often, are:</p>
</div>
<ol style="list-style-type: decimal">
<li><em>model_family</em></li>
<li><em>parameter_count</em></li>
<li><em>method_family</em></li>
<li><em>n_examples</em></li>
<li><em>T_in_previous_year</em></li>
</ol>
<p>We can determine an effect direction for the features <em>parameter_count</em>, <em>n_examples</em> and <em>T_in_previous_year</em>. More parameters and more examples are beneficial. The only exception for this is found for the model Llama 4 Maverick. We discuss this case in section <a href="discussion.html#context-rot">6.2.4</a>. The performance gain gets smaller comparing experiments with three and more provided examples. The prompting strategies <em>n_random_examples</em> and <em>top_n_rag_examples</em> perform best.</p>
<p>The method specific feature <em>respect_units</em> shows meaningful importance for evaluating synthetic tables. Its effect has opposite direction to our assumption. For the hybrid approach it has a small importance, but with an effect direction matching our assumption. We discuss this in Section @ref().</p>
<p>With the synthetic tables we also find that <a href="glossary.html#acronyms_HTML">HTML</a> and Markdown are a <em>input_format</em> that yield better results. We show in section <a href="discussion.html#alternative-input-formats-extraction">6.3.2</a>, that we do not find these benefits for processing real tables from (imperfect) Markdown input.</p>
<div id="interpretations-2" class="section level5 hasAnchor paragraph-start" number="6.1.2.2.2">
<h5><span class="header-section-number">6.1.2.2.2</span> Interpretations<a href="discussion.html#interpretations-2" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>All model and method specific features are meaningful predictors for the information extraction task. Thus, we argue, that <strong>H2.2a</strong> and <strong>H2.2b</strong> find total support. The features <em>model_family</em> importance could be an artifact of Llama 4 Mavericks bad performance with multiple in-context learning examples.</p>
</div>
<p>Of all the table characteristics only <em>T_in_previous_year</em> shows a higher importance. Thus, we argue, that <strong>H2.2c</strong> only gets support for a single feature, where we proposed an effect. There are more features, where we proposed no effect and where no effect is found. These hypotheses also get supported. We assume, that <em>T_in_year</em> would get a higher importance, too, if the number of tables, that posses this characteristic, in our sample would be higher.</p>
<div id="compare-with-previous-work" class="section level5 hasAnchor paragraph-start" number="6.1.2.2.3">
<h5><span class="header-section-number">6.1.2.2.3</span> Compare with previous work<a href="discussion.html#compare-with-previous-work" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p><span class="citation">H. Li, Gao, et al. (<a href="#ref-liExtractingFinancialData2023">2023</a>)</span> report, that the most frequent errors for the extraction of values from <a href="glossary.html#acronyms_ESG">ESG (environmental, social, and governance)</a> reports are based on not correctly handled units. This aligns well with our finding of a high importance value for <em>T_in_previous_year</em>. Our results also align with <span class="citation">Brown et al. (<a href="#ref-brownLanguageModelsAre2020">2020</a>)</span> findings, that the performance might not increase much more by adding additional examples after the second one.</p>
</div>
<div id="limitations" class="section level5 hasAnchor paragraph-start" number="6.1.2.2.4">
<h5><span class="header-section-number">6.1.2.2.4</span> Limitations<a href="discussion.html#limitations" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>We failed to reflect the <em>header_span</em> and <em>text_around</em> characteristics, during the creation of the synthetic <a href="glossary.html#acronyms_HTML">HTML</a> and Markdown tables. Thus, we can not evaluate the interaction effect hypotheses with <em>input_format</em> for those features. But we found no big importance for <em>header_span</em> in any experiment.</p>
</div>
<p>We also did not include the fact, if in-context learning examples are from the same company as the subject of extraction, as a method related feature. We show, that this matters in section <a href="discussion.html#same-company-evaluation">6.2.2.2</a>.</p>
<div id="unexpected-results-2" class="section level5 hasAnchor paragraph-start" number="6.1.2.2.5">
<h5><span class="header-section-number">6.1.2.2.5</span> Unexpected results<a href="discussion.html#unexpected-results-2" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>We did not expect to find such a drastic example for content rot as we do for Llama 4 Maverick. We are surprised that it is not the same for Llama 4 Scout. Since it has an even larger context window, we wonder, if we will observe context rot, if we increase the number of examples proportionally.</p>
</div>
<div id="recommendations" class="section level5 hasAnchor paragraph-start" number="6.1.2.2.6">
<h5><span class="header-section-number">6.1.2.2.6</span> Recommendations<a href="discussion.html#recommendations" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>We recommend to evaluate the hypotheses for the visual table characteristics once more, when more advanced document parsing methods are used, that process visual information. The method for document parsing should be included as a feature in this evaluation as well.</p>
</div>
<div id="conclusion-2" class="section level5 hasAnchor paragraph-start" number="6.1.2.2.7">
<h5><span class="header-section-number">6.1.2.2.7</span> Conclusion<a href="discussion.html#conclusion-2" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>In contrast to the classification task, we find no model family that performs worse in general. More parameters are helpful, but it is more important, that at least one or two examples are provided for in-context learning.</p>
</div>
</div>
<div id="error-rate-guidance-1" class="section level4 hasAnchor" number="6.1.2.3">
<h4><span class="header-section-number">6.1.2.3</span> Error rate guidance<a href="discussion.html#error-rate-guidance-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We posed the following <a href="glossary.html#acronyms_UX">UX</a> inspired side research question and hypotheses:</p>
<ol class="rs-questions" style="--counter: 3;">
<li>
Can we use additional information from the extraction process to guide the user on which values need to be checked and which can be trusted as they are?
</li>
</ol>
<p><strong>H3.1:</strong> The confidence score can be used to guide the user on which of the identified pages need to be checked and which can be trusted as they are.</p>
<p><strong>H3.2:</strong> The confidence score can be used to guide the user on which of the predicted values in the information extraction task need to be checked and which can be trusted as they are.</p>
<div id="results-4" class="section level5 hasAnchor paragraph-start" number="6.1.2.3.1">
<h5><span class="header-section-number">6.1.2.3.1</span> Results<a href="discussion.html#results-4" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>For the page identification task, we find high confidence intervals with (near) zero empirical error rate for well performing models. Ministral-8B shows a wide spread of confidence scores for the page identification task, that can be used to distinguish correct and wrong classifications.</p>
</div>
<p>We do not find high confidence intervals with a error rate below 1 % for the information extraction task on real <strong>Aktiva</strong> tables. Explicitly instructing to respect currency units, reduces the empirical error rate (see Appendix <a href="error-guidance-report.html#hybrid-respect-units">10.2.3</a>). But we can find confidence intervals with zero error rate for the information extraction task on synthetic data.</p>
<div id="interpretations-3" class="section level5 hasAnchor paragraph-start" number="6.1.2.3.2">
<h5><span class="header-section-number">6.1.2.3.2</span> Interpretations<a href="discussion.html#interpretations-3" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>We find support for the hypothesis <strong>H3.1</strong> but not for hypothesis <strong>H3.2</strong>. Thus we answer the research question as follows: The confidence score can be used to guide users attention for the page identification task, but hardly for the information extraction task.</p>
</div>
<div id="compare-with-previous-work-1" class="section level5 hasAnchor paragraph-start" number="6.1.2.3.3">
<h5><span class="header-section-number">6.1.2.3.3</span> Compare with previous work<a href="discussion.html#compare-with-previous-work-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The classification task can be seen as a best-of-N selection task with two or four choices. Here, our simple measure for confidence seems to be sufficient.</p>
</div>
<p>Generating the information extraction response, could be seen as a repetition of many best-of-N selections tasks. If every digit, the floating point delimiter, and ending the sequence is counted as individual choice, there are 12 possibilities. Choosing, if a number or <em>null</em> should be returned is another task with <span class="math inline">\(N=2\)</span>. Even though the number of choices is limited for each decision, chaining those choices seems to yield a less meaningful measure of confidence.</p>
<div id="unexpected-results-3" class="section level5 hasAnchor paragraph-start" number="6.1.2.3.4">
<h5><span class="header-section-number">6.1.2.3.4</span> Unexpected results<a href="discussion.html#unexpected-results-3" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Most models predict high confidence for all most of their predictions, even for the wrong ones.</p>
</div>
<div id="conclusion-3" class="section level5 hasAnchor paragraph-start" number="6.1.2.3.5">
<h5><span class="header-section-number">6.1.2.3.5</span> Conclusion<a href="discussion.html#conclusion-3" class="anchor-section" aria-label="Anchor link to header"></a></h5>
</div>
</div>
</div>
</div>
<div id="error-analysis" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> Error analysis<a href="discussion.html#error-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="page-identification-6" class="section level3 hasAnchor" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> Page identification<a href="discussion.html#page-identification-6" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This section is presenting a brief error analysis for the <a href="glossary.html#acronyms_LLM">LLM</a> and term frequency approach. We discuss errors related to context rot in Section <a href="discussion.html#context-rot">6.2.4</a>, because they occurred in both tasks.</p>
<div id="llm-approach" class="section level4 hasAnchor" number="6.2.1.1">
<h4><span class="header-section-number">6.2.1.1</span> LLM approach<a href="discussion.html#llm-approach" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The seven wrong classified pages by Llama Scout 4 all contain a table, that is filling at least half a page containing one column with text and many columns with numeric values. Six out of those seven are classified as <strong>GuV</strong> and one as <strong>Passiva</strong>. The page, classified as <strong>Passiva</strong> contains the term <em>Passiva</em>.</p>
<p>From our point of view it would be more plausible, if page 63 of â/pvc/Geschaeftsberichte/Berlinovo/ berlinovo_Finanzbericht_2021.pdfâ is classified as <strong>Aktiva</strong> because there are a lot of the same row identifiers present. The term frequency approach correctly classifies this page as <em>other</em> and ranks it on 8th place for <strong>GuV</strong> and <strong>Passiva</strong> and only on 14th place for <strong>Aktiva</strong>. Thus, our intuition what kind of terms are in the table, is not correct.</p>
<p>To prevent those few incorrect classification, the system may need more examples for pages, that are similar as the target classes but not of that type.</p>
</div>
<div id="error-analysis-tf" class="section level4 hasAnchor" number="6.2.1.2">
<h4><span class="header-section-number">6.2.1.2</span> Term frequency approach<a href="discussion.html#error-analysis-tf" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Inspecting some of the pages that are ranked high and wrongly classified as <strong>Aktiva</strong> by the term frequency based random forest, we find, that the normalized sum of term occurrences, can lead to missclassification. For example, we find a page identified as <strong>Aktiva</strong>, that contains no single table but a long text. The term counts based on the <strong>Aktiva</strong> term list can be found in teh Appendix <a href="appendix-e---miscellaneous.html#tf-missclassifications">12.8</a>. The term âGeschÃ¤ftsâ is present 19 times. The term âUnternehmenâ is present 10 times. :::</p>
<p>Those terms are probably present very often all over the document. Thus, they should get less weight. Additionally it might be better to count, how many of the terms are present in a boolean manner, instead of counting them. <span class="citation">Kong et al. (<a href="#ref-kongOpenTabAdvancingLarge2024">2024</a>)</span> shows, that <a href="glossary.html#acronyms_BM25">BM25</a> can be used effectively to identify relevant tables.</p>
<p>We also find pages that are missclassified, because they have a high density of floats. An example for a page with high float density that is not containing an <strong>Aktiva</strong> table can be found in the Appendix in Figure <a href="appendix-e---miscellaneous.html#fig:tf-many-floats">12.4</a>.</p>
<p>We formulate our practical recommendation in Section <a href="discussion.html#tf-practical-recommendation">6.3.1.3.1</a>.</p>
</div>
</div>
<div id="information-extraction-5" class="section level3 hasAnchor" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> Information extraction<a href="discussion.html#information-extraction-5" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>check for halluzination vs wrong placed / repeated numbers</p></li>
<li><p>new lines / splitted lines</p></li>
<li><p>test synthetic hypothesis with pymupdf extract</p></li>
<li><p>2.4 % wrong gold standard creation</p></li>
<li><p>errors from wrong formatted numbers</p></li>
<li><p>errors from wrong / unclear entity mapping</p></li>
<li><p>OpenAI not followed the schema strictly</p></li>
<li><p>Umlaute (ggole models?)</p></li>
</ul>
<div id="real-tables-3" class="section level4 hasAnchor" number="6.2.2.1">
<h4><span class="header-section-number">6.2.2.1</span> Real tables<a href="discussion.html#real-tables-3" class="anchor-section" aria-label="Anchor link to header"></a></h4>
</div>
<div id="same-company-evaluation" class="section level4 hasAnchor" number="6.2.2.2">
<h4><span class="header-section-number">6.2.2.2</span> Company specific results<a href="discussion.html#same-company-evaluation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Figure <a href="discussion.html#fig:extraction-qwen235-by-company">6.1</a> shows, the precision and recall values for predicting a missing value and the percentage of correct numeric predictions for Qwen3-235B for each company. The number after the company name, as well as the color of the boxes indicate, how many of the numeric columns have <em>Tâ¬</em> as currency unit. The crosses indicate the individual scores per document. The teal crosses represent predictions, if examples from the same company are used for the <em>top n rag</em> prompting strategy. Red ones represent predictions, where this is not the case.</p>
<details class=chunk-details><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="discussion.html#cb17-1" tabindex="-1"></a><span class="co"># df_real_table_extraction %&gt;% filter(!str_detect(model, &quot;oss&quot;)) %&gt;% </span></span>
<span id="cb17-2"><a href="discussion.html#cb17-2" tabindex="-1"></a><span class="co">#   filter(n_examples == 3) %&gt;% </span></span>
<span id="cb17-3"><a href="discussion.html#cb17-3" tabindex="-1"></a><span class="co">#   mutate(.before = 1, company = map_chr(filepath, ~str_split(str_split(., &quot;/&quot;)[[1]][5], &quot;__&quot;)[[1]][1])) %&gt;% </span></span>
<span id="cb17-4"><a href="discussion.html#cb17-4" tabindex="-1"></a><span class="co">#   group_by(company) %&gt;% </span></span>
<span id="cb17-5"><a href="discussion.html#cb17-5" tabindex="-1"></a><span class="co">#   ggplot() +</span></span>
<span id="cb17-6"><a href="discussion.html#cb17-6" tabindex="-1"></a><span class="co">#   geom_boxplot(aes(x = company, y = percentage_correct_numeric)) + </span></span>
<span id="cb17-7"><a href="discussion.html#cb17-7" tabindex="-1"></a><span class="co">#   # geom_jitter(aes(x = company, y = percentage_correct_numeric), alpha= .5) +</span></span>
<span id="cb17-8"><a href="discussion.html#cb17-8" tabindex="-1"></a><span class="co">#   scale_x_discrete(guide = guide_axis(angle = 30)) + </span></span>
<span id="cb17-9"><a href="discussion.html#cb17-9" tabindex="-1"></a><span class="co">#   facet_grid(model_family ~ .)</span></span>
<span id="cb17-10"><a href="discussion.html#cb17-10" tabindex="-1"></a></span>
<span id="cb17-11"><a href="discussion.html#cb17-11" tabindex="-1"></a>df_real_table_extraction_best_by_company <span class="ot">&lt;-</span> df_real_table_extraction <span class="sc">%&gt;%</span> </span>
<span id="cb17-12"><a href="discussion.html#cb17-12" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">str_detect</span>(model, <span class="st">&quot;235B&quot;</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb17-13"><a href="discussion.html#cb17-13" tabindex="-1"></a>  <span class="fu">filter</span>(n_examples <span class="sc">==</span> <span class="dv">5</span>, method_family <span class="sc">==</span> <span class="st">&quot;top_n_rag_examples&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb17-14"><a href="discussion.html#cb17-14" tabindex="-1"></a>  <span class="co"># group_by(company) %&gt;% </span></span>
<span id="cb17-15"><a href="discussion.html#cb17-15" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="fu">c</span>(NA_precision, percentage_correct_numeric, NA_recall))</span>
<span id="cb17-16"><a href="discussion.html#cb17-16" tabindex="-1"></a></span>
<span id="cb17-17"><a href="discussion.html#cb17-17" tabindex="-1"></a>df_real_table_extraction_best_by_company <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb17-18"><a href="discussion.html#cb17-18" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>(</span>
<span id="cb17-19"><a href="discussion.html#cb17-19" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">paste</span>(company, n_T_EUR), <span class="at">x =</span> value, <span class="at">fill =</span> <span class="fu">ordered</span>(n_T_EUR)),</span>
<span id="cb17-20"><a href="discussion.html#cb17-20" tabindex="-1"></a>    <span class="at">alpha=</span> .<span class="dv">7</span></span>
<span id="cb17-21"><a href="discussion.html#cb17-21" tabindex="-1"></a>    ) <span class="sc">+</span> </span>
<span id="cb17-22"><a href="discussion.html#cb17-22" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(</span>
<span id="cb17-23"><a href="discussion.html#cb17-23" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">paste</span>(company, n_T_EUR), <span class="at">x =</span> value, <span class="at">color =</span> same_company), </span>
<span id="cb17-24"><a href="discussion.html#cb17-24" tabindex="-1"></a>    <span class="at">shape =</span> <span class="dv">4</span></span>
<span id="cb17-25"><a href="discussion.html#cb17-25" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb17-26"><a href="discussion.html#cb17-26" tabindex="-1"></a>  <span class="fu">scale_y_discrete</span>(<span class="at">label =</span> scales<span class="sc">::</span><span class="fu">label_wrap</span>(<span class="dv">32</span>)) <span class="sc">+</span> </span>
<span id="cb17-27"><a href="discussion.html#cb17-27" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb17-28"><a href="discussion.html#cb17-28" tabindex="-1"></a>    <span class="at">legend.position =</span> <span class="st">&quot;bottom&quot;</span></span>
<span id="cb17-29"><a href="discussion.html#cb17-29" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb17-30"><a href="discussion.html#cb17-30" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;&quot;</span>) <span class="sc">+</span></span>
<span id="cb17-31"><a href="discussion.html#cb17-31" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb17-32"><a href="discussion.html#cb17-32" tabindex="-1"></a>    <span class="at">title =</span> df_real_table_extraction_best_by_company<span class="sc">$</span>model[[<span class="dv">1</span>]],</span>
<span id="cb17-33"><a href="discussion.html#cb17-33" tabindex="-1"></a>    <span class="at">subtitle =</span> df_real_table_extraction_best_by_company<span class="sc">$</span>method[[<span class="dv">1</span>]]</span>
<span id="cb17-34"><a href="discussion.html#cb17-34" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb17-35"><a href="discussion.html#cb17-35" tabindex="-1"></a>  <span class="fu">facet_nested</span>(.<span class="sc">~</span>name)</span></code></pre></div>
</details>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:extraction-qwen235-by-company"></span>
<img src="_main_files/figure-html/extraction-qwen235-by-company-1.png" alt="Comparing the F1 score for predicting the missingness of a value for OpenAi's LLMs with some Qwen 3 models. The green crosses indicate results where a model has predicted only numeric values even though there have been missing values." width="100%" />
<p class="caption">
Figure 6.1: Comparing the F1 score for predicting the missingness of a value for OpenAiâs LLMs with some Qwen 3 models. The green crosses indicate results where a model has predicted only numeric values even though there have been missing values.
</p>
</div>
<p>One can see, that Qwen3-235B yields perfect predictions for the majority of the companies. This is especially true, if we only consider the teal crosses. The predictions improve for most companies, if examples from the same company are used for in-context learning. It is especially helpful for handling the single numeric column with <em>Tâ¬</em> for <em>Deutsche Klassenlotterie</em>. It also helps with the two columns with <em>Tâ¬</em> for <em>Gewobag</em>, even though the other examples have not <em>Tâ¬</em> present.</p>
<p>It seems a little harmful for <em>WBM GmbH</em> and can not solve the problems for numeric prediction for <em>Helmholtz Zentrum GmbH</em> and <em>Berliner StadtgÃ¼ter</em>. It improved the precision for <em>Rundfunk Berlin-Brandenburg</em> and the recall of <em>Stadt und Land GmbH</em> and <em>Partner fÃ¼r Deutschland</em>.</p>
<p>Table <a href="discussion.html#tab:information-extraction-compare-same-company-examples-qwen235">6.1</a> shows the performance of Qwen3-235B for the <em>top n rag</em> and <em>n random</em> example strategies and distinguishes based on the fact, if examples from the same company can be used for in-context learning. The achieved percentage of correct predictions total is highest, if examples form the same company are used. It is even higher than the human reference score.</p>
<p>If using examples form the same company is not allowed, it seems better to use random examples. This is probably the case, because this comes with a higher heterogeneity. High homogeneity among the learning examples from other companies might demonstrate patterns, that are not correct for the company the target document comes from. The pattern, that the same company in-context learning yields best results is true for all models. The order of the results with random examples or examples from other companies varies among the models.</p>
<details class=chunk-details><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="discussion.html#cb18-1" tabindex="-1"></a>table_same_company <span class="ot">&lt;-</span> df_real_table_extraction <span class="sc">%&gt;%</span> </span>
<span id="cb18-2"><a href="discussion.html#cb18-2" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">str_detect</span>(model, <span class="st">&quot;235B&quot;</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb18-3"><a href="discussion.html#cb18-3" tabindex="-1"></a>  <span class="co"># filter(n_examples == 5, method_family == &quot;top_n_rag_examples&quot;) %&gt;%</span></span>
<span id="cb18-4"><a href="discussion.html#cb18-4" tabindex="-1"></a>  <span class="fu">group_by</span>(model, method, same_company) <span class="sc">%&gt;%</span> </span>
<span id="cb18-5"><a href="discussion.html#cb18-5" tabindex="-1"></a>  <span class="fu">reframe</span>(</span>
<span id="cb18-6"><a href="discussion.html#cb18-6" tabindex="-1"></a>    <span class="at">mean_numeric =</span> <span class="fu">mean</span>(percentage_correct_numeric, <span class="at">na.rm =</span> <span class="cn">TRUE</span>),</span>
<span id="cb18-7"><a href="discussion.html#cb18-7" tabindex="-1"></a>    <span class="at">mean_F1 =</span> <span class="fu">mean</span>(NA_F1, <span class="at">na.rm =</span> <span class="cn">TRUE</span>),</span>
<span id="cb18-8"><a href="discussion.html#cb18-8" tabindex="-1"></a>    <span class="at">mean_total =</span> <span class="fu">mean</span>(percentage_correct_total, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)</span>
<span id="cb18-9"><a href="discussion.html#cb18-9" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span></span>
<span id="cb18-10"><a href="discussion.html#cb18-10" tabindex="-1"></a>  <span class="fu">group_by</span>(same_company) <span class="sc">%&gt;%</span> <span class="fu">slice_max</span>(<span class="at">n =</span> <span class="dv">1</span>, mean_numeric, <span class="at">with_ties =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb18-11"><a href="discussion.html#cb18-11" tabindex="-1"></a>  <span class="co"># select(model, method, mean_numeric, mean_F1, mean_total) %&gt;% </span></span>
<span id="cb18-12"><a href="discussion.html#cb18-12" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb18-13"><a href="discussion.html#cb18-13" tabindex="-1"></a>  <span class="fu">mutate_if</span>(</span>
<span id="cb18-14"><a href="discussion.html#cb18-14" tabindex="-1"></a>    is.numeric, </span>
<span id="cb18-15"><a href="discussion.html#cb18-15" tabindex="-1"></a>    <span class="sc">~</span><span class="fu">ifelse</span>(</span>
<span id="cb18-16"><a href="discussion.html#cb18-16" tabindex="-1"></a>      . <span class="sc">==</span> <span class="fu">max</span>(., <span class="at">na.rm =</span> <span class="cn">TRUE</span>),</span>
<span id="cb18-17"><a href="discussion.html#cb18-17" tabindex="-1"></a>      <span class="fu">paste0</span>(<span class="st">&quot;**&quot;</span>, <span class="fu">format_floats</span>(., <span class="dv">3</span>), <span class="st">&quot;**&quot;</span>),</span>
<span id="cb18-18"><a href="discussion.html#cb18-18" tabindex="-1"></a>      <span class="fu">format_floats</span>(., <span class="dv">3</span>)</span>
<span id="cb18-19"><a href="discussion.html#cb18-19" tabindex="-1"></a>    )</span>
<span id="cb18-20"><a href="discussion.html#cb18-20" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> <span class="fu">setNames</span>(<span class="fu">colnames</span>(.) <span class="sc">%&gt;%</span> <span class="fu">str_replace</span>(<span class="st">&quot;_&quot;</span>, <span class="st">&quot; &quot;</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb18-21"><a href="discussion.html#cb18-21" tabindex="-1"></a>  <span class="fu">render_table</span>(</span>
<span id="cb18-22"><a href="discussion.html#cb18-22" tabindex="-1"></a>    <span class="at">alignment =</span> <span class="st">&quot;lllrrr&quot;</span>,</span>
<span id="cb18-23"><a href="discussion.html#cb18-23" tabindex="-1"></a>    <span class="at">caption =</span> <span class="st">&quot;Comparing the performance of Qwen3-235B for the best approaches depending on the circumstance if examples from the same company can be used for learning.&quot;</span>,</span>
<span id="cb18-24"><a href="discussion.html#cb18-24" tabindex="-1"></a>    <span class="at">ref =</span> opts_current<span class="sc">$</span><span class="fu">get</span>(<span class="st">&quot;label&quot;</span>),</span>
<span id="cb18-25"><a href="discussion.html#cb18-25" tabindex="-1"></a>    <span class="at">dom =</span> <span class="st">&quot;t&quot;</span></span>
<span id="cb18-26"><a href="discussion.html#cb18-26" tabindex="-1"></a>  )</span></code></pre></div>
</details>
<table>
<caption>
<span id="tab:information-extraction-compare-same-company-examples-qwen235">Table 6.1: </span>Comparing the performance of Qwen3-235B for the best approaches depending on the circumstance if examples from the same company can be used for learning.
</caption>
</table>
<details class=chunk-details><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="discussion.html#cb19-1" tabindex="-1"></a><span class="cf">if</span>(knitr<span class="sc">::</span><span class="fu">is_latex_output</span>()) {</span>
<span id="cb19-2"><a href="discussion.html#cb19-2" tabindex="-1"></a>  table_same_company <span class="ot">&lt;-</span> table_same_company <span class="sc">%&gt;%</span></span>
<span id="cb19-3"><a href="discussion.html#cb19-3" tabindex="-1"></a>    <span class="fu">column_spec</span>(<span class="dv">4</span><span class="sc">:</span><span class="dv">6</span>, <span class="at">width =</span> <span class="st">&quot;1.5cm&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb19-4"><a href="discussion.html#cb19-4" tabindex="-1"></a>    <span class="fu">column_spec</span>(<span class="dv">1</span>, <span class="at">width =</span> <span class="st">&quot;3.2cm&quot;</span>)</span>
<span id="cb19-5"><a href="discussion.html#cb19-5" tabindex="-1"></a>}</span>
<span id="cb19-6"><a href="discussion.html#cb19-6" tabindex="-1"></a>table_same_company</span></code></pre></div>
</details>
<div class="datatables html-widget html-fill-item" id="htmlwidget-e3bebb1ed2fc15d485a6" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-e3bebb1ed2fc15d485a6">{"x":{"filter":"none","vertical":false,"data":[["1","2","3"],["Qwen3-235B-A22B-Instruct-2507-FP8","Qwen3-235B-A22B-Instruct-2507-FP8","Qwen3-235B-A22B-Instruct-2507-FP8"],["top_<wbr>3_<wbr>rag_<wbr>examples","top_<wbr>5_<wbr>rag_<wbr>examples","5_<wbr>random_<wbr>examples"],["FALSE","TRUE",null],["0.972","<b>0.990<\/b>","0.982"],["0.972","<b>0.987<\/b>","0.975"],["0.959","<b>0.982<\/b>","0.966"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>model<\/th>\n      <th>method<\/th>\n      <th>same company<\/th>\n      <th>mean numeric<\/th>\n      <th>mean F1<\/th>\n      <th>mean total<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":10,"scrollX":true,"dom":"t","columnDefs":[{"targets":0,"className":"dt-left"},{"targets":1,"className":"dt-left"},{"targets":2,"className":"dt-left"},{"targets":3,"className":"dt-left"},{"targets":4,"className":"dt-right"},{"targets":5,"className":"dt-right"},{"targets":6,"className":"dt-right"},{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"model","targets":1},{"name":"method","targets":2},{"name":"same company","targets":3},{"name":"mean numeric","targets":4},{"name":"mean F1","targets":5},{"name":"mean total","targets":6}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
</div>
<div id="synthetic-tables-3" class="section level4 hasAnchor" number="6.2.2.3">
<h4><span class="header-section-number">6.2.2.3</span> Synthetic tables<a href="discussion.html#synthetic-tables-3" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The 0.1 % incorrect predictions on synthetic tables from the PDF documents could be caused by faulty text extracts by <em>pdfium</em>. But the Markdown input is without any flaws and resulted in 0.1 % errors as well.</p>
</div>
<div id="numeric-transformation-discussion" class="section level4 hasAnchor" number="6.2.2.4">
<h4><span class="header-section-number">6.2.2.4</span> Numeric transformations<a href="discussion.html#numeric-transformation-discussion" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>synth and hybrid</p>
<p>This section discusses the surprisingly high percentage of correct extracted numeric values. If no numeric transformation is performed, 80.8 % is the upper limit. We assume, that the behavior to transform the numeric values without being instructed to do so, is nothing learned during fine tuning, because the percentage of correct extracted numeric values for the <em>zero_shot</em> performance (0.763) and the <em>static_example</em> performance (0.803) are below the expected limit. The static example demonstrates no numeric transformation and the observed performance is found to be almost as high as the expected upper limit.</p>
<p>Table <a href="discussion.html#tab:information-extraction-compare-same-company-examples-qwen235">6.1</a> shows, that this limit is overcome with all other prompting strategies. It is plausible for the <em>top_n_rag_examples</em> strategy, if examples from the same company are used. But it implies, that almost always there is at least one example, among the five random examples presented, that shows this transformation. And it implies further, that the model recognizes, that the pattern demonstrated by a minority of examples is to apply for the subject of the current extraction task. For future work the provided examples should be logged as well, to investigate this implication.</p>
<p>We tested the influence of providing examples, that show how to perform the numeric transformation, together with an explicit instruction to do so, in the hybrid approach (see section <a href="information-extraction-report.html#hybrid-learn-respect-units">9.2.3.0.2</a>). The hybrid approach uses synthetic tables as examples for extracting information from real examples. We show, that Qwen3-235B is capable to learn how to extract numeric values respecting the currency unit and is able to transfer this knowledge from examples with two columns with <em>Tâ¬</em> to tables that only have one column with <em>Tâ¬</em>. This is not possible for all models, e.g.Â not for Ministral-8B. We also find models that over generalize this pattern and achieve worse performance for extraction subjects without <em>Tâ¬</em> as currency unit - i.e.Â Qwen3-8B.</p>
<p>We also see in our hybrid approach experiments, that the <a href="glossary.html#acronyms_LLM">LLM</a> benefit more from the real examples for extracting the numeric values than for label matching. Comparing Figure <a href="figure-collection.html#fig:compare-real-table-extraction-by-context-type-numeric">14.28</a> and Figure <a href="figure-collection.html#fig:compare-real-table-extraction-by-context-type-F1">14.29</a> shows that <a href="glossary.html#acronyms_LLM">LLM</a>s yield more consistently good results for predicting <em>null</em> learning from synthetic examples than extracting the correct numeric value.</p>
<p>In general the approach seems not be prone to hallucinations. When we accidentally tried to extract values from a <strong>Passiva</strong> and <strong>GuV</strong> table, no prediction was made, because non of the row identifiers matches our strict schema.</p>
<p>We have not specifically investigated, if an annual report of the following or previous year is more helpful than years further away. This would be plausible, because it serves the correct numeric and missing values for half of the information extract perfectly formatted as <a href="glossary.html#acronyms_json">json</a>. Theoretically it should become trivial to extract all values correct and transform it accordingly to the currency units, if the previous and following years annual reports are presented as examples for the in-context learning. This should be investigated in future work.</p>
<p>predictions for barrierefreie documents of WBM empty</p>
<p>An odd text marking order in a PDF by dragging the mouse is no indicator for a bad text extract.</p>
</div>
<div id="regex-synth-backend-discussion" class="section level4 hasAnchor" number="6.2.2.5">
<h4><span class="header-section-number">6.2.2.5</span> Regular expression approach<a href="discussion.html#regex-synth-backend-discussion" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We find, that the regular expression approaches performance on the synthetic dataset is highly influenced by the extraction library used. For the real data we find no difference. Figure <a href="information-extraction-report.html#fig:table-extraction-regex-performance">9.1</a> B shows, that the <a href="glossary.html#acronyms_regex">regex</a> approach on text extracted with <em>pdfium</em> especially has a wider precision range. The number of wrong extracted numeric values is a little as well.</p>
<p>A reason for this might be incorrect extracted texts. We find, that there are issues with missing (or additional) white space, misplaced line breaks and an extraction of the text column first, followed by the numeric columns. You can find examples for those types of incorrect extracted texts by three different PDF extraction libraries in section <a href="appendix-e---miscellaneous.html#regex-extraction-mistakes">12.7</a>. One of the examples is found with the real table dataset, while two are found with the synthetic tables.</p>
<p>The random white space and line breaks could be handles by adjusting the regular expression for the label matching. Missing white space between numeric values could also be handled by adjusting the <a href="glossary.html#acronyms_regex">regex</a>. The misplaced columns would need more advanced reprocessing strategies. But all those error ypes shouel influence the recall and not the precision.</p>
<p>A possible explanation for a small spread in precision with both PDF extraction backends could be the duplicated row identifier <em>Geleistete Anzahlungen</em>. Our simple approach matches this row always with the first occurrence. This means, if the second occurrence is given in the ground truth, but not the first one, our approach would create a false positive result. The percentage of false positive example is then determining the precision value and is linked to the number of total rows in the ground truth. But we do not see sucha pattern for the <em>pymupdf</em> results at all.</p>
<p>A reason for wrong numeric values are rows, where the summed value is given in the next column, but same row, as the individual values. In this case the approach selects one individual value and a sum, instead of two individual values.</p>
<ul>
<li>synthetic tables have been generated with cell lines because this should have improved the performance of a table extraction approach (not conducted)- maybe this is confusing pdfium? Or the zoom level?</li>
</ul>
</div>
<div id="openai-discussion" class="section level4 hasAnchor" number="6.2.2.6">
<h4><span class="header-section-number">6.2.2.6</span> OpenAI models<a href="discussion.html#openai-discussion" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We could not use a strict schema neither with OpenAIs closed-weight GPT models nor with the new open-weight OSS models. Figure <a href="information-extraction-report.html#fig:table-extraction-llm-prediction-count-gpt">9.3</a> shows, that this results in many predictions with no or few predictions, where the row identifier matched with our ground truth. It might also be, that the models simply made less predictions than the expected 29 rows. We find this especially for the <em>nano</em> models. We even found some predictions, where some rows have been predicted multiple time, resulting in more than the expected 29 rows.</p>
<p>Figure <a href="information-extraction-report.html#fig:table-extraction-llm-f1-gpt-slice">9.2</a> also shows, that we find responses, where no single <em>null</em> value is returned. This means, that the models hallucinate numeric values. This is true for the large GPT-4-1 as well, if it does not get three examples for in-context learning. In contrast, GPT-5-mini and gpt-oss-120B are (almost) without hallucinated values.</p>
<p>Nevertheless, even without a strict schema, we find GPT-4-1 and GPT-5 performing almost as well as Qwen3-235B. This shows, that a guided decoding approach could also work and that a strict schema is not necessary for larger models.</p>
<p>Unfortunately, we could not use batch processing with the closed-weight models resulting in run times of 30 to 135 minutes. Interestingly, GPT-5-nano had the longest runtime and produced much more output tokens as the other models. This is similar to the gpt-oss models that use the new harmony response format, that creates many tokens in a chain of thought stream, before it returns the tokens for the requested <a href="glossary.html#acronyms_json">json</a> table. This might bring insights in the models processes, but increases the response time a lot. We would welcome the possibility to just get the final answer, as we can disable thinking in Qwen3.</p>
</div>
</div>
<div id="unconsistent-label-matching" class="section level3 hasAnchor" number="6.2.3">
<h3><span class="header-section-number">6.2.3</span> Ground truth creation<a href="discussion.html#unconsistent-label-matching" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>GPT-Suggestion: Reflect on the challenges and lessons learned during ground truth creation, including how LLM predictions helped uncover errors in the gold standard and the iterative improvement process.</p>
<p>During the second pass of the ground truth creation for the information extraction task we find, that 2.4 % of the values differ among the previously created gold standard and the results of the second pass. In the first pass the values are copied manually, while the results of the second pass are <a href="glossary.html#acronyms_LLM">LLM</a>s predictions, that we double checked. We find 75 values differing in the 24 documents that are part of both data collections. Table <a href="discussion.html#tab:error-analysis-gold-standard-extraction">6.2</a> shows the nature of errors and their counts. Most errors are distributed in the <em>omission</em> classes.</p>
<p>Errors of this type result from an inconsistent coding process. In one pass a value might have been included, while it is not included in the other pass. Or the value is matched to different row identifiers during the two passes. To resolve this kind of errors a strict and detailed coding manual is necessary. Additionally, the coding should be done from experts of the field instead of the data scientist.</p>
<details class=chunk-details><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="discussion.html#cb20-1" tabindex="-1"></a><span class="fu">tribble</span>(</span>
<span id="cb20-2"><a href="discussion.html#cb20-2" tabindex="-1"></a>  <span class="sc">~</span>error_type, <span class="sc">~</span>count,</span>
<span id="cb20-3"><a href="discussion.html#cb20-3" tabindex="-1"></a>  <span class="st">&quot;ommited in first pass&quot;</span>, <span class="dv">29</span>,</span>
<span id="cb20-4"><a href="discussion.html#cb20-4" tabindex="-1"></a>  <span class="st">&quot;ommited in second pass&quot;</span>, <span class="dv">20</span>,</span>
<span id="cb20-5"><a href="discussion.html#cb20-5" tabindex="-1"></a>  <span class="st">&quot;multiple differences&quot;</span>, <span class="dv">13</span>,</span>
<span id="cb20-6"><a href="discussion.html#cb20-6" tabindex="-1"></a>  <span class="st">&quot;missing digit&quot;</span>, <span class="dv">10</span>,</span>
<span id="cb20-7"><a href="discussion.html#cb20-7" tabindex="-1"></a>  <span class="st">&quot;swapped digits&quot;</span>, <span class="dv">2</span>,</span>
<span id="cb20-8"><a href="discussion.html#cb20-8" tabindex="-1"></a>  <span class="st">&quot;comma instead of dot&quot;</span>, <span class="dv">1</span>,</span>
<span id="cb20-9"><a href="discussion.html#cb20-9" tabindex="-1"></a>) <span class="sc">%&gt;%</span> <span class="fu">render_table</span>(</span>
<span id="cb20-10"><a href="discussion.html#cb20-10" tabindex="-1"></a>  <span class="at">alignment =</span> <span class="st">&quot;lr&quot;</span>,</span>
<span id="cb20-11"><a href="discussion.html#cb20-11" tabindex="-1"></a>  <span class="at">caption =</span> <span class="st">&quot;Showing the nature of errors and their counts. Errors with multiple difference have Levenshtein distance greater one.&quot;</span>,</span>
<span id="cb20-12"><a href="discussion.html#cb20-12" tabindex="-1"></a>  <span class="at">ref =</span> opts_current<span class="sc">$</span><span class="fu">get</span>(<span class="st">&quot;label&quot;</span>),</span>
<span id="cb20-13"><a href="discussion.html#cb20-13" tabindex="-1"></a>  <span class="at">dom =</span> <span class="st">&quot;t&quot;</span></span>
<span id="cb20-14"><a href="discussion.html#cb20-14" tabindex="-1"></a>)</span></code></pre></div>
</details>
<table>
<caption>
<span id="tab:error-analysis-gold-standard-extraction">Table 6.2: </span>Showing the nature of errors and their counts. Errors with multiple difference have Levenshtein distance greater one.
</caption>
</table>
<div class="datatables html-widget html-fill-item" id="htmlwidget-0b906e7fc99ded5703ea" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-0b906e7fc99ded5703ea">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6"],["ommited in first pass","ommited in second pass","multiple differences","missing digit","swapped digits","comma instead of dot"],["29","20","13","10","2","1"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>error type<\/th>\n      <th>count<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":10,"scrollX":true,"dom":"t","columnDefs":[{"targets":0,"className":"dt-left"},{"targets":1,"className":"dt-left"},{"targets":2,"className":"dt-right"},{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"error type","targets":1},{"name":"count","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<p>Inspecting the predictions of the first experiments for the classification task, yielded interesting information, tool. Qwen 2.5 consistently classified some pages right after of the listed <strong>GuV</strong> pages to be of type <strong>GuV</strong> as well. And it was correct. For the company <em>IBB</em> the <strong>GuV</strong> spreads over two pages. This led to an adjustment of the ground truth, including all pages of tables, that span multiple pages.</p>
</div>
<div id="context-rot" class="section level3 hasAnchor" number="6.2.4">
<h3><span class="header-section-number">6.2.4</span> Context rot<a href="discussion.html#context-rot" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We reported the worsening performance of Llama 4 Maverick, when it gets to many examples presented in both main tasks. Since we used the FP8 version, we tested if this is a problem of to low precision in the calculation. But we find the same behavior with the FP16 version. It is the only model we detect the issue of <em>context rot</em> for.</p>
<p><em>Context rot</em> is a term introduces in <span class="citation">(<a href="#ref-kellyhongContextRotHow2025">Kelly Hong &amp; Anton Troynikov, 2025</a>)</span> technical report. The investigated an advanced <em>Needle in the Haystack</em> problem, including distractors and requiring the <a href="glossary.html#acronyms_LLM">LLM</a>s to find semantic similarity instead of exact term matching. They find that the accuracy often starts to decrease with 10 k input tokens and more.</p>
<p>Meta claims that Llama 4 Maverick has a context length 1 M (Llama 4 Scout even 10 M), where other models often ar limited to 128 k or 32 k or less. We limited our input token length to 32 k in most cases and reached this limit multiple times. We find it remarkable, that Llama 4 Maverick already shows <em>context rot</em> at inputs of length 10 k - 100 times shorter than their context window.</p>
<p><span class="citation">Levy et al. (<a href="#ref-levySameTaskMore2024">2024</a>)</span> show a notable degradation in LLMsâ reasoning performance at much shorter input lengths than their technical maximum. They also show, that Mistral achieves the highest accuracy, when the relevant information is at the end of the prompt. We are not sure, how to relate these findings, since we do not include irrelevant information.</p>
<div id="page-identification-7" class="section level4 hasAnchor" number="6.2.4.1">
<h4><span class="header-section-number">6.2.4.1</span> Page identification<a href="discussion.html#page-identification-7" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Figure <a href="discussion.html#fig:bar-plot-maverick-binary">6.2</a> shows the amount of correct (matching) and incorrect classifications by Llama 4 Maverick for the binary classification tasks ordered by target type and method. One can see, that the <em>n_rag_example</em> strategy starts predicting the target class too often with increased number of examples. This behavior is not observed for the <em>n_random_examples</em> strategy.</p>
<details class=chunk-details><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="discussion.html#cb21-1" tabindex="-1"></a>df_rot_binary <span class="ot">&lt;-</span> df_binary <span class="sc">%&gt;%</span> </span>
<span id="cb21-2"><a href="discussion.html#cb21-2" tabindex="-1"></a>  <span class="fu">filter</span>(</span>
<span id="cb21-3"><a href="discussion.html#cb21-3" tabindex="-1"></a>    <span class="fu">str_detect</span>(model, <span class="st">&quot;Mav&quot;</span>), </span>
<span id="cb21-4"><a href="discussion.html#cb21-4" tabindex="-1"></a>    method_family <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;n_rag_examples&quot;</span>, <span class="st">&quot;n_random_examples&quot;</span>)</span>
<span id="cb21-5"><a href="discussion.html#cb21-5" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb21-6"><a href="discussion.html#cb21-6" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>filepath) <span class="sc">%&gt;%</span> </span>
<span id="cb21-7"><a href="discussion.html#cb21-7" tabindex="-1"></a>  <span class="fu">unnest</span>(predictions)</span>
<span id="cb21-8"><a href="discussion.html#cb21-8" tabindex="-1"></a></span>
<span id="cb21-9"><a href="discussion.html#cb21-9" tabindex="-1"></a>df_rot_binary <span class="sc">%&gt;%</span> </span>
<span id="cb21-10"><a href="discussion.html#cb21-10" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb21-11"><a href="discussion.html#cb21-11" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">if_else</span>(predicted_type <span class="sc">==</span> <span class="st">&quot;no&quot;</span>, <span class="st">&quot;other&quot;</span>, <span class="st">&quot;target&quot;</span>), <span class="at">fill =</span> match)) <span class="sc">+</span></span>
<span id="cb21-12"><a href="discussion.html#cb21-12" tabindex="-1"></a>  <span class="fu">facet_nested</span>(classification_type<span class="sc">~</span>method_family<span class="sc">+</span>n_examples) <span class="sc">+</span></span>
<span id="cb21-13"><a href="discussion.html#cb21-13" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;predicted type&quot;</span>)</span></code></pre></div>
</details>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bar-plot-maverick-binary"></span>
<img src="_main_files/figure-html/bar-plot-maverick-binary-1.png" alt="Comparing the amount of correct classifications by Llama 4 Maverick for the binary classification tasks ordered by target type and method. With increased number of examples the n-rag-example strategy starts predicting the target class too often." width="100%" />
<p class="caption">
Figure 6.2: Comparing the amount of correct classifications by Llama 4 Maverick for the binary classification tasks ordered by target type and method. With increased number of examples the n-rag-example strategy starts predicting the target class too often.
</p>
</div>
<p>Figure <a href="discussion.html#fig:confusion-matrix-maverick-multi-class">6.3</a> is showing the confusion matrices for the multi-class classification with Llama 4 Maverick grouped by <em>method_family</em> and <em>n_examples</em>. Teal bordered tiles are correct predictions and red bordered tiles represent wrong predictions. The number is showing the percentage of classifications by the <a href="glossary.html#acronyms_LLM">LLM</a> of a certain type (<em>predicted_type</em>) based on the true count of observations with that type (<em>type</em>). They sum up to one column-wise.</p>
<p>We can see, that the <em>n_rag_example</em> strategy starts to predict <strong>GuV</strong> too often, when presented with two or more examples. We observe the same for the <em>n_random_examples</em> strategy starting from three provided examples. The <a href="glossary.html#acronyms_LLM">LLM</a> is not just over-predicting <strong>GuV</strong>, but also other target classes. The over-prediction rate for <em>other</em> is lowest. Those pages often have no page filling table and thus are more different from the target classes and easier to distinguish (for a human).</p>
<details class=chunk-details><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="discussion.html#cb22-1" tabindex="-1"></a>df_rot_multi <span class="ot">&lt;-</span> df_multi <span class="sc">%&gt;%</span> </span>
<span id="cb22-2"><a href="discussion.html#cb22-2" tabindex="-1"></a>  <span class="fu">filter</span>(</span>
<span id="cb22-3"><a href="discussion.html#cb22-3" tabindex="-1"></a>    <span class="fu">str_detect</span>(model, <span class="st">&quot;Mav&quot;</span>), </span>
<span id="cb22-4"><a href="discussion.html#cb22-4" tabindex="-1"></a>    method_family <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;n_rag_examples&quot;</span>, <span class="st">&quot;n_random_examples&quot;</span>)</span>
<span id="cb22-5"><a href="discussion.html#cb22-5" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb22-6"><a href="discussion.html#cb22-6" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>filepath) <span class="sc">%&gt;%</span> </span>
<span id="cb22-7"><a href="discussion.html#cb22-7" tabindex="-1"></a>  <span class="fu">unnest</span>(predictions)</span>
<span id="cb22-8"><a href="discussion.html#cb22-8" tabindex="-1"></a></span>
<span id="cb22-9"><a href="discussion.html#cb22-9" tabindex="-1"></a>df_rot_multi <span class="sc">%&gt;%</span> </span>
<span id="cb22-10"><a href="discussion.html#cb22-10" tabindex="-1"></a>  <span class="fu">group_by</span>(type, method_family, n_examples) <span class="sc">%&gt;%</span></span>
<span id="cb22-11"><a href="discussion.html#cb22-11" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb22-12"><a href="discussion.html#cb22-12" tabindex="-1"></a>    <span class="at">count_total =</span> <span class="fu">n</span>()</span>
<span id="cb22-13"><a href="discussion.html#cb22-13" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb22-14"><a href="discussion.html#cb22-14" tabindex="-1"></a>  <span class="fu">group_by</span>(type, predicted_type, method_family, n_examples) <span class="sc">%&gt;%</span> </span>
<span id="cb22-15"><a href="discussion.html#cb22-15" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb22-16"><a href="discussion.html#cb22-16" tabindex="-1"></a>    <span class="at">count =</span> <span class="fu">n</span>(),</span>
<span id="cb22-17"><a href="discussion.html#cb22-17" tabindex="-1"></a>    <span class="at">percentage_correct =</span> count<span class="sc">/</span>count_total</span>
<span id="cb22-18"><a href="discussion.html#cb22-18" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb22-19"><a href="discussion.html#cb22-19" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb22-20"><a href="discussion.html#cb22-20" tabindex="-1"></a>  <span class="fu">geom_tile</span>(</span>
<span id="cb22-21"><a href="discussion.html#cb22-21" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">x =</span> type, <span class="at">y =</span> predicted_type, <span class="at">fill =</span> percentage_correct, <span class="at">color =</span> match),</span>
<span id="cb22-22"><a href="discussion.html#cb22-22" tabindex="-1"></a>    <span class="at">size =</span> <span class="dv">1</span>, <span class="at">height =</span> <span class="fl">0.81</span>, <span class="at">width =</span> <span class="fl">0.9</span></span>
<span id="cb22-23"><a href="discussion.html#cb22-23" tabindex="-1"></a>    ) <span class="sc">+</span> </span>
<span id="cb22-24"><a href="discussion.html#cb22-24" tabindex="-1"></a>  <span class="fu">facet_nested</span>(method_family<span class="sc">~</span>n_examples) <span class="sc">+</span></span>
<span id="cb22-25"><a href="discussion.html#cb22-25" tabindex="-1"></a>  <span class="fu">scale_x_discrete</span>(<span class="at">guide =</span> <span class="fu">guide_axis</span>(<span class="at">angle =</span> <span class="dv">30</span>)) <span class="sc">+</span></span>
<span id="cb22-26"><a href="discussion.html#cb22-26" tabindex="-1"></a>  <span class="fu">geom_text</span>(</span>
<span id="cb22-27"><a href="discussion.html#cb22-27" tabindex="-1"></a>    <span class="at">data =</span> . <span class="sc">%&gt;%</span> <span class="fu">select</span>(type, method_family, n_examples, percentage_correct) <span class="sc">%&gt;%</span> <span class="fu">unique</span>(),</span>
<span id="cb22-28"><a href="discussion.html#cb22-28" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">label =</span> <span class="fu">round</span>(percentage_correct, <span class="dv">2</span>), <span class="at">y =</span> predicted_type, <span class="at">x =</span> type), <span class="at">color =</span> <span class="st">&quot;white&quot;</span></span>
<span id="cb22-29"><a href="discussion.html#cb22-29" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb22-30"><a href="discussion.html#cb22-30" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb22-31"><a href="discussion.html#cb22-31" tabindex="-1"></a>    <span class="at">legend.position =</span> <span class="st">&quot;bottom&quot;</span></span>
<span id="cb22-32"><a href="discussion.html#cb22-32" tabindex="-1"></a>  )</span></code></pre></div>
</details>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:confusion-matrix-maverick-multi-class"></span>
<img src="_main_files/figure-html/confusion-matrix-maverick-multi-class-1.png" alt="Showing the confusion matrices for the multi-class classification with Llama 4 Maverick grouped by method-family and n-examples." width="100%" />
<p class="caption">
Figure 6.3: Showing the confusion matrices for the multi-class classification with Llama 4 Maverick grouped by method-family and n-examples.
</p>
</div>
<p>A possible explanation fro over-predicting <strong>GuV</strong> most might be, that the examples for <strong>GuV</strong> are presented first, because we just iterate over the <em>phrase_dict</em> dictionary (see code below). <span class="citation">Liu et al. (<a href="#ref-liuLostMiddleHow2023">2023</a>)</span> describe a behavior of <a href="glossary.html#acronyms_LLM">LLM</a>s, that they are better with identifying relevant information, when it is placed in the beginning or end of the context. Since all examples are provided in the same manner, examples for classes other than the target class, could be interpreted as distractors with a high similarity. <span class="citation">Kelly Hong &amp; Anton Troynikov (<a href="#ref-kellyhongContextRotHow2025">2025</a>)</span> shows, that in the presence of similar <a href="glossary.html#acronyms_LLM">LLM</a>sâ performance can degrade quickly. They do not present results, if the position of the picked distractor is important. Thus, we formulate the hypotheses for future investigation:</p>
<ol style="list-style-type: decimal">
<li><p><a href="glossary.html#acronyms_LLM">LLM</a>s tend to choose distractors at the beginning or end of the prompt.</p></li>
<li><p><a href="glossary.html#acronyms_LLM">LLM</a>s tend to choose distractors that apprear first or last.</p></li>
<li><p>There is an interaction effect, with the position, where the task itself is specified.</p></li>
</ol>
<details class=chunk-details><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="discussion.html#cb23-1" tabindex="-1"></a>phrase_dict <span class="op">=</span> {</span>
<span id="cb23-2"><a href="discussion.html#cb23-2" tabindex="-1"></a>  <span class="st">&quot;GuV&quot;</span>: <span class="st">&quot;a &#39;Gewinn- und Verlustrechnung&#39; (profit and loss statement) table&quot;</span>,</span>
<span id="cb23-3"><a href="discussion.html#cb23-3" tabindex="-1"></a>  <span class="st">&quot;Aktiva&quot;</span>: <span class="st">&quot;a &#39;Aktiva&#39; (assets) table&quot;</span>,</span>
<span id="cb23-4"><a href="discussion.html#cb23-4" tabindex="-1"></a>  <span class="st">&quot;Passiva&quot;</span>: <span class="st">&quot;a &#39;Passiva&#39; (liabilities) table&quot;</span>,</span>
<span id="cb23-5"><a href="discussion.html#cb23-5" tabindex="-1"></a>  <span class="st">&#39;other&#39;</span>: <span class="st">&quot;a text that does not suit the categories of interest&quot;</span>,</span>
<span id="cb23-6"><a href="discussion.html#cb23-6" tabindex="-1"></a>}</span></code></pre></div>
</details>
</div>
<div id="information-extraction-6" class="section level4 hasAnchor" number="6.2.4.2">
<h4><span class="header-section-number">6.2.4.2</span> Information extraction<a href="discussion.html#information-extraction-6" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Figure <a href="discussion.html#fig:confusion-matrix-maverick-extraction">6.4</a> shows the confusion matrix for the information extraction task with Llama 4 Maverick and five examples. It shows, that the <a href="glossary.html#acronyms_LLM">LLM</a> starts to predict numeric values for every row instead of prediction <em>null</em> if a row is missing. Figure <a href="discussion.html#fig:numeric-predictions-maverick-extraction">6.5</a> shows, what kind of numeric values are predicted. We find two peaks for predicting floating point numbers close to zero or close to 30, while the true values (and values from the examples provided) are in a range of 1_000 and 10_000_000. Thus, we assume the values are hallucinated and not wrongly picked from the examples provided.</p>
<p>Local and global context window / attention <span class="citation">(<a href="#ref-khowajaAnalysisLlama4s2025">Khowaja, 2025</a>)</span>. Trained on 256 k tokens with FP8 precision.</p>
<details class=chunk-details><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="discussion.html#cb24-1" tabindex="-1"></a>df_rot <span class="ot">&lt;-</span> df_real_table_extraction <span class="sc">%&gt;%</span> </span>
<span id="cb24-2"><a href="discussion.html#cb24-2" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">str_detect</span>(model, <span class="st">&quot;Mav&quot;</span>), n_examples <span class="sc">==</span> <span class="dv">5</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb24-3"><a href="discussion.html#cb24-3" tabindex="-1"></a>  <span class="fu">unnest</span>(predictions)</span>
<span id="cb24-4"><a href="discussion.html#cb24-4" tabindex="-1"></a></span>
<span id="cb24-5"><a href="discussion.html#cb24-5" tabindex="-1"></a>df_rot <span class="sc">%&gt;%</span> </span>
<span id="cb24-6"><a href="discussion.html#cb24-6" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(NA_true_positive<span class="sc">:</span>NA_true_negative) <span class="sc">%&gt;%</span> </span>
<span id="cb24-7"><a href="discussion.html#cb24-7" tabindex="-1"></a>  <span class="fu">group_by</span>(name) <span class="sc">%&gt;%</span> </span>
<span id="cb24-8"><a href="discussion.html#cb24-8" tabindex="-1"></a>  <span class="fu">reframe</span>(</span>
<span id="cb24-9"><a href="discussion.html#cb24-9" tabindex="-1"></a>    <span class="at">mean =</span> <span class="fu">mean</span>(value),</span>
<span id="cb24-10"><a href="discussion.html#cb24-10" tabindex="-1"></a>    <span class="at">median =</span> <span class="fu">median</span>(value)</span>
<span id="cb24-11"><a href="discussion.html#cb24-11" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb24-12"><a href="discussion.html#cb24-12" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb24-13"><a href="discussion.html#cb24-13" tabindex="-1"></a>    <span class="at">predicted =</span> <span class="sc">!</span><span class="fu">str_detect</span>(name, <span class="st">&quot;negative&quot;</span>),</span>
<span id="cb24-14"><a href="discussion.html#cb24-14" tabindex="-1"></a>    <span class="at">truth =</span> <span class="sc">!</span>(name <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;NA_true_negative&quot;</span>, <span class="st">&quot;NA_false_positive&quot;</span>)),</span>
<span id="cb24-15"><a href="discussion.html#cb24-15" tabindex="-1"></a>    <span class="at">upper_bond =</span> <span class="fu">ordered</span>(<span class="fu">ceiling</span>(mean)),</span>
<span id="cb24-16"><a href="discussion.html#cb24-16" tabindex="-1"></a>    <span class="at">median =</span> <span class="fu">ordered</span>(median)</span>
<span id="cb24-17"><a href="discussion.html#cb24-17" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb24-18"><a href="discussion.html#cb24-18" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb24-19"><a href="discussion.html#cb24-19" tabindex="-1"></a>  <span class="fu">geom_tile</span>(</span>
<span id="cb24-20"><a href="discussion.html#cb24-20" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">y =</span> truth, <span class="at">x =</span> predicted, <span class="at">fill =</span> mean, <span class="at">color =</span> median),</span>
<span id="cb24-21"><a href="discussion.html#cb24-21" tabindex="-1"></a>    <span class="at">size=</span><span class="dv">2</span>, <span class="at">height =</span> <span class="fl">0.98</span>, <span class="at">width =</span> <span class="fl">0.98</span></span>
<span id="cb24-22"><a href="discussion.html#cb24-22" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb24-23"><a href="discussion.html#cb24-23" tabindex="-1"></a>  <span class="fu">geom_text</span>(</span>
<span id="cb24-24"><a href="discussion.html#cb24-24" tabindex="-1"></a>    <span class="at">data =</span> . <span class="sc">%&gt;%</span> <span class="fu">select</span>(name, truth, predicted) <span class="sc">%&gt;%</span> <span class="fu">unique</span>(),</span>
<span id="cb24-25"><a href="discussion.html#cb24-25" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">label =</span> name, <span class="at">y =</span> truth, <span class="at">x =</span> predicted), <span class="at">color =</span> <span class="st">&quot;white&quot;</span></span>
<span id="cb24-26"><a href="discussion.html#cb24-26" tabindex="-1"></a>  )</span></code></pre></div>
</details>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:confusion-matrix-maverick-extraction"></span>
<img src="_main_files/figure-html/confusion-matrix-maverick-extraction-1.png" alt="Showing the confusion matrix for the information extraction task with Llama 4 Maverick and five in-context learning examples." width="80%" />
<p class="caption">
Figure 6.4: Showing the confusion matrix for the information extraction task with Llama 4 Maverick and five in-context learning examples.
</p>
</div>
<details class=chunk-details><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="discussion.html#cb25-1" tabindex="-1"></a>ticks <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">2</span>,<span class="dv">8</span>,<span class="dv">2</span>)</span>
<span id="cb25-2"><a href="discussion.html#cb25-2" tabindex="-1"></a>ooms <span class="ot">&lt;-</span> <span class="dv">10</span><span class="sc">^</span><span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb25-3"><a href="discussion.html#cb25-3" tabindex="-1"></a>minor_breaks <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(ticks <span class="sc">%o%</span> ooms)</span>
<span id="cb25-4"><a href="discussion.html#cb25-4" tabindex="-1"></a></span>
<span id="cb25-5"><a href="discussion.html#cb25-5" tabindex="-1"></a>ticks <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb25-6"><a href="discussion.html#cb25-6" tabindex="-1"></a>ooms <span class="ot">&lt;-</span> <span class="dv">10</span><span class="sc">^</span><span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb25-7"><a href="discussion.html#cb25-7" tabindex="-1"></a>breaks <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(ticks <span class="sc">%o%</span> ooms)</span>
<span id="cb25-8"><a href="discussion.html#cb25-8" tabindex="-1"></a></span>
<span id="cb25-9"><a href="discussion.html#cb25-9" tabindex="-1"></a>df_rot <span class="sc">%&gt;%</span> </span>
<span id="cb25-10"><a href="discussion.html#cb25-10" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(year_truth<span class="sc">:</span>previous_year_result) <span class="sc">%&gt;%</span> </span>
<span id="cb25-11"><a href="discussion.html#cb25-11" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb25-12"><a href="discussion.html#cb25-12" tabindex="-1"></a>    <span class="at">year =</span> <span class="fu">str_extract</span>(name, <span class="st">&quot;.*year&quot;</span>),</span>
<span id="cb25-13"><a href="discussion.html#cb25-13" tabindex="-1"></a>    <span class="at">type =</span> <span class="fu">str_extract</span>(name, <span class="st">&quot;truth|result&quot;</span>),</span>
<span id="cb25-14"><a href="discussion.html#cb25-14" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb25-15"><a href="discussion.html#cb25-15" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb25-16"><a href="discussion.html#cb25-16" tabindex="-1"></a>  <span class="co"># geom_violin(aes(x = name, y = log(value, 10))) +</span></span>
<span id="cb25-17"><a href="discussion.html#cb25-17" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">30</span>, <span class="at">linetype =</span> <span class="st">&quot;dotted&quot;</span>) <span class="sc">+</span></span>
<span id="cb25-18"><a href="discussion.html#cb25-18" tabindex="-1"></a>  <span class="fu">geom_violin</span>(<span class="fu">aes</span>(<span class="at">x =</span> type, <span class="at">y =</span> value, <span class="at">fill =</span> type)) <span class="sc">+</span></span>
<span id="cb25-19"><a href="discussion.html#cb25-19" tabindex="-1"></a>  <span class="co"># coord_cartesian(ylim = c(0, 10)) +</span></span>
<span id="cb25-20"><a href="discussion.html#cb25-20" tabindex="-1"></a>  <span class="fu">scale_fill_discrete</span>(<span class="at">guide=</span><span class="st">&quot;none&quot;</span>) <span class="sc">+</span></span>
<span id="cb25-21"><a href="discussion.html#cb25-21" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;EUR&quot;</span>) <span class="sc">+</span></span>
<span id="cb25-22"><a href="discussion.html#cb25-22" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;value status&quot;</span>) <span class="sc">+</span></span>
<span id="cb25-23"><a href="discussion.html#cb25-23" tabindex="-1"></a>  <span class="fu">facet_nested</span>(<span class="sc">~</span>year) <span class="sc">+</span></span>
<span id="cb25-24"><a href="discussion.html#cb25-24" tabindex="-1"></a>  <span class="fu">scale_y_log10</span>(<span class="at">breaks =</span> breaks, <span class="at">minor_breaks=</span>minor_breaks)</span></code></pre></div>
</details>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:numeric-predictions-maverick-extraction"></span>
<img src="_main_files/figure-html/numeric-predictions-maverick-extraction-1.png" alt="Comparing the predicted numeric values with the true value distribution for the information extraction task with Llama 4 Maverick and five in-context learning examples. The dotted line is marking the value 30 EUR." width="80%" />
<p class="caption">
Figure 6.5: Comparing the predicted numeric values with the true value distribution for the information extraction task with Llama 4 Maverick and five in-context learning examples. The dotted line is marking the value 30 EUR.
</p>
</div>
</div>
</div>
</div>
<div id="general-performance" class="section level2 hasAnchor" number="6.3">
<h2><span class="header-section-number">6.3</span> Practical Implications and Limitations<a href="discussion.html#general-performance" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This section discusses the results from an engineers perspective, focusing on implications for the planned <a href="glossary.html#acronyms_HITL">HITL</a> application and possible improvements.</p>
<div id="page-identification-8" class="section level3 hasAnchor" number="6.3.1">
<h3><span class="header-section-number">6.3.1</span> Page identification<a href="discussion.html#page-identification-8" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A detailed view on the results shows, a combination of two <a href="glossary.html#acronyms_LLM">LLM</a>s would be necessary, to get the best results for each target class. A more general approach would be using Llama 4 Scout for multi-class classification for all target classes. If there is little VRAM Ministral-8B also does a decent job in multi-class classification.</p>
<p>We recommend, to refine the page range, using a term frequency based approach, for efficiency reasons discussed in Section <a href="discussion.html#efficency-discussion">6.3.1.5</a>. It is an important prerequisite, that any method used for page refinement has a recall of 1.0. Otherwise, a user potentially has to inspect the whole document and no improvement is reached compared to the manual processing.</p>
<p>Afterwards the <a href="glossary.html#acronyms_LLM">LLM</a> can be used to perform a multi-class classification on the top k pages from the ranking resulting from the term frequency approach. The page, that gets the highest confidence score from the <a href="glossary.html#acronyms_LLM">LLM</a> should be used for the information extraction task. The confidence score ranking should be kept for presenting alternative pages, if the chosen one is incorrect.</p>
<p>Figure <a href="discussion.html#fig:hitl-error-handling">6.6</a> visualizes our recommendation, to not include an obligatory step, to confirm the selected page by a human user, but start the information extraction right away. When the user is checking the results, a wrong page will be noticed immediately. Alternative pages can be inspected manually, following the order in the confidence score ranking.</p>
<p>Already classified pages should be stored in a vector database together with their class label. Thus, they can be used for future classification tasks and improve the systemâs performance. The examples for the in-context learning few-shot strategy should be chosen based on the vector similarity and include documents from the same company. We recommend to fill the vector database document by document in the beginning, before starting with batch wise processing.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:hitl-error-handling"></span>
<img src="images/HITL_flowchart_error_handling.png" alt="Showing the information extraction process in a HITL application. We propose to include user action only after the information extraction. If a wrong page is selected, this can be fixed and extraction runs again. Wrong extracted values and handling unknown row identifiers should be done in one place." width="100%" />
<p class="caption">
Figure 6.6: Showing the information extraction process in a HITL application. We propose to include user action only after the information extraction. If a wrong page is selected, this can be fixed and extraction runs again. Wrong extracted values and handling unknown row identifiers should be done in one place.
</p>
</div>
<div id="transfering-the-system-to-new-problems" class="section level4 hasAnchor" number="6.3.1.1">
<h4><span class="header-section-number">6.3.1.1</span> Transfering the system to new problems<a href="discussion.html#transfering-the-system-to-new-problems" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Introducing new areas of application should be easily possible and manageable even from a regular user. For the term frequency approach we can set up a pipeline, where the user has to enter a list of keywords and then gets presented a page ranking, based on <a href="glossary.html#acronyms_TF-IDF">TF-IDF</a> values. The user might adjust the key word list or select correct pages right away, to build a ground truth. If there are more measures of interest (e.g.Â a float frequency as well) the system can automatically train a random forest classifier as well.</p>
<p>Another approach is, that the user provides documents and a list on which page the information of interest is located. This can be the base for a retrieval augmented few-shot classifier, that will improve in the process of classifying more pages.</p>
</div>
<div id="limitations-of-transfer" class="section level4 hasAnchor" number="6.3.1.2">
<h4><span class="header-section-number">6.3.1.2</span> Limitations of transfer<a href="discussion.html#limitations-of-transfer" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The term frequency and <a href="glossary.html#acronyms_LLM">LLM</a> classification might perform worse, if the information of interest, is just making up a small part of the pages content. If the information is placed in a table, we can use a visual table detection model, to identify all tables. We show in the Appendix <a href="appendix-e---miscellaneous.html#yolo">12.3.2.2</a>, that this is a promising approach. Then we can use the retrieval augmented few-shot approach to identify, which table is the correct one.</p>
<p>If the information is not even in a table, but part of a regular sentence, it might get difficult to find the correct page with this approach. Maybe the <a href="glossary.html#acronyms_TOC">TOC</a> approach could be used for page range refinement in this case, if the information is found in a section with known heading.</p>
</div>
<div id="toc-discussion" class="section level4 hasAnchor" number="6.3.1.3">
<h4><span class="header-section-number">6.3.1.3</span> Possible improvement<a href="discussion.html#toc-discussion" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="tf-practical-recommendation" class="section level5 hasAnchor paragraph-start" number="6.3.1.3.1">
<h5><span class="header-section-number">6.3.1.3.1</span> Term frequency approach<a href="discussion.html#tf-practical-recommendation" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Based on the error analysis for the term frequency approach in Section <a href="discussion.html#error-analysis-tf">6.2.1.2</a>, we recommend, instead of using the normalized sum of term frequencies, sum of boolean indicators or the sum of <a href="glossary.html#acronyms_BM25">BM25</a> scores one could also use each single indicator as a feature for random forest. But for this case it would be necessary, to provide a larger train and test dataset to prevent overfitting, because the number of features would be large.</p>
</div>
<div id="table-of-contents-understanding-approach" class="section level5 hasAnchor paragraph-start" number="6.3.1.3.2">
<h5><span class="header-section-number">6.3.1.3.2</span> Table of contents understanding approach<a href="discussion.html#table-of-contents-understanding-approach" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p><span class="citation">H. Li, Gao, et al. (<a href="#ref-liExtractingFinancialData2023">2023</a>)</span> use a few-shot learning strategy with the <a href="glossary.html#acronyms_TOC">TOC</a> approach. We implemented only a zero-shot strategy. With more expertise and concrete examples in the prompt, this approach probably could perform better as reported here. Also they used OpenAIâs GPT-4 for the <a href="glossary.html#acronyms_TOC">TOC</a> understanding task, which has much more parameters than Ministral-8B. One could investigate, if Qwen3-235B would perform much better with the text based <a href="glossary.html#acronyms_TOC">TOC</a>.</p>
</div>
</div>
<div id="conclusion-4" class="section level4 hasAnchor" number="6.3.1.4">
<h4><span class="header-section-number">6.3.1.4</span> Conclusion<a href="discussion.html#conclusion-4" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>gleiches Level?</p>
</div>
<div id="efficency-discussion" class="section level4 hasAnchor" number="6.3.1.5">
<h4><span class="header-section-number">6.3.1.5</span> Energy usage and runtime<a href="discussion.html#efficency-discussion" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The fastest and least energy consuming strategy, using only <a href="glossary.html#acronyms_LLM">LLM</a>s, is to use a small model as Ministral-8B-Instruct for the multi-class approach. This is more effective than running three binary classifications.</p>
<p>An alternative approach could be to binary predict if the page is of any target type and then perform a classification, which type exactly the page is of. But this would probably consume as much energy as the multi-class approach, because we have to provide a balanced amount of examples for each class. The results of the multi-class strategy are good enough to run it right away.</p>
<p>In both strategies the k required for perfect recall is three, using the Ministral-8B-Instruct model<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>.</p>
<p>Nevertheless, it is more promising, to reduce the number of pages, to classify with the <a href="glossary.html#acronyms_LLM">LLM</a> in the first place. This can be achieved, by running the term-frequency approach first to refine the page range, and then use the <a href="glossary.html#acronyms_LLM">LLM</a> approach.</p>
<div id="compare-with-manual-page-identification" class="section level5 hasAnchor paragraph-start" number="6.3.1.5.1">
<h5><span class="header-section-number">6.3.1.5.1</span> Compare with manual page identification<a href="discussion.html#compare-with-manual-page-identification" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The manual approach is the slowest. We identified the pages of interest for all target classes in ten random documents for the benchmark. We used the <a href="glossary.html#acronyms_TOC">TOC</a> and the search function to find key words like <strong>Aktiva</strong> or <strong>Bilanz</strong>. Anyhow, it is almost as fast as the full multi-classification using Llama 4 Scout, while consuming eight times less energy. Comparing it to Ministral-8B-Instruct it takes three times longer but consumes less then half of the energy.</p>
</div>
<p>Thus, the only arguments for a <a href="glossary.html#acronyms_LLM">LLM</a> classification without previous page refinement are, that the human user could perform another task, while the <a href="glossary.html#acronyms_LLM">LLM</a> is classifying a whole batch of documents and that it frees the user from a boring task. With a view on the energy usage driven climate change process we would discard both arguments.</p>
<p>Not taken into account fo this comparison are factors as:</p>
<ul>
<li><p>costs to buy and maintain hardware (i.e.Â a GPU cluster).</p></li>
<li><p>higher costs per runtime if the <a href="glossary.html#acronyms_LLM">LLM</a> compute is purchased from cloud providers. The number of response tokens per page can be limited to one. In contrast here are the counts of input tokens needed to classify a single page:</p>
<ul>
<li><p>four classes (3 random examples): 11 k input tokens</p></li>
<li><p>binary (3 random examples): 6.5 k input tokens</p></li>
</ul></li>
<li><p>payment and insurance to pay for a human (e.g.Â student coworker).</p></li>
<li><p>the training time and energy consumption for training either</p>
<ul>
<li><p>a <a href="glossary.html#acronyms_LLM">LLM</a> (probably done by the <a href="glossary.html#acronyms_LLM">LLM</a> provider).</p></li>
<li><p>a human (growing up, getting educated).</p></li>
</ul></li>
<li><p>the energy consumed to produce the hardware.</p></li>
</ul>
<p>Nevertheless, the argument that probably will be most important to many CEOs are costs. The costs presented in table <a href="results.html#tab:page-identification-efficiency-overview-all">5.3</a> only include the costs for energy.</p>
<p>For a human employee we have to add their payment and insurance costs. Even for a student worker this will sum up to 0.5 CENTS per second. This totals in 319.80 â¬ for identifying the target pages for 1_000 documents. If we assume, one uses GPT-4.1-mini hosted in the Azure cloud instead of running the \ac rt{LLM} locally, we estimate a price of 118.80 â¬.</p>
</div>
</div>
<div id="alternative-input-formats-extraction" class="section level3 hasAnchor" number="6.3.2">
<h3><span class="header-section-number">6.3.2</span> Information extraction<a href="discussion.html#alternative-input-formats-extraction" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We have not investigated yet, if the 2 % wrong extracted numeric values are caused by not respecting currency units, or if there is another reason. A potential reason may be numeric values, that get stitched together by faulty text extraction. If this would be the case, the question would arise, if more effort should be invested into more sophisticated table extraction methods. Personally we would recommend investing the energy into establishing end-to-end data pipelines, to ensure that document parsing is unnecessary at all.</p>
<p>Nevetheless, we checked other extraction libraries for the text extraction, too. Our benchmark includes advanced approaches as <em>Azure Document Intelligence</em> and <em>Docling</em>, that can detect and extract tables. We also tried to provide Markdown instead of plain text, generated by <em>Docling</em> and <em>pymupdf</em> to maintain the tabula structure information. We also tested an <a href="glossary.html#acronyms_OCR">OCR</a> approach using <em>tesseract</em>.</p>
<p>Table <a href="discussion.html#tab:input-format-qwen235-evaluation">6.3</a> shows the results aggregated over all documents for the best prompting method for Qwen3-235B for each input type. We can find no improvement over the results we achieve with the text extracted by <em>pdfium</em>. In contrast, we find that the performance with Markdown generated by <em>pymupdf</em> or the text generated using <a href="glossary.html#acronyms_OCR">OCR</a> are worse. But this is not a Markdown specific problem. Qwen3-235B performs equally well with the Markdown generated by <em>Docling</em> as with the plain text extract.</p>
<details class=chunk-details><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="discussion.html#cb26-1" tabindex="-1"></a>df_qwen235 <span class="ot">&lt;-</span>  <span class="fu">readRDS</span>(<span class="st">&quot;data_storage/table_extraction_qwen3_235B_multiple_input_formats&quot;</span>)</span>
<span id="cb26-2"><a href="discussion.html#cb26-2" tabindex="-1"></a></span>
<span id="cb26-3"><a href="discussion.html#cb26-3" tabindex="-1"></a>table_characteristics <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;../benchmark_truth/real_tables_extended/table_characteristics_more_examples.csv&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb26-4"><a href="discussion.html#cb26-4" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb26-5"><a href="discussion.html#cb26-5" tabindex="-1"></a>    <span class="at">filepath =</span> <span class="fu">paste0</span>(<span class="st">&quot;/pvc/benchmark_truth/real_tables_extended/&quot;</span>, company, <span class="st">&quot;__&quot;</span>, filename)</span>
<span id="cb26-6"><a href="discussion.html#cb26-6" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> <span class="fu">as_tibble</span>()</span>
<span id="cb26-7"><a href="discussion.html#cb26-7" tabindex="-1"></a></span>
<span id="cb26-8"><a href="discussion.html#cb26-8" tabindex="-1"></a>df_qwen235 <span class="ot">&lt;-</span> df_qwen235 <span class="sc">%&gt;%</span> <span class="fu">left_join</span>(table_characteristics)</span>
<span id="cb26-9"><a href="discussion.html#cb26-9" tabindex="-1"></a></span>
<span id="cb26-10"><a href="discussion.html#cb26-10" tabindex="-1"></a>df_qwen235 <span class="sc">%&gt;%</span> <span class="fu">group_by</span>(model, method, extractor, input_format) <span class="sc">%&gt;%</span> </span>
<span id="cb26-11"><a href="discussion.html#cb26-11" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_total =</span> <span class="fu">mean</span>(percentage_correct_total)) <span class="sc">%&gt;%</span> </span>
<span id="cb26-12"><a href="discussion.html#cb26-12" tabindex="-1"></a>  <span class="fu">group_by</span>(model, extractor, input_format) <span class="sc">%&gt;%</span> </span>
<span id="cb26-13"><a href="discussion.html#cb26-13" tabindex="-1"></a>  <span class="fu">slice_max</span>(<span class="at">n =</span> <span class="dv">1</span>, mean_total, <span class="at">with_ties =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb26-14"><a href="discussion.html#cb26-14" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">mean_total =</span> <span class="fu">format_floats</span>(mean_total, <span class="dv">3</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb26-15"><a href="discussion.html#cb26-15" tabindex="-1"></a>  <span class="fu">render_table</span>(</span>
<span id="cb26-16"><a href="discussion.html#cb26-16" tabindex="-1"></a>    <span class="at">alignment =</span> <span class="st">&quot;lllrr&quot;</span>,</span>
<span id="cb26-17"><a href="discussion.html#cb26-17" tabindex="-1"></a>    <span class="at">caption =</span> <span class="st">&quot;Comparing the best prompting method for different types of input for the information extraction task with Qwen3-235B.&quot;</span>,</span>
<span id="cb26-18"><a href="discussion.html#cb26-18" tabindex="-1"></a>    <span class="at">ref =</span> opts_current<span class="sc">$</span><span class="fu">get</span>(<span class="st">&quot;label&quot;</span>)</span>
<span id="cb26-19"><a href="discussion.html#cb26-19" tabindex="-1"></a>  )</span></code></pre></div>
</details>
<table>
<caption>
<span id="tab:input-format-qwen235-evaluation">Table 6.3: </span>Comparing the best prompting method for different types of input for the information extraction task with Qwen3-235B.
</caption>
</table>
<div class="datatables html-widget html-fill-item" id="htmlwidget-b9b663779e8d3bb3d7d4" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-b9b663779e8d3bb3d7d4">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6"],["Qwen3-235B-A22B-Instruct-2507-FP8","Qwen3-235B-A22B-Instruct-2507-FP8","Qwen3-235B-A22B-Instruct-2507-FP8","Qwen3-235B-A22B-Instruct-2507-FP8","Qwen3-235B-A22B-Instruct-2507-FP8","Qwen3-235B-A22B-Instruct-2507-FP8"],["top_<wbr>3_<wbr>rag_<wbr>examples","top_<wbr>5_<wbr>rag_<wbr>examples","top_<wbr>5_<wbr>rag_<wbr>examples","5_<wbr>random_<wbr>examples","top_<wbr>5_<wbr>rag_<wbr>examples","top_<wbr>5_<wbr>rag_<wbr>examples"],["docling","docling","pdfium","pymupdf","pymupdf","tesseract"],["markdown","text","text","markdown","text","text"],["0.958","0.967","0.970","0.871","0.970","0.848"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>model<\/th>\n      <th>method<\/th>\n      <th>extractor<\/th>\n      <th>input format<\/th>\n      <th>mean total<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":10,"scrollX":true,"dom":"tiprfl","columnDefs":[{"targets":0,"className":"dt-left"},{"targets":1,"className":"dt-left"},{"targets":2,"className":"dt-left"},{"targets":3,"className":"dt-left"},{"targets":4,"className":"dt-right"},{"targets":5,"className":"dt-right"},{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"model","targets":1},{"name":"method","targets":2},{"name":"extractor","targets":3},{"name":"input format","targets":4},{"name":"mean total","targets":5}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<div id="limitations-1" class="section level5 hasAnchor paragraph-start" number="6.3.2.0.1">
<h5><span class="header-section-number">6.3.2.0.1</span> Limitations<a href="discussion.html#limitations-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The current approach uses a single strict schema. This enables easy evaluation of the results and processing in down stream tasks. But it excluded reports of well known companies as BVG and BSR. For the final system we intend to add an additional classifier between the page identification and information extraction, that detects what granularity the asset table is reported in. Then a proper schema is applied in the information extraction task.</p>
</div>
<p>But this will still not use all information found in all tables. Therefore, we intend to access, which row identifiers did not match and extract the corresponding rows in a separate <a href="glossary.html#acronyms_json">json</a> formatted list. We have to test, if this can be performed in a single step or with another information extraction prompt.</p>
<p>Another approach would be to use guided instead of restricted decoding. For this strategy one can pass the description of the target structure in the prompt and just enforce the generation of valid <a href="glossary.html#acronyms_json">json</a> code. We unwillingly made first tests with this approach, because we were not able to use a strict schema with the models of OpenAI. We describe our findings about this in Section <a href="discussion.html#openai-discussion">6.2.2.6</a>.</p>
<div id="conclusion-5" class="section level5 hasAnchor paragraph-start" number="6.3.2.0.2">
<h5><span class="header-section-number">6.3.2.0.2</span> Conclusion<a href="discussion.html#conclusion-5" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>To summarize, we recommend to invest resources into an end-to-end supply of machine-readable information and good user experience instead of system that achieves perfect extraction results. We believe that the performance as it is is already sufficient. Especially if the document extraction database is build document by document to use a <a href="glossary.html#acronyms_RAG">RAG</a> architecture to take advantage of in-context learning with same-company examples.</p>
</div>
</div>
<div id="error-rate-guidance-2" class="section level3 hasAnchor" number="6.3.3">
<h3><span class="header-section-number">6.3.3</span> Error rate guidance<a href="discussion.html#error-rate-guidance-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A measure to guide a users attention, which predictions to inspect and which to trust as they are would be important for the information extraction task. Checking the extracted values for a single table takes up to three minutes. This totals in 300 minutes prediction checking for our sample. This is up to four times faster, than manually cpoy over all the values.</p>
<p>Selecting a smaller model that is finishing after 2:30 minutes instead of 3:00 minutes is not speeding up the process a lot, as long as the error checking has to be performed on all values afterwards. This would be the case, if we get perfect results in the first place, or if a criteria is found, the predictions can be grouped by forming bins with near zero error rate.</p>
<p>An interesting criteria for this goal could be the company which creates a document. We show in <a href="discussion.html#same-company-evaluation">6.2.2.2</a> that the information extraction already yields error free results for many companies. If the characteristics of the table of interest do not change, we can expect to find the same empirical error rate for future documents, too. But we already identified some companies in our sample, where the structure changed in important details, e.g.Â starting to report values in <em>Tâ¬</em>.</p>
<p>Furthermore, we recommend to choose a threshold value close to zero instead of exact zero, to define groups of predictions with a sufficient low empirical error rate. Otherwise those groups are too unstable.</p>
<p>One could also test to use more sophisticated confidence measures. But we are not to optimistic to find a much better discriminating criteria this way.</p>
<div id="conclusion-6" class="section level5 hasAnchor paragraph-start" number="6.3.3.0.1">
<h5><span class="header-section-number">6.3.3.0.1</span> Conclusion<a href="discussion.html#conclusion-6" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The discrimination between correct and incorrect classified pages works well. Even though it will be rarely needed there, because of the almost perfect results, it can be used to form a ranking of pages, that can be used to find the most promising alternative, if the classification should be wrong.</p>
</div>
<p>For the information extraction task additional segmentation might help to find a use for the confidence score there as well. But alternative segmentation criteria might remove the need for the confidence scores as additional criteria at all.</p>
</div>
</div>
<div id="not-covered" class="section level2 hasAnchor" number="6.4">
<h2><span class="header-section-number">6.4</span> Not covered<a href="discussion.html#not-covered" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this section we briefly mention the topics we have not investigated in this thesis.</p>
<div id="table-extraction-and-document-parsing" class="section level5 hasAnchor paragraph-start" number="6.4.0.0.1">
<h5><span class="header-section-number">6.4.0.0.1</span> Table extraction and document parsing<a href="discussion.html#table-extraction-and-document-parsing" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>There are classical libraries and recent machine learning models, that are specialised on extracting tables from documents. We tested <em>tabula</em> as a classical solution, but were not satisfied by its results. Without borders in the tables it rarely identified rows and columns correct.</p>
</div>
<p>We did not manage to implement recent models for this task, for example visual <a href="glossary.html#acronyms_LLM">LLM</a>s. There are promising results for their performance on table extraction, but a easy to use version for <em>transformers</em> or <em>vLLM</em> is missing most of the time. We were surprised and glad to see, that our approach works well with the basic text extract and did not continue to pursue the attempt to use more sophisticate extraction tolls or models.</p>
<div id="optical-character-recognition" class="section level5 hasAnchor paragraph-start" number="6.4.0.0.2">
<h5><span class="header-section-number">6.4.0.0.2</span> Optical character recognition<a href="discussion.html#optical-character-recognition" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>If documents have no textual information, because they are just a collection of (scanned) images, <a href="glossary.html#acronyms_OCR">OCR</a> is a necessary step in data preparation, because all our approaches use the text extract. In the <a href="glossary.html#acronyms_OCR">OCR</a> process the textual information of the image is converted into machine-readable text. <a href="glossary.html#acronyms_OCR">OCR</a> systems often perform a document layout analysis too, in order to handle multi-column layouts and tables.</p>
</div>
<div id="fine-tuning" class="section level5 hasAnchor paragraph-start" number="6.4.0.0.3">
<h5><span class="header-section-number">6.4.0.0.3</span> Fine-tuning<a href="discussion.html#fine-tuning" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p><a href="glossary.html#acronyms_LLM">LLM</a>s can be fine tuned on specific tasks. For example, they can be trained to produce text of a specific style or on classification tasks. For classification tasks a softmax pooling layer is added. Another example is the object detection model Yolo 12 we are using. It is fine tuned on detecting tables.</p>
</div>
<p>We do not perform fine tuning with <a href="glossary.html#acronyms_LLM">LLM</a>s. Instead we are using in-context learning and test, if this yields sufficient results. It would be interesting to estimate, how many in-context prompts have to be queried, so that the energy consumption for the additional token processing is becoming greater than the energy consumption of a fine tuning.</p>
<div id="training-an-encoder-only-model" class="section level5 hasAnchor paragraph-start" number="6.4.0.0.4">
<h5><span class="header-section-number">6.4.0.0.4</span> Training an encoder-only model<a href="discussion.html#training-an-encoder-only-model" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Instead of fine tuning a <a href="glossary.html#acronyms_LLM">LLM</a> it probably would be more efficient to train a smaller (encoder-only) model, e.g.Â <a href="glossary.html#acronyms_BERT">BERT (Bidirectional Encoder Representations from Transformers)</a>. Such a model would probably be pretty efficient for the whole classification task as well. But in contrast to an <a href="glossary.html#acronyms_LLM">LLM</a> we would have to retrain the model for every new classification task and build compose a training dataset for this.</p>
</div>
<div id="ux-design-study" class="section level5 hasAnchor paragraph-start" number="6.4.0.0.5">
<h5><span class="header-section-number">6.4.0.0.5</span> UX design study<a href="discussion.html#ux-design-study" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>We have not performed a <a href="glossary.html#acronyms_UX">UX</a> design study so far. This might be performed in near future to create an application, using the information extraction processes investigated in this thesis, that can be used well by the employees of <a href="glossary.html#acronyms_RHvB">RHvB</a>. Participating potential users early in the process, is meaningful for successful software development <span class="citation">(<a href="#ref-UserParticipationSoftware2010"><em>User <span>Participation</span> in <span>Software Development Projects</span> â <span>Communications</span> of the <span>ACM</span></em>, 2010</a>)</span> and can prevent developing unnecessary features or non intuitive, cumbersome processes. At the same time it can increase the willingness and motivation to use the final <a href="glossary.html#acronyms_AI">AI</a> driven product <span class="citation">(<a href="#ref-erridaDeterminantsOrganizationalChange2021">Errida &amp; Lotfi, 2021</a>)</span>.</p>
</div>
<div id="advanced-prompting-techniques" class="section level5 hasAnchor paragraph-start" number="6.4.0.0.6">
<h5><span class="header-section-number">6.4.0.0.6</span> Advanced prompting techniques<a href="discussion.html#advanced-prompting-techniques" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Advanced prompting strategies as Chain-of-Thought, ReAct or Self-Consitency <span class="citation">(<a href="#ref-PromptEngineeringGuide"><em>Prompt <span>Engineering Guide</span></em>, n.d.</a>)</span>, prompting to think step-by-step or put in a lot of effort. But since we already find pretty good performance and also first cases of content rot, we do not recommend to invest more effort in advanced prompt template building.</p>
</div>
</div>
<div id="outlook-implementation" class="section level2 hasAnchor" number="6.5">
<h2><span class="header-section-number">6.5</span> Outlook<a href="discussion.html#outlook-implementation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In order to build the outlined system at <a href="glossary.html#acronyms_RHvB">RHvB</a> we have to overcome some infrastructural hurdles. Since the local infrastructure gets discarded, we need to move into a cloud environment, ensure secure connections with the Berlin intranet and secured processing of confidential data. The short term strategy does not include any <a href="glossary.html#acronyms_GPU">GPU</a> resources yet.</p>
<p>Among the possible improvements of the system we see increasing the flexibility and extending the number of use-cases as most important. This includes, finding a solution, how unknown row identifiers can be handled by the users and setting up an automated process to fill the <a href="glossary.html#acronyms_RAG">RAG</a> component with examples, that can be used for the identification and extraction tasks.</p>
<p>Overall, we still have to build a user interface, that guides the process and allows users to correct correct errors and handle unknown row identifiers. Furthermore, we have to discuss how to proceed with new entries. Should we aggregate them with known row identifiers or extend the list of known entities in the main database? Maybe introducing a new hierarchy level, to handle the finer grained reporting of housing cooperative for some of the enties?</p>
<p>Additionally we want to set up a machine learning operations pipeline that performs health check for our system and can be used for additional benchmarks. Thus we could test new modelsâ performance - and more important - check if the new examples provided by the employees might be harmful for the systems performance.</p>
<p>Additionally, we will request the annual reports in <a href="glossary.html#acronyms_XBRL">XBRL (eXtensible Bbusiness Reporting Language)</a> format. German companies are obligated to create reports in this format since 2012 for reporting to the tax authorities (Â§ 5b EStG). A fact not used at <a href="glossary.html#acronyms_RHvB">RHvB</a> so far. We hope to build an error free solution based on this machine-readable format for this specific task.</p>
</div>
<div id="ethics" class="section level2 hasAnchor" number="6.6">
<h2><span class="header-section-number">6.6</span> Ethical &amp; Practical Considerations<a href="discussion.html#ethics" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="pdf-extraction-limitations" class="section level3 hasAnchor" number="6.6.1">
<h3><span class="header-section-number">6.6.1</span> PDF extraction limitations<a href="discussion.html#pdf-extraction-limitations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Pdfminer informs that the text of some annual reports from <em>IBB</em> and <em>Berlinovo</em> should not be extracted. This information is given in a meta data field of the PDF. We use the text extract from these documents for our study anyway.</p>
<p>Errors catched by <a href="glossary.html#acronyms_HITL">HITL</a> approach before they have down stream implications.</p>
</div>
<div id="computational-constraints" class="section level3 hasAnchor" number="6.6.2">
<h3><span class="header-section-number">6.6.2</span> Computational constraints<a href="discussion.html#computational-constraints" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The extraction with <a href="glossary.html#acronyms_LLM">LLM</a>s is computationally demanding and should be run on <a href="glossary.html#acronyms_GPU">GPU</a>s. To run Qwen3-235B-A32B-Instruct-FP8 - the model that yields the best results for the extraction task - four H200 <a href="glossary.html#acronyms_GPU">GPU</a>s are needed. To run Llama 4 Scout - the model that performed best in the page identification task - another four H200 <a href="glossary.html#acronyms_GPU">GPU</a>s are needed. It make no sense, to load these models ad-hoc, since the setup time is around 30 minutes. For running Ministral-8B and Qwen3-8B a single Nvidia 5090 RTX or A100 are needed.</p>
</div>
<div id="generalizability-scope" class="section level3 hasAnchor" number="6.6.3">
<h3><span class="header-section-number">6.6.3</span> Generalizability scope<a href="discussion.html#generalizability-scope" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The approach tested here is probably using on other companies annual reports as well. To extract information that is only filling a small part of a page the framework may has to be adjusted. The page identification could be trickier with some approaches if only a single key word is searched.</p>
</div>
<div id="ethical-considerations" class="section level3 hasAnchor" number="6.6.4">
<h3><span class="header-section-number">6.6.4</span> Ethical considerations<a href="discussion.html#ethical-considerations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The extraction of numeric information is not the same as making decisions. It probably isnât affected by any bias, that is discriminating humans.</p>
<p>The automatisation of information extraction is potentially replacing low requirements work places. At <a href="glossary.html#acronyms_RHvB">RHvB</a> there are no jobs for such a task anymore. More free time for other tasks. Shifting to more complex tasks.</p>
<p>AI Act does probably not apply, since decisions are not made on individual level?: Are there restrictions on the use of automated decision-making? Yes, <strong>individuals should not be subject to a decision that is based solely on automated processing</strong> (such as algorithms) and that is legally binding or which significantly affects them.</p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-brownLanguageModelsAre2020" class="csl-entry">
Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., â¦ Amodei, D. (2020). <em>Language <span>Models</span> are <span>Few-Shot Learners</span></em> (arXiv:2005.14165). arXiv. <a href="https://doi.org/10.48550/arXiv.2005.14165">https://doi.org/10.48550/arXiv.2005.14165</a>
</div>
<div id="ref-erridaDeterminantsOrganizationalChange2021" class="csl-entry">
Errida, A., &amp; Lotfi, B. (2021). The determinants of organizational change management success: <span>Literature</span> review and case study. <em>International Journal of Engineering Business Management</em>, <em>13</em>, 18479790211016273. <a href="https://doi.org/10.1177/18479790211016273">https://doi.org/10.1177/18479790211016273</a>
</div>
<div id="ref-kellyhongContextRotHow2025" class="csl-entry">
Kelly Hong, &amp; Anton Troynikov. (2025). <em>Context <span>Rot</span>: <span>How Increasing Input Tokens Impacts LLM Performance</span></em>. https://research.trychroma.com/context-rot.
</div>
<div id="ref-khowajaAnalysisLlama4s2025" class="csl-entry">
Khowaja, S. A. (2025). Analysis of <span>Llama</span> 4âs 10 <span>Million Token Context Window Claim</span>. In <em>Medium</em>.
</div>
<div id="ref-kongOpenTabAdvancingLarge2024" class="csl-entry">
Kong, K., Zhang, J., Shen, Z., Srinivasan, B., Lei, C., Faloutsos, C., Rangwala, H., &amp; Karypis, G. (2024). <em><span>OpenTab</span>: <span>Advancing Large Language Models</span> as <span class="nocase">Open-domain Table Reasoners</span></em> (arXiv:2402.14361). arXiv. <a href="https://doi.org/10.48550/arXiv.2402.14361">https://doi.org/10.48550/arXiv.2402.14361</a>
</div>
<div id="ref-levySameTaskMore2024" class="csl-entry">
Levy, M., Jacoby, A., &amp; Goldberg, Y. (2024). <em>Same <span>Task</span>, <span>More Tokens</span>: The <span>Impact</span> of <span>Input Length</span> on the <span>Reasoning Performance</span> of <span>Large Language Models</span></em> (arXiv:2402.14848). arXiv. <a href="https://doi.org/10.48550/arXiv.2402.14848">https://doi.org/10.48550/arXiv.2402.14848</a>
</div>
<div id="ref-liExtractingFinancialData2023" class="csl-entry">
Li, H., Gao, H. (Harry)., Wu, C., &amp; Vasarhelyi, M. A. (2023). <em>Extracting <span>Financial Data</span> from <span>Unstructured Sources</span>: <span>Leveraging Large Language Models</span></em> ({{SSRN Scholarly Paper}} 4567607). Social Science Research Network. <a href="https://doi.org/10.2139/ssrn.4567607">https://doi.org/10.2139/ssrn.4567607</a>
</div>
<div id="ref-liuLostMiddleHow2023" class="csl-entry">
Liu, N. F., Lin, K., Hewitt, J., Paranjape, A., Bevilacqua, M., Petroni, F., &amp; Liang, P. (2023). <em>Lost in the <span>Middle</span>: <span>How Language Models Use Long Contexts</span></em> (arXiv:2307.03172). arXiv. <a href="https://doi.org/10.48550/arXiv.2307.03172">https://doi.org/10.48550/arXiv.2307.03172</a>
</div>
<div id="ref-PromptEngineeringGuide" class="csl-entry">
<em>Prompt <span>Engineering Guide</span></em>. (n.d.). https://www.promptingguide.ai/techniques.
</div>
<div id="ref-qwenteamQwen3ThinkDeeper2025" class="csl-entry">
Qwen Team. (2025). Qwen3: <span>Think Deeper</span>, <span>Act Faster</span>. In <em>Qwen</em>. https://qwenlm.github.io/blog/qwen3/.
</div>
<div id="ref-QwenQwen34BHugging2025" class="csl-entry">
<em>Qwen/<span>Qwen3-4B</span> <span><span class="math inline">\(\cdot\)</span></span> <span>Hugging Face</span></em>. (2025). https://huggingface.co/Qwen/Qwen3-4B.
</div>
<div id="ref-UserParticipationSoftware2010" class="csl-entry">
<em>User <span>Participation</span> in <span>Software Development Projects</span> â <span>Communications</span> of the <span>ACM</span></em>. (2010).
</div>
</div>
<div class="footnotes">
<hr />
<ol start="7">
<li id="fn7"><p>The Qwen3 models support two operating modes: A thining mode and a non-thinking mode. The thinking mode should yield better answers in complex tasks and the additional amount of processing can be controlled by setting a thinking budget <span class="citation">(<a href="#ref-qwenteamQwen3ThinkDeeper2025">Qwen Team, 2025</a>)</span>. This thinking budget can be seen as the amount of tokens used for a step wise solution.<a href="discussion.html#fnref7" class="footnote-back">â©ï¸</a></p></li>
<li id="fn8"><p>Potentially smaller fine tuned models can solve the task even more efficient.<a href="discussion.html#fnref8" class="footnote-back">â©ï¸</a></p></li>
</ol>
</div>
<script>
// Lightbox functionality for displaying images in a modal view
document.addEventListener("DOMContentLoaded", function () {
  // Create a lightbox container
  const lightbox = document.createElement("div");
  lightbox.id = "lightbox";
  lightbox.style.position = "fixed";
  lightbox.style.top = "0";
  lightbox.style.left = "0";
  lightbox.style.width = "100%";
  lightbox.style.height = "100%";
  lightbox.style.backgroundColor = "rgba(0, 0, 0, 0.8)";
  lightbox.style.display = "none";
  lightbox.style.justifyContent = "center";
  lightbox.style.alignItems = "center";
  lightbox.style.zIndex = "1000";
  document.body.appendChild(lightbox);

  // Add an image element to the lightbox
  const lightboxImage = document.createElement("img");
  lightboxImage.id = "lightbox-image";
  // lightboxImage.style.maxWidth = "90%";
  // lightboxImage.style.maxHeight = "90%";
  lightbox.appendChild(lightboxImage);

  // Close lightbox on click
  lightbox.addEventListener("click", function () {
    lightbox.style.display = "none";
  });

  // Add onclick event to all images except the excluded one
  const images = document.querySelectorAll("img");
  images.forEach((img) => {
    if (img.src.includes("images/BHT_Logo_horizontal_Anthrazit_transparent.svg")) {
      return; // Skip the excluded image
    }
    img.style.cursor = "pointer"; // Change cursor to indicate clickability
    img.addEventListener("click", function () {
      lightboxImage.src = img.src; // Set the lightbox image source
      lightbox.style.display = "flex"; // Show the lightbox
    });
  });
});
</script>

<script>
// Image slider/carousel functionality for divs with class "image-slider"
document.addEventListener("DOMContentLoaded", function () {
  document.querySelectorAll('.image-slider').forEach(function (slider) {
    const images = slider.querySelectorAll('img');
    if (images.length < 2) return; // No need for slider if only one image

    // Hide all images except the first
    images.forEach((img, i) => img.style.display = i === 0 ? 'inline' : 'none');
    let current = 0;

    // Create navigation buttons
    const prevBtn = document.createElement('button');
    prevBtn.textContent = 'â¨ Prev';
    prevBtn.style.marginRight = '10px';
    const nextBtn = document.createElement('button');
    nextBtn.textContent = 'Next â©';
    nextBtn.style.marginLeft = '10px';

    // Create a caption container
    const captionContainer = document.createElement('div');
    captionContainer.style.fontStyle = 'italic';
    captionContainer.style.color = '#555';

    // Create a flex container for buttons and caption
    const controlsContainer = document.createElement('div');
    controlsContainer.style.display = 'flex';
    controlsContainer.style.justifyContent = 'space-between';
    controlsContainer.style.alignItems = 'center';
    controlsContainer.style.marginTop = '10px';
    controlsContainer.style.width = '100%';

    // Place buttons and caption in flex container
    controlsContainer.appendChild(prevBtn);
    controlsContainer.appendChild(captionContainer);
    controlsContainer.appendChild(nextBtn);

    // Function to update the caption
    const updateCaption = () => {
      const caption = images[current].nextElementSibling;
      if (caption && caption.classList.contains('image-caption')) {
        captionContainer.textContent = caption.textContent;
      } else {
        captionContainer.textContent = ''; // Clear caption if none exists
      }
    };

    // Function to show the next image
    const showNextImage = () => {
      images[current].style.display = 'none';
      current = (current + 1) % images.length;
      images[current].style.display = 'inline';
      updateCaption();
    };

    // Function to show the previous image
    const showPrevImage = () => {
      images[current].style.display = 'none';
      current = (current - 1 + images.length) % images.length;
      images[current].style.display = 'inline';
      updateCaption();
    };

    // Button click handlers
    prevBtn.onclick = function () {
      stopAutoSlide();
      showPrevImage();
    };
    nextBtn.onclick = function () {
      stopAutoSlide();
      showNextImage();
    };

    // Insert controls container below images
    slider.appendChild(controlsContainer);

    // Automatic sliding
    let autoSlideInterval = setInterval(showNextImage, 2000);

    // Stop automatic sliding on user interaction
    const stopAutoSlide = () => {
      clearInterval(autoSlideInterval);
    };

    // Stop auto-slide when the user interacts with the slider
    prevBtn.addEventListener('click', stopAutoSlide);
    nextBtn.addEventListener('click', stopAutoSlide);
    images.forEach((img) => {
      img.addEventListener('click', stopAutoSlide);
    });

    // Initialize the caption
    updateCaption();
  });
});
</script>

<script>
// Dropdown filter functionality for images with lightbox
document.addEventListener("DOMContentLoaded", function () {
  document.querySelectorAll('.image-selector').forEach(function (selector) {
    const images = selector.querySelectorAll('img');
    if (images.length === 0) return;

    // Create a dropdown filter container
    const filterContainer = document.createElement('div');
    filterContainer.classList.add('filter-container');

    const dropdown = document.createElement('select');
    dropdown.multiple = true;
    dropdown.classList.add('filter-dropdown');

    // Add options to the dropdown
    const uniqueCategories = [];
    images.forEach((img) => {
      const caption = img.nextElementSibling;
      if (caption && caption.classList.contains('image-caption')) {
        const category = caption.textContent.trim();
        if (!uniqueCategories.includes(category)) uniqueCategories.push(category);
      }
    });

    uniqueCategories.forEach((category) => {
      const option = document.createElement('option');
      option.value = category;
      option.textContent = category;
      // Do NOT set option.selected here!
      dropdown.appendChild(option);
    });

    filterContainer.appendChild(dropdown);
    selector.appendChild(filterContainer);

    // Add a grid container for filtered images
    const gridContainer = document.createElement('div');
    gridContainer.classList.add('image-grid');
    selector.appendChild(gridContainer);

    // Choices.js initialization
    const choices = new Choices(dropdown, {
      removeItemButton: true,
      shouldSort: false,
      searchEnabled: false,
      placeholder: true,
      placeholderValue: 'Filter categories',
    });

    // Clear any existing selection first, then set initial selection
    choices.removeActiveItems(); // This clears existing selections
    choices.setChoiceByValue(uniqueCategories[0]); // This sets only the first category

    // Filtering function
    const filterImages = () => {
      const selectedCategories = Array.from(dropdown.selectedOptions).map(opt => opt.value);
      gridContainer.innerHTML = '';
      let shownWrappers = [];
      images.forEach((img) => {
        const caption = img.nextElementSibling;
        if (caption && caption.classList.contains('image-caption')) {
          const category = caption.textContent.trim();
          if (selectedCategories.includes(category)) {
            const imgWrapper = document.createElement('div');
            imgWrapper.classList.add('image-wrapper');
            const imgClone = img.cloneNode(true);
            imgClone.style.cursor = 'pointer';
            imgClone.addEventListener('click', function () {
              const lightboxImage = document.querySelector("#lightbox img");
              const lightbox = document.querySelector("#lightbox");
              lightboxImage.src = imgClone.src;
              lightbox.style.display = 'flex';
            });
            imgWrapper.appendChild(imgClone);
            const captionClone = caption.cloneNode(true);
            imgWrapper.appendChild(captionClone);
            gridContainer.appendChild(imgWrapper);
            shownWrappers.push(imgWrapper);
          }
        }
      });
      // If only one image is shown, make it span both columns
      if (shownWrappers.length === 1) {
        shownWrappers[0].style.gridColumn = "span 2";
      }
    };

    // Listen for changes from Choices.js
    dropdown.addEventListener('change', filterImages);

    // Initial grid (only first category shown)
    filterImages();
  });
});
</script>
<script>
document.addEventListener("DOMContentLoaded", function () {
  var codes = document.querySelectorAll('.hideme');
  var code, i, d, s, p;
  for (i = 0; i < codes.length; i++) {
    code = codes[i];
    p = code.parentNode;
    d = document.createElement('details');
    s = document.createElement('summary');
    s.innerText = 'Details';
    // <details><summary>Details</summary></details>
    d.appendChild(s);
    // move the code into <details>
    p.replaceChild(d, code);
    d.appendChild(code);
  }
});
</script>
            </section>

          </div>
        </div>
      </div>
<a href="results.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="conclusion.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["_main.pdf"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
