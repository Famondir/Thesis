{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9af563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "import requests\n",
    "\n",
    "easy_table = \"../benchmark_tables/easy_table_german_finance_v2.pdf\"\n",
    "\n",
    "reader = PdfReader(easy_table)\n",
    "page = reader.pages[0]\n",
    "# print(page.extract_text())\n",
    "\n",
    "# Define the API endpoint\n",
    "api_url = \"http://localhost:8000/generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f1c3b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:  The response must be a JSON list with the tables extracted from the text. Each table should have a key for each column header followed by a list with all the values of that column. If there are multiple tables, create an separate entry in the JSON list. Do not include any other text or explanation in the response. The response must be a JSON list with the tables extracted from the text. Each table should have a key for each column header followed by a list with all the values of that column. If there are multiple tables, create an separate entry in the JSON list. Do not include any other text or explanation in the response. The response must be a JSON list with the tables extracted from the text. Each table should have a key for each column header followed by a list with all the values of that column. If there are multiple tables, create an separate entry in the JSON list. Do not include any other text or explanation in the response. The response must be a JSON list with the tables extracted from the text. Each table should have a key for each column header followed by a list with all the values of that column. If there are multiple tables, create an separate entry in the JSON list. Do not include any other text or explanation in the response. The response must be a JSON list with the tables extracted from the text. Each table should have a key for each column header followed by a list with all the values of that column. If there are multiple tables, create\n"
     ]
    }
   ],
   "source": [
    "prompt = f'Extract all tables from the following text and return them as JSON:\\n\\n \"\"\"\\n{page.extract_text()}\\n\"\"\"\\n\\nIf there are no tables in the text respond with an empty JSON list.\\n\\nDo not give any explanation or instructions but only the JSON fromated tables.\\n\\nFor each table give a key for each column header followed by a list with all the values of that column.\\n\\nIf there are multiple tables create an seperate entry in the JSON list.\\n\\nDo not include any other text or explanation in the response.'\n",
    "# Set up the input data for inference\n",
    "data = {\n",
    "    \"prompt\": prompt,\n",
    "    \"temperature\": 0.3,      # Control randomness (optional)\n",
    "    \"max_tokens\": 300,       # Limit the length of the response\n",
    "    \"top_p\": 0.9,            # Use nucleus sampling (optional)\n",
    "}\n",
    "\n",
    "# Make the POST request to the vLLM API server\n",
    "response = requests.post(api_url, json=data)\n",
    "\n",
    "# Parse and display the response\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    generated_text = result[\"text\"]\n",
    "    print(\"Generated text:\", generated_text[0].replace(prompt, \"\"))\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e767cb75",
   "metadata": {},
   "source": [
    "Die Ergebnisse von Gwen2.5 7B sind viel besser als von 0.5B-Instruct. At least it worked yesterday (2025-04-15)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5c5ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: Here is the extracted tables from the text in JSON format:\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"Titel\": [\"Posten Einheit 2023 2024 Differenz\"],\n",
      "        \"Vermögen TEUR\": [\"20\", \"21\", \"1\"],\n",
      "        \"Ausgaben TEUR\": [\"10\", \"12\", \"2\"],\n",
      "        \"Einnahmen TEUR\": [\"19\", \"13\", \"-6\"]\n",
      "    },\n",
      "    {\n",
      "        \"Posten 2023 2024 Differenz\": [\"Vermögen TEUR\", \"Ausgaben TEUR\", \"Einnahmen TEUR\"],\n",
      "        \"Vermögen TEUR\": [\"30\", \"23\", \"-7\"],\n",
      "        \"Ausgaben TEUR\": [\"15\", \"17\", \"2\"],\n",
      "        \"Einnahmen TEUR\": [\"19\", \"19\", \"0\"]\n",
      "    },\n",
      "    {\n",
      "        \"Summe\": [\"4\", \"2\"]\n",
      "    },\n",
      "    {\n",
      "        \"Aber was die Quantenstruktur der Bosonen verändert, wenn diese mit Röntgenstrahlung beschossen wird, ist bisher unklar.\": []\n",
      "    }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = '''Extract all tables from the following text and return them as JSON:\n",
    "\n",
    "\"\"\"\n",
    "{#data#}\n",
    "\"\"\"\n",
    "\n",
    "If there are no tables in the text respond with an empty JSON list.\n",
    "\n",
    "Do not give any explanation or instructions. Just return the JSON fromated tables.\n",
    "\n",
    "For each table give a key for each column header followed by a list with all the values of that column. It should follow this format:\n",
    "[{\n",
    "    \"column_header_1\": [value_1, value_2, ...],\n",
    "    \"column_header_2\": [value_1, value_2, ...],\n",
    "    ...\n",
    "    \"column_header_n\": [value_1, value_2, ...]\n",
    "},\n",
    "{\n",
    "    \"column_header_1\": [value_1, value_2, ...],\n",
    "    \"column_header_2\": [value_1, value_2, ...],\n",
    "    ...\n",
    "    \"column_header_m\": [value_1, value_2, ...]\n",
    "}]\n",
    "\n",
    "If there are multiple tables create an seperate entry in the JSON list.\n",
    "'''.replace(\"{#data#}\", page.extract_text())\n",
    "# Set up the input data for inference\n",
    "data = {\n",
    "    \"prompt\": prompt,\n",
    "    \"temperature\": 0.3,      # Control randomness (optional)\n",
    "    \"max_tokens\": 300,       # Limit the length of the response\n",
    "    \"top_p\": 0.9,            # Use nucleus sampling (optional)\n",
    "}\n",
    "\n",
    "# Make the POST request to the vLLM API server\n",
    "response = requests.post(api_url, json=data)\n",
    "\n",
    "# Parse and display the response\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    generated_text = result[\"text\"]\n",
    "    print(\"Generated text:\", generated_text[0].replace(prompt, \"\")\n",
    "          )\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f3f00d",
   "metadata": {},
   "source": [
    "Es scheinen richtige Absätze mit \\n\\n besser erkannt zu werden, als einfache \\n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f330af74",
   "metadata": {},
   "source": [
    "OpenAI Backend viel langsamer beim starten! Caching funktioniert nicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fdeb79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
