{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8706a5e-4734-46f4-82e3-9d8323703767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df319309-07d8-4fcf-940e-91fb5d5bc9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Unternehmen                                                URL  \\\n",
      "0  Berliner Bäder Betriebe  https://www.berlinerbaeder.de/unternehmen/gesc...   \n",
      "\n",
      "               Stichwort Suchbereich       Funktion  \n",
      "0  Gesch.{1,2}ftsbericht        text  beautifulsoup  \n"
     ]
    }
   ],
   "source": [
    "def create_dataframe(data, columns):\n",
    "    \"\"\"\n",
    "    Erstellt ein pandas DataFrame aus einer Liste von Listen und einer Liste von Spaltennamen.\n",
    "\n",
    "    :param data: List[List], die Datenreihen\n",
    "    :param columns: List[str], die Spaltennamen\n",
    "    :return: pandas.DataFrame\n",
    "    \"\"\"\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "\"\"\"\n",
    "ohne Sammelseiten:\n",
    "* deutsche Film und Fernsehakademie\n",
    "* deutsches Zentrum für Hochschul und Wissenschaftsforschung\n",
    "* Berliner Werkstätten für Menschen mit Behinderung\n",
    "\"\"\"\n",
    "data = [\n",
    "    # ['IBB', 'https://www.ibb.de/de/ueber-uns/finanzberichte/finanzberichte.html', 'Jahresabschluss', 'text', 'beautifulsoup'],\n",
    "    # ['IBB', 'https://www.ibb.de/de/service/download-center/download-center.html?tag=03_geschaeftsberichte', 'Geschäftsbericht', 'text', 'beautifulsoup'],\n",
    "\n",
    "    # ['degewo AG', 'https://www.degewo.de/presse', 'Konzernlagebericht', 'text', 'beautifulsoup'],\n",
    "    # ['GESOBAU AG', 'https://www.gesobau.de/ueber-uns/gesobau-in-zahlen/geschaeftsbericht/', r'Gesch.{1,2}ftsbericht', 'url', 'beautifulsoup'],\n",
    "    \n",
    "    # ['Berlinovo', 'https://www.berlinovo.de/de/presse/geschaeftsbericht-2021', r'Geschäftsbericht|Jahresabschluss', 'text', 'beautifulsoup'],\n",
    "    # ['Berlinovo', 'https://2023.berlinovo-geschäftsbericht.de/downloads', 'Finanzbericht', 'text', 'beautifulsoup'], # muss man wohl immer anpassen\n",
    "\n",
    "    # ['Amt für Statistik Berlin-Brandenburg', 'https://www.statistik-berlin-brandenburg.de/geschaeftsberichte', 'Geschaeftsbericht', 'url', 'selenium'],\n",
    "\n",
    "    # ['Berlin Energie und Netzholding', 'https://be-nh.de/dokumente/', 'Jahresabschluss', 'text', 'beautifulsoup'],\n",
    "\n",
    "    ['Berliner Bäder Betriebe', 'https://www.berlinerbaeder.de/unternehmen/geschaeftsberichte/', r'Gesch.{1,2}ftsbericht', 'text', 'beautifulsoup'],\n",
    "]\n",
    "\n",
    "columns = [\"Unternehmen\", \"URL\", \"Stichwort\", 'Suchbereich', 'Funktion']\n",
    "\n",
    "df = create_dataframe(data, columns)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "331c4239-e08a-4907-8cd2-30c4cc96c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdfs(url, DOWNLOAD_FOLDER, pattern, link_part = 'text', verbose = False):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    links = soup.find_all(\"a\", href=True)\n",
    "\n",
    "    count_downloaded = 0\n",
    "    count_skipped = 0\n",
    "    count_error = 0\n",
    "    \n",
    "    for link in links:\n",
    "        if link_part == 'text':\n",
    "            search_string = link.text\n",
    "        elif link_part == 'url':\n",
    "            search_string = link['href']\n",
    "        if re.search(pattern, search_string) and link[\"href\"].endswith(\".pdf\"):\n",
    "            pdf_url = link[\"href\"]\n",
    "            if not pdf_url.startswith(\"http\"):\n",
    "                pdf_url = requests.compat.urljoin(url, pdf_url)\n",
    "            \n",
    "            pdf_name = os.path.join(DOWNLOAD_FOLDER, pdf_url.split(\"/\")[-1])\n",
    "\n",
    "            if os.path.exists(pdf_name):\n",
    "                if verbose:\n",
    "                    print(f\"Bereits vorhanden: {pdf_name}\")\n",
    "                \n",
    "                count_skipped += 1\n",
    "                continue\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Lade herunter: {pdf_url}\")\n",
    "\n",
    "            pdf_response = requests.get(pdf_url)\n",
    "            with open(pdf_name, \"wb\") as file:\n",
    "                file.write(pdf_response.content)\n",
    "                count_downloaded += 1\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"Gespeichert als: {pdf_name}\")\n",
    "\n",
    "    if not verbose:\n",
    "        print(f'Es wurden {count_downloaded} Berichte heruntergeladen.\\nEs wurden {count_skipped} schon vorhandene Berichte übersprungen.\\nEs gab {count_error} Fehler.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dc3b7c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "\n",
    "def download_pdfs_with_selenium(url, download_folder, pattern, link_part='text', wait_time=10, verbose=False):\n",
    "    \"\"\"\n",
    "    Opens a website with Chromium using Selenium and downloads all PDF files where the link name or label matches a regex pattern.\n",
    "\n",
    "    :param url: str, the URL of the website\n",
    "    :param download_folder: str, the folder where PDFs will be saved\n",
    "    :param pattern: str, the regex pattern to match link names or labels\n",
    "    :param link_part: str, 'text' to match link text or 'url' to match href attribute\n",
    "    :param wait_time: int, time to wait for the page to load\n",
    "    :param verbose: bool, whether to print detailed logs\n",
    "    \"\"\"\n",
    "    # Set up Selenium WebDriver (ensure you have the correct path to your chromedriver)\n",
    "    # service = Service('path/to/chromedriver')  # Replace with the path to your chromedriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')  # Run in headless mode\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    driver = webdriver.Chrome(\n",
    "        service=Service(ChromeDriverManager().install()), \n",
    "        options=options\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        # Open the URL\n",
    "        driver.get(url)\n",
    "\n",
    "        count_downloaded = 0\n",
    "        count_skipped = 0\n",
    "        count_error = 0\n",
    "\n",
    "        while True:\n",
    "            # Wait for the page to load\n",
    "            try:\n",
    "                # Wait for the page to load\n",
    "                WebDriverWait(driver, wait_time).until(\n",
    "                    EC.presence_of_all_elements_located((\n",
    "                        # By.TAG_NAME, 'a'\n",
    "                        By.CLASS_NAME, 'afs-item-result'\n",
    "                        ))\n",
    "                )\n",
    "            except TimeoutException:\n",
    "                print(\"Timeout waiting for page to load.\")\n",
    "                break\n",
    "\n",
    "            # Find all links on the page\n",
    "            links = driver.find_elements(By.TAG_NAME, 'a')\n",
    "\n",
    "            for link in links:\n",
    "                try:           \n",
    "                    if link_part == 'text':\n",
    "                        search_string = link.text\n",
    "                    elif link_part == 'url':\n",
    "                        search_string = link.get_attribute('href')\n",
    "\n",
    "                    if search_string and re.search(pattern, search_string) and search_string.endswith('.pdf'):\n",
    "                        pdf_url = search_string if link_part == 'url' else link.get_attribute('href')\n",
    "                        if not pdf_url.startswith(\"http\"):\n",
    "                            pdf_url = requests.compat.urljoin(url, pdf_url)\n",
    "\n",
    "                        pdf_name = os.path.join(download_folder, pdf_url.split(\"/\")[-1])\n",
    "\n",
    "                        if os.path.exists(pdf_name):\n",
    "                            if verbose:\n",
    "                                print(f\"Bereits vorhanden: {pdf_name}\")\n",
    "                            count_skipped += 1\n",
    "                            continue\n",
    "\n",
    "                        if verbose:\n",
    "                            print(f\"Lade herunter: {pdf_url}\")\n",
    "\n",
    "                        pdf_response = requests.get(pdf_url)\n",
    "                        with open(pdf_name, \"wb\") as file:\n",
    "                            file.write(pdf_response.content)\n",
    "                            count_downloaded += 1\n",
    "\n",
    "                            if verbose:\n",
    "                                print(f\"Gespeichert als: {pdf_name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Fehler beim Abrufen des Links: {e}\")\n",
    "                    count_error += 1\n",
    "                    continue\n",
    "\n",
    "            # Check for the next page button\n",
    "            # funktioniert für Amt für Statistik nicht\n",
    "            try:\n",
    "                # Locate the parent element with class 'pagination'\n",
    "                pagination = driver.find_element(By.CLASS_NAME, 'pagination')\n",
    "                # Find the last element with class 'pagination-nav-item' within the parent\n",
    "                next_button = pagination.find_elements(By.CLASS_NAME, 'pagination-nav-item')[-1].find_element(By.TAG_NAME, 'a')\n",
    "                print(next_button.label)\n",
    "                \n",
    "                if 'disabled' in next_button.get_attribute('class'):\n",
    "                    print(\"No more pages to navigate.\")\n",
    "                    break\n",
    "                next_button.click()\n",
    "                time.sleep(2)  # Wait for the next page to load\n",
    "            except Exception as e:\n",
    "                print(\"No next page button found or error navigating to the next page.\")\n",
    "                break\n",
    "\n",
    "        if not verbose:\n",
    "            print(f'Es wurden {count_downloaded} Berichte heruntergeladen.\\nEs wurden {count_skipped} schon vorhandene Berichte übersprungen.')\n",
    "\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "        # pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2c78a651-322f-4271-9297-1472e28e9eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####### Berliner Bäder Betriebe #######\n",
      "Lade herunter: https://www.berlinerbaeder.de/fileadmin/BBB/Dateien/Unternehmen/Geschaeftsberichte/2023_Geschaeftsbericht_BBB.pdf\n",
      "Gespeichert als: Geschaeftsberichte/Berliner Bäder Betriebe/2023_Geschaeftsbericht_BBB.pdf\n",
      "Lade herunter: https://www.berlinerbaeder.de/fileadmin/BBB/Dateien/Unternehmen/Geschaeftsberichte/2022_Geschaeftsbericht_BBB.pdf\n",
      "Gespeichert als: Geschaeftsberichte/Berliner Bäder Betriebe/2022_Geschaeftsbericht_BBB.pdf\n",
      "Lade herunter: https://www.berlinerbaeder.de/fileadmin/BBB/Dateien/Unternehmen/Geschaeftsberichte/2021_Geschaeftsbericht_BBB.pdf\n",
      "Gespeichert als: Geschaeftsberichte/Berliner Bäder Betriebe/2021_Geschaeftsbericht_BBB.pdf\n",
      "Lade herunter: https://www.berlinerbaeder.de/fileadmin/BBB/Dateien/Unternehmen/Geschaeftsberichte/2020_Geschaeftsbericht_BBB.pdf\n",
      "Gespeichert als: Geschaeftsberichte/Berliner Bäder Betriebe/2020_Geschaeftsbericht_BBB.pdf\n",
      "Lade herunter: https://www.berlinerbaeder.de/fileadmin/BBB/Dateien/Unternehmen/Geschaeftsberichte/2019_Geschaeftsbericht_BBB.pdf\n",
      "Gespeichert als: Geschaeftsberichte/Berliner Bäder Betriebe/2019_Geschaeftsbericht_BBB.pdf\n",
      "Lade herunter: https://www.berlinerbaeder.de/fileadmin/BBB/Dateien/Unternehmen/Geschaeftsberichte/Geschaeftsberichte_der_BBB_Infrastruktur-Verwaltungs_GmbH___BBB_Infrastruktur_GmbH___Co._KG/GB_BBB_Infra_2023.pdf\n",
      "Gespeichert als: Geschaeftsberichte/Berliner Bäder Betriebe/GB_BBB_Infra_2023.pdf\n",
      "Lade herunter: https://www.berlinerbaeder.de/fileadmin/BBB/Dateien/Unternehmen/Geschaeftsberichte/Geschaeftsberichte_der_BBB_Infrastruktur-Verwaltungs_GmbH___BBB_Infrastruktur_GmbH___Co._KG/GB_BBB_Infra_2022_low.pdf\n",
      "Gespeichert als: Geschaeftsberichte/Berliner Bäder Betriebe/GB_BBB_Infra_2022_low.pdf\n",
      "Lade herunter: https://www.berlinerbaeder.de/fileadmin/BBB/Dateien/Unternehmen/Geschaeftsberichte/Geschaeftsberichte_der_BBB_Infrastruktur-Verwaltungs_GmbH___BBB_Infrastruktur_GmbH___Co._KG/GB_BBB_Infra_2021.pdf\n",
      "Gespeichert als: Geschaeftsberichte/Berliner Bäder Betriebe/GB_BBB_Infra_2021.pdf\n",
      "Lade herunter: https://www.berlinerbaeder.de/fileadmin/BBB/Dateien/Unternehmen/Geschaeftsberichte/Geschaeftsberichte_der_BBB_Infrastruktur-Verwaltungs_GmbH___BBB_Infrastruktur_GmbH___Co._KG/GB_BBB_Infra_2020.pdf\n",
      "Gespeichert als: Geschaeftsberichte/Berliner Bäder Betriebe/GB_BBB_Infra_2020.pdf\n",
      "Lade herunter: https://www.berlinerbaeder.de/fileadmin/BBB/Dateien/Unternehmen/Geschaeftsberichte/Geschaeftsberichte_der_BBB_Infrastruktur-Verwaltungs_GmbH___BBB_Infrastruktur_GmbH___Co._KG/GB_BBB_Infra_2019.pdf\n",
      "Gespeichert als: Geschaeftsberichte/Berliner Bäder Betriebe/GB_BBB_Infra_2019.pdf\n",
      "Es befinden sich 10 Berichte im Verzeichnis.\n"
     ]
    }
   ],
   "source": [
    "def pdf_downloader_loop(df, download_parent_folder = 'Geschaeftsberichte/'):\n",
    "    for index, row in df.iterrows():\n",
    "        unternehmen = row['Unternehmen']\n",
    "        URL = row['URL']\n",
    "        stichwort = row['Stichwort']\n",
    "        suchbereich = row['Suchbereich']\n",
    "        f = row['Funktion']\n",
    "\n",
    "        # Verzeichnis für die heruntergeladenen PDFs\n",
    "        DOWNLOAD_FOLDER = download_parent_folder+unternehmen\n",
    "        verbose = False if os.path.exists(DOWNLOAD_FOLDER) else True\n",
    "        os.makedirs(DOWNLOAD_FOLDER, exist_ok=True)\n",
    "\n",
    "        print(f'\\n####### {unternehmen} #######')\n",
    "        if f == 'beautifulsoup':\n",
    "            download_pdfs(URL, DOWNLOAD_FOLDER, stichwort, suchbereich, verbose)\n",
    "        elif f == 'selenium':\n",
    "            download_pdfs_with_selenium(URL, DOWNLOAD_FOLDER, stichwort, suchbereich, verbose=verbose)\n",
    "        file_count = len([file for file in os.listdir(DOWNLOAD_FOLDER) if file.endswith('.pdf')])\n",
    "        print(f'Es befinden sich {file_count} Berichte im Verzeichnis.')\n",
    "\n",
    "pdf_downloader_loop(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006c2690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
